{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9640b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import train_flow\n",
    "import importlib\n",
    "importlib.reload(train_flow)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d89da1",
   "metadata": {},
   "source": [
    "# Feature Engineering for net new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83ee60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Feature Sets: dict_keys(['ma', 'rsi', 'macd', 'volume', 'atr_adx', 'volatility', 'vix_skew', 'experimental_slope', 'past_return'])\n"
     ]
    }
   ],
   "source": [
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "ticker = 'QQQ'\n",
    "include_minute_feats = \"N\"\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "df_daily, feature_sets, return_cols, daily_cols, feature_dict, features = train_flow.import_data(ticker, include_minute_feats, returns)\n",
    "\n",
    "# ---------- #\n",
    "# UPDATE ME  #\n",
    "# ---------- #\n",
    "# Add any new features\n",
    "df_daily[[f\"{c}_sum10\" for c in df_daily.columns if c.startswith(\"Past_Return_\")]] = (df_daily.sort_values(by=\"Date\", ascending=True).filter(like=\"Past_Return_\").rolling(10, min_periods=1).sum())\n",
    "past_ret_cols = [c for c in df_daily.columns if c.startswith(\"Past_Return%\") or c.endswith(\"sum10\")]\n",
    "past_perc_cols = [c for c in df_daily.columns if c.startswith(\"Past_Return%\")]\n",
    "past_sum_cols = [c for c in df_daily.columns if c.endswith(\"sum10\")]\n",
    "cutoff_date = '2026-02-06' # Unlessretraining all baseline models, leave alone\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "df_main = df_daily[df_daily['Date'] <= cutoff_date].copy() #cutoff date for baseline performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a8226",
   "metadata": {},
   "source": [
    "# Run Train_Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "38859f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for horizon 2 | include_new\n",
      "86 | 8 | All Cols: ['ADL', 'SMA_10_Lag200_min', 'VROC_10', 'VROC_3', 'VROC_5', 'Vol_Ratio_100', 'Vol_Ratio_25_zscore', 'Vol_Ratio_50_zscore']\n",
      "Run 1/120 | Train: 2021-03-17 → 2026-01-30 | Test: 2026-02-04 → 2026-02-04 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "86 | 8 | All Cols: ['CMF_20', 'OBV_Z10', 'VROC_10', 'VROC_5', 'Vol_Ratio_100', 'Vol_Ratio_100_zscore', 'Vol_Ratio_25_zscore', 'Vol_Ratio_50_zscore']\n",
      "Run 2/120 | Train: 2021-03-16 → 2026-01-29 | Test: 2026-02-03 → 2026-02-03 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "86 | 8 | All Cols: ['CMF_10', 'SMA_10_Lag200_min', 'VROC_10', 'VROC_3', 'VROC_5', 'Vol_Ratio_100_zscore', 'Vol_Ratio_25_zscore', 'Vol_Ratio_50_zscore']\n",
      "Run 3/120 | Train: 2021-03-15 → 2026-01-28 | Test: 2026-02-02 → 2026-02-02 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "86 | 8 | All Cols: ['CMF_20', 'SMA_10_Lag200_min', 'VROC_10', 'VROC_5', 'Vol_Ratio_100', 'Vol_Ratio_25_zscore', 'Vol_Ratio_50_zscore', 'Vol_Spike_20']\n",
      "Run 4/120 | Train: 2021-03-12 → 2026-01-27 | Test: 2026-01-30 → 2026-01-30 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# --------- #\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# LEAVE ME  #\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# --------- # \u001b[39;00m\n\u001b[1;32m     37\u001b[0m models \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost-3\u001b[39m\u001b[38;5;124m\"\u001b[39m: XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)}\n\u001b[0;32m---> 38\u001b[0m results_df, perm_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_day\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays_assessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_horizons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi_handlings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_main\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtrain_years\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi_years\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Stocks/train_flow.py:410\u001b[0m, in \u001b[0;36mrun_train_flow\u001b[0;34m(test_day, days_assessed, returns, pi_handlings, feature_cols, df, models, train_years, pi_years, min_feats, list_name, new_features)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning for horizon \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpi_handling\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m base_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(base_cols \u001b[38;5;241m+\u001b[39m new_features))\n\u001b[0;32m--> 410\u001b[0m df_scores, perm_df \u001b[38;5;241m=\u001b[39m \u001b[43mwalkback_runs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpi_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpi_years\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_year\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_day\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_day\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpurge_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpi_handling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpi_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m df_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_set\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m list_name\n\u001b[1;32m    429\u001b[0m df_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m r\n",
      "File \u001b[0;32m~/Documents/Stocks/train_flow.py:237\u001b[0m, in \u001b[0;36mwalkback_runs\u001b[0;34m(df, models, feature_cols, target_col, pi_years, date_col, train_years, test_days, step_days, runs, purge_days, fill_inf, min_feats, pi_handling, new_features)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m#start_time = time.time()\u001b[39;00m\n\u001b[1;32m    236\u001b[0m m \u001b[38;5;241m=\u001b[39m clone(model)\n\u001b[0;32m--> 237\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m preds \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    240\u001b[0m proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1597\u001b[0m )\n\u001b[0;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import train_flow\n",
    "import importlib\n",
    "importlib.reload(train_flow)\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "# Handling of new features and permutation importance\n",
    "pi_handlings = ['include_new']#['exclude_new', 'include_new', 'run_separately']\n",
    "train_flow.pi_handling_test(pi_handlings)\n",
    "\n",
    "\"\"\"\n",
    "Applicable when appending new features to an existing set\n",
    "run_separately: runs pi for old and new feature set separately --> combines the top features from each set at end\n",
    "exclude_new: runs pi only for old feature set then appends all new features onto the trimmed list --> combines the top old list features with all new features \n",
    "include_new: runs pi for combined old and new feature set --> if new features aren't adding incremental value they will be completely excluded\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ---------- #\n",
    "# UPDATE ME  #\n",
    "# ---------- #\n",
    "new_features = feature_dict['volu']\n",
    "target_horizons = [2]#, 10, 20, 30]\n",
    "train_years = [5]\n",
    "pi_years = [1.5]\n",
    "min_feats = [8]\n",
    "days_assessed = 120\n",
    "test_day = 1\n",
    "feature_cols = feature_dict['ma_lag'] #feature_cols\n",
    "list_name = \"ma_num+exp\"\n",
    "\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- # \n",
    "models = {\"xgboost-3\": XGBClassifier(n_estimators=300, random_state=42, n_jobs=-1)}\n",
    "results_df, perm_df = train_flow.run_train_flow(test_day, days_assessed, target_horizons, pi_handlings, feature_cols, df_main, models,\n",
    "                   train_years, pi_years, min_feats, list_name, new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9c186",
   "metadata": {},
   "source": [
    "# Run for combo of sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdc199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma_lag-['Past_Return%_1', 'Past_Return%_2', 'Past_Return%_3', 'Past_Return%_5', 'Past_Return%_10', 'Past_Return%_20', 'Past_Return%_30', 'Past_Return_1_sum10', 'Past_Return_2_sum10', 'Past_Return_3_sum10', 'Past_Return_5_sum10', 'Past_Return_10_sum10', 'Past_Return_20_sum10', 'Past_Return_30_sum10']\n",
      "Running for horizon 2 | run_separately\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 50\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# --------- #\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# LEAVE ME  #\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# --------- # \u001b[39;00m\n\u001b[1;32m     49\u001b[0m models \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost-3\u001b[39m\u001b[38;5;124m\"\u001b[39m: XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)}\n\u001b[0;32m---> 50\u001b[0m results_df, perm_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_day\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays_assessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_horizons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi_handlings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_main\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_years\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi_years\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m master_results\u001b[38;5;241m.\u001b[39mappend(results_df)\n\u001b[1;32m     54\u001b[0m master_perm\u001b[38;5;241m.\u001b[39mappend(perm_df)\n",
      "File \u001b[0;32m~/Documents/Stocks/train_flow.py:410\u001b[0m, in \u001b[0;36mrun_train_flow\u001b[0;34m(test_day, days_assessed, returns, pi_handlings, feature_cols, df, models, train_years, pi_years, min_feats, list_name, new_features)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning for horizon \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpi_handling\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m base_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(base_cols \u001b[38;5;241m+\u001b[39m new_features))\n\u001b[0;32m--> 410\u001b[0m df_scores, perm_df \u001b[38;5;241m=\u001b[39m \u001b[43mwalkback_runs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpi_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpi_years\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_year\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_day\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_day\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpurge_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpi_handling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpi_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m df_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_set\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m list_name\n\u001b[1;32m    429\u001b[0m df_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m r\n",
      "File \u001b[0;32m~/Documents/Stocks/train_flow.py:167\u001b[0m, in \u001b[0;36mwalkback_runs\u001b[0;34m(df, models, feature_cols, target_col, pi_years, date_col, train_years, test_days, step_days, runs, purge_days, fill_inf, min_feats, pi_handling, new_features)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pi_handling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_separately\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    165\u001b[0m     feat \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m base_feature_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m new_features]\n\u001b[0;32m--> 167\u001b[0m     perm_cols, p_df \u001b[38;5;241m=\u001b[39m \u001b[43mperm_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdfpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpi_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpi_year\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_feat\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     new_perm_cols, p_df \u001b[38;5;241m=\u001b[39m perm_list(\n\u001b[1;32m    178\u001b[0m         df\u001b[38;5;241m=\u001b[39mdfpi,\n\u001b[1;32m    179\u001b[0m         feature_cols\u001b[38;5;241m=\u001b[39mnew_features,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         feat_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feature_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(perm_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Original Cols: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(perm_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Stocks/train_flow.py:330\u001b[0m, in \u001b[0;36mperm_list\u001b[0;34m(df, feature_cols, target_col, model, fill_inf, pi_year, min_feats, feat_type)\u001b[0m\n\u001b[1;32m    327\u001b[0m m \u001b[38;5;241m=\u001b[39m clone(model)\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# permutation importance on training-only slice\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m pi \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_pi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# or \"accuracy\", \"neg_log_loss\", etc.\u001b[39;49;00m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# pi.importances_mean aligns to feature_cols order\u001b[39;00m\n\u001b[1;32m    341\u001b[0m pi_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature_cols,                 \u001b[38;5;66;03m# same order used to build X_train\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: pi\u001b[38;5;241m.\u001b[39mimportances_mean,\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi_std\u001b[39m\u001b[38;5;124m\"\u001b[39m:  pi\u001b[38;5;241m.\u001b[39mimportances_std,\n\u001b[1;32m    345\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/inspection/_permutation_importance.py:287\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    284\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m    285\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[0;32m--> 287\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    304\u001b[0m         name: _create_importances_bunch(\n\u001b[1;32m    305\u001b[0m             baseline_score[name],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[1;32m    310\u001b[0m     }\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import train_flow\n",
    "import importlib\n",
    "importlib.reload(train_flow)\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "# Handling of new features and permutation importance\n",
    "pi_handlings = ['run_separately'] #'exclude_new', 'include_new', 'run_separately'\n",
    "new_feature = past_ret_cols\n",
    "train_flow.pi_handling_test(pi_handlings)\n",
    "keys = list(feature_dict.keys())\n",
    "two_combos = list(combinations(keys, 2))\n",
    "new_feat_combos = [(k, new_feature) for k in keys]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Applicable when appending new features to an existing set\n",
    "run_separately: runs pi for old and new feature set separately --> combines the top features from each set at end\n",
    "exclude_new: runs pi only for old feature set then appends all new features onto the trimmed list --> combines the top old list features with all new features \n",
    "include_new: runs pi for combined old and new feature set --> if new features aren't adding incremental value they will be completely excluded\n",
    "\"\"\"\n",
    "\n",
    "master_results = []\n",
    "master_perm = []\n",
    "\n",
    "for a, b in new_feat_combos:\n",
    "    # ---------- #\n",
    "    # UPDATE ME  #\n",
    "    # ---------- #\n",
    "    #new_features = feature_dict[b] # use when referencing feature dict only\n",
    "    new_features = b\n",
    "    target_horizons = [2, 5, 10, 20, 30]\n",
    "    train_years = [5]\n",
    "    pi_years = [1.5]\n",
    "    min_feats = [4]\n",
    "    days_assessed = 120\n",
    "    test_day = 1\n",
    "    feature_cols = feature_dict[a] #feature_cols\n",
    "    #list_name = f\"{a}-{b}\"\n",
    "    list_name = f\"{a}-pr\"\n",
    "    print(f\"{a}-pr\")\n",
    "\n",
    "\n",
    "    # --------- #\n",
    "    # LEAVE ME  #\n",
    "    # --------- # \n",
    "    models = {\"xgboost-3\": XGBClassifier(n_estimators=300, random_state=42, n_jobs=-1)}\n",
    "    results_df, perm_df = train_flow.run_train_flow(test_day, days_assessed, target_horizons, pi_handlings, feature_cols, df_main, models,\n",
    "                    train_years, pi_years, min_feats, list_name, new_features)\n",
    "    \n",
    "    master_results.append(results_df)\n",
    "    master_perm.append(perm_df)\n",
    "\n",
    "# final master DataFrames\n",
    "master_results_df = pd.concat(master_results, ignore_index=True)\n",
    "master_perm_df    = pd.concat(master_perm, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8e9a0",
   "metadata": {},
   "source": [
    "# Save most recent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- #\n",
    "# UPDATE ME  #\n",
    "# ---------- #\n",
    "df = pd.read_csv(f\"horizon_r_baseline.csv\")\n",
    "\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "cols = ['model', 'test_days', 'pred', 'acc', 'test_n', 'test_pos_n', 'train_n', 'test_start', 'test_end', 'train_years', 'feature_set', 'horizon',\n",
    "        'pi_size', 'min_feats']\n",
    "df_new = master_results_df[cols].copy()\n",
    "df_concat = pd.concat([df[cols], df_new], ignore_index=True)\n",
    "\n",
    "\n",
    "# ---------- #\n",
    "# UPDATE ME  #\n",
    "# ---------- #\n",
    "df_concat.to_csv(f\"horizon_r_baseline_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c564d",
   "metadata": {},
   "source": [
    "# Run Performance_Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e8787bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model</th>\n",
       "      <th>train_years</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>pi_size</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>records</th>\n",
       "      <th>bal_prec</th>\n",
       "      <th>bal_prec_|0.75|</th>\n",
       "      <th>brier</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>mcc</th>\n",
       "      <th>pprec</th>\n",
       "      <th>nprec</th>\n",
       "      <th>cov_|0.75|</th>\n",
       "      <th>pprec_|0.75|</th>\n",
       "      <th>nprec_|0.75|</th>\n",
       "      <th>composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>ma_num_ba</td>\n",
       "      <td>1.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.56</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>experimental_slope_ba</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>ma_num-baseline</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.56</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag-rsi_macd</td>\n",
       "      <td>1.5-r</td>\n",
       "      <td>4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>rsi_macd-baseline</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.56</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_num-atr_adxvola</td>\n",
       "      <td>1.5-r</td>\n",
       "      <td>4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4.67</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>ma_rel-baseline</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.55</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.71</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>volu_ba</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.13</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>ma_rel_ba</td>\n",
       "      <td>1.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.55</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.48</td>\n",
       "      <td>6.99</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>atr_adxvola_ba</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.40</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    horizon      model  train_years            feature_set pi_size  min_feats  \\\n",
       "27        2  xgboost-3            6              ma_num_ba     1.5        100   \n",
       "57        2  xgboost-3            6  experimental_slope_ba     1.5          6   \n",
       "3         2  xgboost-3            6        ma_num-baseline     1.5          8   \n",
       "65        2  xgboost-3            5        ma_lag-rsi_macd   1.5-r          4   \n",
       "4         2  xgboost-3            6      rsi_macd-baseline     1.5          8   \n",
       "..      ...        ...          ...                    ...     ...        ...   \n",
       "85        2  xgboost-3            5     ma_num-atr_adxvola   1.5-r          4   \n",
       "1         2  xgboost-3            6        ma_rel-baseline     1.5          8   \n",
       "51        2  xgboost-3            6                volu_ba     1.5          6   \n",
       "23        2  xgboost-3            6              ma_rel_ba     1.5        100   \n",
       "53        2  xgboost-3            6         atr_adxvola_ba     1.5          6   \n",
       "\n",
       "    pos_rate  records  bal_prec  bal_prec_|0.75|  brier  log_loss   mcc  \\\n",
       "27      0.56    112.0      0.59             0.57   0.33      4.09  0.17   \n",
       "57      0.54    114.0      0.58             0.56   0.33      3.48  0.15   \n",
       "3       0.56    111.0      0.58             0.55   0.34      3.85  0.15   \n",
       "65      0.55    105.0      0.57             0.64   0.32      3.36  0.14   \n",
       "4       0.56    104.0      0.57             0.54   0.32      2.14  0.14   \n",
       "..       ...      ...       ...              ...    ...       ...   ...   \n",
       "85      0.55    111.0      0.39             0.37   0.43      4.67 -0.22   \n",
       "1       0.55    110.0      0.39             0.35   0.48      7.71 -0.22   \n",
       "51      0.54    109.0      0.38             0.41   0.46      5.13 -0.23   \n",
       "23      0.55    113.0      0.38             0.35   0.48      6.99 -0.23   \n",
       "53      0.54    109.0      0.36             0.38   0.46      5.40 -0.25   \n",
       "\n",
       "    pprec  nprec  cov_|0.75|  pprec_|0.75|  nprec_|0.75|  composite  \n",
       "27   0.63   0.55        0.77          0.57          0.57       0.47  \n",
       "57   0.59   0.57        0.82          0.60          0.52       0.46  \n",
       "3    0.62   0.53        0.78          0.56          0.55       0.45  \n",
       "65   0.60   0.54        0.74          0.65          0.62       0.45  \n",
       "4    0.62   0.52        0.84          0.63          0.45       0.45  \n",
       "..    ...    ...         ...           ...           ...        ...  \n",
       "85   0.47   0.30        0.77          0.51          0.23       0.24  \n",
       "1    0.46   0.31        0.79          0.44          0.27       0.23  \n",
       "51   0.45   0.32        0.77          0.44          0.37       0.23  \n",
       "23   0.47   0.29        0.80          0.44          0.26       0.23  \n",
       "53   0.45   0.28        0.77          0.45          0.31       0.21  \n",
       "\n",
       "[98 rows x 19 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import performance_flow\n",
    "importlib.reload(performance_flow)\n",
    "\n",
    "# ---------- #\n",
    "# UPDATE ME  #\n",
    "# ---------- #\n",
    "results_file_name = \"horizon_2_baseline_new.csv\" # Match prior cell saved as file name horizon_2_baseline_new\n",
    "min_th = 0.55\n",
    "cov_th = 0.75\n",
    "\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "return_cols, perf_df = performance_flow.import_data(results_file_name, df_main)\n",
    "composite_score = performance_flow.run_performance(perf_df, min_th, cov_th)\n",
    "bucket_df = performance_flow.bucket_scores(df_main, perf_df, returns, min_th)\n",
    "\n",
    "composite_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
