{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Feature Sets: dict_keys(['ma', 'rsi', 'macd', 'volume', 'atr_adx', 'volatility', 'vix_skew', 'experimental_slope'])\n"
     ]
    }
   ],
   "source": [
    "import min_features, daily_return\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\", message=\"y_pred contains classes not in y_true\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import time\n",
    "\n",
    "importlib.reload(min_features)\n",
    "importlib.reload(daily_return)\n",
    "\n",
    "min_feats = \"N\"\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "\n",
    "if min_feats != 'N':\n",
    "    df_min = min_features.min_features()\n",
    "    df_daily, feature_sets = daily_return.pull_daily('QQQ', returns) \n",
    "\n",
    "    df_main = pd.merge(df_min, df_daily, how='inner', on='Date')\n",
    "    df_main = df_main.sort_values(by='Date', ascending=False)\n",
    "\n",
    "    return_cols = df_main.columns[df_main.columns.str.contains(\"Return_\")].to_list()\n",
    "    daily_cols = [\n",
    "        c for c in df_daily.iloc[:, 1:].columns\n",
    "        if \"return\" not in c.lower()\n",
    "    ]\n",
    "    close_cols = df_min.columns[(df_min.columns.str.contains(\"close_\")) | (df_min.columns.str.contains(\"post_\")) | (df_min.columns.str.contains(\"overnight_\"))].to_list()\n",
    "    min_cols = (\n",
    "        df_min\n",
    "        .loc[:, ~df_min.columns.isin(close_cols)]  # drop close_ columns\n",
    "        .iloc[:, 1:]                               # drop first column\n",
    "        .columns\n",
    "        .to_list()\n",
    "    )\n",
    "else:\n",
    "    df_daily, feature_sets = daily_return.pull_daily('QQQ', returns) \n",
    "    return_cols = df_daily.columns[df_daily.columns.str.contains(\"Return_\")].to_list()\n",
    "    daily_cols = [\n",
    "        c for c in df_daily.iloc[:, 1:].columns\n",
    "        if \"return\" not in c.lower()\n",
    "    ]\n",
    "    df_main = df_daily[df_daily['Date'] <= '2026-01-21'].copy()\n",
    "\n",
    "#top_models = pd.read_csv(\"top_performers2.csv\")\n",
    "print(f'Available Feature Sets: {feature_sets.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_days_50</th>\n",
       "      <th>num_days_100</th>\n",
       "      <th>num_days_200</th>\n",
       "      <th>Max_10_Rows_Since</th>\n",
       "      <th>Min_10_Rows_Since</th>\n",
       "      <th>Max_30_Rows_Since</th>\n",
       "      <th>Min_30_Rows_Since</th>\n",
       "      <th>Max_60_Rows_Since</th>\n",
       "      <th>Min_60_Rows_Since</th>\n",
       "      <th>Max_120_Rows_Since</th>\n",
       "      <th>Min_120_Rows_Since</th>\n",
       "      <th>Max_240_Rows_Since</th>\n",
       "      <th>Min_240_Rows_Since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>5.164786</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>4.779123</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>5.293305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>5.159055</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>4.770685</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>5.288267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>5.153292</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>5.283204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>5.147494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>5.278115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>2.079442</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>5.141664</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>5.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>5.135798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>4.736198</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>5.267858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>4.727388</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>5.262690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>5.123964</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>4.718499</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>5.257495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6750</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.117994</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>4.709530</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>5.252273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>5.111988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>4.700480</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>5.247024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>5.105945</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>4.691348</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>5.241747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>5.099866</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>5.236442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>4.779123</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>5.231109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>5.087596</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>4.770685</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>5.225747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>5.081404</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>5.220356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>5.075174</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>5.214936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>5.068904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>5.209486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>5.204007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>5.056246</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>5.198497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>4.779123</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>5.192957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>5.043425</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>5.187386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>-1.386294</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>5.036953</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>5.181784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>-1.098612</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>5.030438</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>4.779123</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>5.176150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>5.023881</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>5.170484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.164786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_days_50  num_days_100  num_days_200  Max_10_Rows_Since  \\\n",
       "6758     0.693147      3.713572      5.164786           1.386294   \n",
       "6757     0.000000      3.688879      5.159055           1.098612   \n",
       "6756     2.302585      3.663562      5.153292           0.693147   \n",
       "6755     2.197225      3.637586      5.147494           0.000000   \n",
       "6754     2.079442      3.610918      5.141664           0.693147   \n",
       "6753     1.945910      3.583519      5.135798           0.000000   \n",
       "6752     1.791759      3.555348      5.129899           0.000000   \n",
       "6751     1.609438      3.526361      5.123964           1.098612   \n",
       "6750     1.386294      3.496508      5.117994           0.693147   \n",
       "6749     1.098612      3.465736      5.111988           0.000000   \n",
       "6748     0.693147      3.433987      5.105945           1.945910   \n",
       "6747     0.000000      3.401197      5.099866           1.791759   \n",
       "6746    -0.693147      3.367296      5.093750           1.609438   \n",
       "6745     0.000000      3.332205      5.087596           1.386294   \n",
       "6744     1.945910      3.295837      5.081404           1.098612   \n",
       "6743     1.791759      3.258097      5.075174           0.693147   \n",
       "6742     1.609438      3.218876      5.068904           0.000000   \n",
       "6741     1.386294      3.178054      5.062595           2.302585   \n",
       "6740     1.098612      3.135494      5.056246           2.302585   \n",
       "6739     0.693147      3.091042      5.049856           2.197225   \n",
       "6738     0.000000      3.044522      5.043425           2.079442   \n",
       "6737    -1.386294      2.995732      5.036953           1.945910   \n",
       "6736    -1.098612      2.944439      5.030438           1.791759   \n",
       "6735    -0.693147      2.890372      5.023881           1.609438   \n",
       "6734     0.000000      2.833213      5.017280           1.386294   \n",
       "\n",
       "      Min_10_Rows_Since  Max_30_Rows_Since  Min_30_Rows_Since  \\\n",
       "6758           0.693147           1.386294           3.135494   \n",
       "6757           0.000000           1.098612           3.091042   \n",
       "6756           1.098612           0.693147           3.044522   \n",
       "6755           2.302585           0.000000           2.995732   \n",
       "6754           2.197225           0.693147           2.944439   \n",
       "6753           2.079442           0.000000           2.890372   \n",
       "6752           1.945910           0.000000           2.833213   \n",
       "6751           1.791759           3.044522           2.772589   \n",
       "6750           1.609438           2.995732           3.401197   \n",
       "6749           1.386294           2.944439           3.401197   \n",
       "6748           1.098612           2.890372           3.401197   \n",
       "6747           0.693147           2.833213           3.367296   \n",
       "6746           2.302585           2.772589           3.332205   \n",
       "6745           2.302585           2.708050           3.295837   \n",
       "6744           2.197225           2.639057           3.258097   \n",
       "6743           2.079442           2.564949           3.218876   \n",
       "6742           1.945910           2.484907           3.178054   \n",
       "6741           1.791759           2.397895           3.135494   \n",
       "6740           1.609438           2.302585           3.091042   \n",
       "6739           1.386294           2.197225           3.044522   \n",
       "6738           1.098612           2.079442           2.995732   \n",
       "6737           0.693147           1.945910           2.944439   \n",
       "6736           0.000000           1.791759           2.890372   \n",
       "6735           0.000000           1.609438           2.833213   \n",
       "6734           0.000000           3.401197           2.772589   \n",
       "\n",
       "      Max_60_Rows_Since  Min_60_Rows_Since  Max_120_Rows_Since  \\\n",
       "6758           4.043051           3.688879            4.043051   \n",
       "6757           4.025352           3.663562            4.025352   \n",
       "6756           4.007333           3.637586            4.007333   \n",
       "6755           3.988984           3.610918            3.988984   \n",
       "6754           3.970292           3.583519            3.970292   \n",
       "6753           3.951244           3.555348            3.951244   \n",
       "6752           3.931826           3.526361            3.931826   \n",
       "6751           3.912023           3.496508            3.912023   \n",
       "6750           3.891820           3.465736            3.891820   \n",
       "6749           3.871201           3.433987            3.871201   \n",
       "6748           3.850148           3.401197            3.850148   \n",
       "6747           3.828641           3.367296            3.828641   \n",
       "6746           3.806662           3.332205            3.806662   \n",
       "6745           3.784190           3.295837            3.784190   \n",
       "6744           3.761200           3.258097            3.761200   \n",
       "6743           3.737670           3.218876            3.737670   \n",
       "6742           3.713572           3.178054            3.713572   \n",
       "6741           3.688879           3.135494            3.688879   \n",
       "6740           3.663562           3.091042            3.663562   \n",
       "6739           3.637586           3.044522            3.637586   \n",
       "6738           3.610918           2.995732            3.610918   \n",
       "6737           3.583519           2.944439            3.583519   \n",
       "6736           3.555348           2.890372            3.555348   \n",
       "6735           3.526361           2.833213            3.526361   \n",
       "6734           3.496508           2.772589            3.496508   \n",
       "\n",
       "      Min_120_Rows_Since  Max_240_Rows_Since  Min_240_Rows_Since  \n",
       "6758            4.779123            4.043051            5.293305  \n",
       "6757            4.770685            4.025352            5.288267  \n",
       "6756            4.762174            4.007333            5.283204  \n",
       "6755            4.753590            3.988984            5.278115  \n",
       "6754            4.744932            3.970292            5.273000  \n",
       "6753            4.736198            3.951244            5.267858  \n",
       "6752            4.727388            3.931826            5.262690  \n",
       "6751            4.718499            3.912023            5.257495  \n",
       "6750            4.709530            3.891820            5.252273  \n",
       "6749            4.700480            3.871201            5.247024  \n",
       "6748            4.691348            3.850148            5.241747  \n",
       "6747            4.787492            3.828641            5.236442  \n",
       "6746            4.779123            3.806662            5.231109  \n",
       "6745            4.770685            3.784190            5.225747  \n",
       "6744            4.762174            3.761200            5.220356  \n",
       "6743            4.753590            3.737670            5.214936  \n",
       "6742            4.744932            3.713572            5.209486  \n",
       "6741            4.787492            3.688879            5.204007  \n",
       "6740            4.787492            3.663562            5.198497  \n",
       "6739            4.779123            3.637586            5.192957  \n",
       "6738            4.787492            3.610918            5.187386  \n",
       "6737            4.787492            3.583519            5.181784  \n",
       "6736            4.779123            3.555348            5.176150  \n",
       "6735            4.787492            3.526361            5.170484  \n",
       "6734            4.787492            3.496508            5.164786  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# signed log1p transform for every column in ma_num\n",
    "cols = ma_num\n",
    "\n",
    "df_main[[f\"{c}\" for c in cols]] = (\n",
    "    np.sign(df_main[cols]) * np.log1p(np.abs(df_main[cols]))\n",
    ")\n",
    "\n",
    "df_main[ma_num].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran permutation importance | Len: 735 | Old: 86 | New: 20\n",
      "Run 1/230 | Train: 2022-02-16 → 2026-01-13 | Test: 2026-01-16 → 2026-01-16 | Train_n=980 | Test_n=1\n",
      "Run 2/230 | Train: 2022-02-15 → 2026-01-12 | Test: 2026-01-15 → 2026-01-15 | Train_n=980 | Test_n=1\n",
      "Run 3/230 | Train: 2022-02-14 → 2026-01-09 | Test: 2026-01-14 → 2026-01-14 | Train_n=980 | Test_n=1\n",
      "Run 4/230 | Train: 2022-02-11 → 2026-01-08 | Test: 2026-01-13 → 2026-01-13 | Train_n=980 | Test_n=1\n",
      "Run 5/230 | Train: 2022-02-10 → 2026-01-07 | Test: 2026-01-12 → 2026-01-12 | Train_n=980 | Test_n=1\n",
      "Run 6/230 | Train: 2022-02-09 → 2026-01-06 | Test: 2026-01-09 → 2026-01-09 | Train_n=980 | Test_n=1\n",
      "Run 7/230 | Train: 2022-02-08 → 2026-01-05 | Test: 2026-01-08 → 2026-01-08 | Train_n=980 | Test_n=1\n",
      "Run 8/230 | Train: 2022-02-07 → 2026-01-02 | Test: 2026-01-07 → 2026-01-07 | Train_n=980 | Test_n=1\n",
      "Run 9/230 | Train: 2022-02-04 → 2025-12-31 | Test: 2026-01-06 → 2026-01-06 | Train_n=980 | Test_n=1\n",
      "Run 10/230 | Train: 2022-02-03 → 2025-12-30 | Test: 2026-01-05 → 2026-01-05 | Train_n=980 | Test_n=1\n",
      "Run 11/230 | Train: 2022-02-02 → 2025-12-29 | Test: 2026-01-02 → 2026-01-02 | Train_n=980 | Test_n=1\n",
      "Run 12/230 | Train: 2022-02-01 → 2025-12-26 | Test: 2025-12-31 → 2025-12-31 | Train_n=980 | Test_n=1\n",
      "Run 13/230 | Train: 2022-01-31 → 2025-12-24 | Test: 2025-12-30 → 2025-12-30 | Train_n=980 | Test_n=1\n",
      "Run 14/230 | Train: 2022-01-28 → 2025-12-23 | Test: 2025-12-29 → 2025-12-29 | Train_n=980 | Test_n=1\n",
      "Run 15/230 | Train: 2022-01-27 → 2025-12-22 | Test: 2025-12-26 → 2025-12-26 | Train_n=980 | Test_n=1\n",
      "Run 16/230 | Train: 2022-01-26 → 2025-12-19 | Test: 2025-12-24 → 2025-12-24 | Train_n=980 | Test_n=1\n",
      "Run 17/230 | Train: 2022-01-25 → 2025-12-18 | Test: 2025-12-23 → 2025-12-23 | Train_n=980 | Test_n=1\n",
      "Run 18/230 | Train: 2022-01-24 → 2025-12-17 | Test: 2025-12-22 → 2025-12-22 | Train_n=980 | Test_n=1\n",
      "Run 19/230 | Train: 2022-01-21 → 2025-12-16 | Test: 2025-12-19 → 2025-12-19 | Train_n=980 | Test_n=1\n",
      "Run 20/230 | Train: 2022-01-20 → 2025-12-15 | Test: 2025-12-18 → 2025-12-18 | Train_n=980 | Test_n=1\n",
      "Run 21/230 | Train: 2022-01-19 → 2025-12-12 | Test: 2025-12-17 → 2025-12-17 | Train_n=980 | Test_n=1\n",
      "Run 22/230 | Train: 2022-01-18 → 2025-12-11 | Test: 2025-12-16 → 2025-12-16 | Train_n=980 | Test_n=1\n",
      "Run 23/230 | Train: 2022-01-14 → 2025-12-10 | Test: 2025-12-15 → 2025-12-15 | Train_n=980 | Test_n=1\n",
      "Run 24/230 | Train: 2022-01-13 → 2025-12-09 | Test: 2025-12-12 → 2025-12-12 | Train_n=980 | Test_n=1\n",
      "Run 25/230 | Train: 2022-01-12 → 2025-12-08 | Test: 2025-12-11 → 2025-12-11 | Train_n=980 | Test_n=1\n",
      "Run 26/230 | Train: 2022-01-11 → 2025-12-05 | Test: 2025-12-10 → 2025-12-10 | Train_n=980 | Test_n=1\n",
      "Run 27/230 | Train: 2022-01-10 → 2025-12-04 | Test: 2025-12-09 → 2025-12-09 | Train_n=980 | Test_n=1\n",
      "Run 28/230 | Train: 2022-01-07 → 2025-12-03 | Test: 2025-12-08 → 2025-12-08 | Train_n=980 | Test_n=1\n",
      "Run 29/230 | Train: 2022-01-06 → 2025-12-02 | Test: 2025-12-05 → 2025-12-05 | Train_n=980 | Test_n=1\n",
      "Run 30/230 | Train: 2022-01-05 → 2025-12-01 | Test: 2025-12-04 → 2025-12-04 | Train_n=980 | Test_n=1\n",
      "Run 31/230 | Train: 2022-01-04 → 2025-11-28 | Test: 2025-12-03 → 2025-12-03 | Train_n=980 | Test_n=1\n",
      "Run 32/230 | Train: 2022-01-03 → 2025-11-26 | Test: 2025-12-02 → 2025-12-02 | Train_n=980 | Test_n=1\n",
      "Run 33/230 | Train: 2021-12-31 → 2025-11-25 | Test: 2025-12-01 → 2025-12-01 | Train_n=980 | Test_n=1\n",
      "Run 34/230 | Train: 2021-12-30 → 2025-11-24 | Test: 2025-11-28 → 2025-11-28 | Train_n=980 | Test_n=1\n",
      "Run 35/230 | Train: 2021-12-29 → 2025-11-21 | Test: 2025-11-26 → 2025-11-26 | Train_n=980 | Test_n=1\n",
      "Run 36/230 | Train: 2021-12-28 → 2025-11-20 | Test: 2025-11-25 → 2025-11-25 | Train_n=980 | Test_n=1\n",
      "Run 37/230 | Train: 2021-12-27 → 2025-11-19 | Test: 2025-11-24 → 2025-11-24 | Train_n=980 | Test_n=1\n",
      "Run 38/230 | Train: 2021-12-23 → 2025-11-18 | Test: 2025-11-21 → 2025-11-21 | Train_n=980 | Test_n=1\n",
      "Run 39/230 | Train: 2021-12-22 → 2025-11-17 | Test: 2025-11-20 → 2025-11-20 | Train_n=980 | Test_n=1\n",
      "Run 40/230 | Train: 2021-12-21 → 2025-11-14 | Test: 2025-11-19 → 2025-11-19 | Train_n=980 | Test_n=1\n",
      "Run 41/230 | Train: 2021-12-20 → 2025-11-13 | Test: 2025-11-18 → 2025-11-18 | Train_n=980 | Test_n=1\n",
      "Run 42/230 | Train: 2021-12-17 → 2025-11-12 | Test: 2025-11-17 → 2025-11-17 | Train_n=980 | Test_n=1\n",
      "Run 43/230 | Train: 2021-12-16 → 2025-11-11 | Test: 2025-11-14 → 2025-11-14 | Train_n=980 | Test_n=1\n",
      "Run 44/230 | Train: 2021-12-15 → 2025-11-10 | Test: 2025-11-13 → 2025-11-13 | Train_n=980 | Test_n=1\n",
      "Run 45/230 | Train: 2021-12-14 → 2025-11-07 | Test: 2025-11-12 → 2025-11-12 | Train_n=980 | Test_n=1\n",
      "Run 46/230 | Train: 2021-12-13 → 2025-11-06 | Test: 2025-11-11 → 2025-11-11 | Train_n=980 | Test_n=1\n",
      "Run 47/230 | Train: 2021-12-10 → 2025-11-05 | Test: 2025-11-10 → 2025-11-10 | Train_n=980 | Test_n=1\n",
      "Run 48/230 | Train: 2021-12-09 → 2025-11-04 | Test: 2025-11-07 → 2025-11-07 | Train_n=980 | Test_n=1\n",
      "Run 49/230 | Train: 2021-12-08 → 2025-11-03 | Test: 2025-11-06 → 2025-11-06 | Train_n=980 | Test_n=1\n",
      "Run 50/230 | Train: 2021-12-07 → 2025-10-31 | Test: 2025-11-05 → 2025-11-05 | Train_n=980 | Test_n=1\n",
      "Run 51/230 | Train: 2021-12-06 → 2025-10-30 | Test: 2025-11-04 → 2025-11-04 | Train_n=980 | Test_n=1\n",
      "Run 52/230 | Train: 2021-12-03 → 2025-10-29 | Test: 2025-11-03 → 2025-11-03 | Train_n=980 | Test_n=1\n",
      "Run 53/230 | Train: 2021-12-02 → 2025-10-28 | Test: 2025-10-31 → 2025-10-31 | Train_n=980 | Test_n=1\n",
      "Run 54/230 | Train: 2021-12-01 → 2025-10-27 | Test: 2025-10-30 → 2025-10-30 | Train_n=980 | Test_n=1\n",
      "Run 55/230 | Train: 2021-11-30 → 2025-10-24 | Test: 2025-10-29 → 2025-10-29 | Train_n=980 | Test_n=1\n",
      "Run 56/230 | Train: 2021-11-29 → 2025-10-23 | Test: 2025-10-28 → 2025-10-28 | Train_n=980 | Test_n=1\n",
      "Run 57/230 | Train: 2021-11-26 → 2025-10-22 | Test: 2025-10-27 → 2025-10-27 | Train_n=980 | Test_n=1\n",
      "Run 58/230 | Train: 2021-11-24 → 2025-10-21 | Test: 2025-10-24 → 2025-10-24 | Train_n=980 | Test_n=1\n",
      "Run 59/230 | Train: 2021-11-23 → 2025-10-20 | Test: 2025-10-23 → 2025-10-23 | Train_n=980 | Test_n=1\n",
      "Run 60/230 | Train: 2021-11-22 → 2025-10-17 | Test: 2025-10-22 → 2025-10-22 | Train_n=980 | Test_n=1\n",
      "Run 61/230 | Train: 2021-11-19 → 2025-10-16 | Test: 2025-10-21 → 2025-10-21 | Train_n=980 | Test_n=1\n",
      "Run 62/230 | Train: 2021-11-18 → 2025-10-15 | Test: 2025-10-20 → 2025-10-20 | Train_n=980 | Test_n=1\n",
      "Run 63/230 | Train: 2021-11-17 → 2025-10-14 | Test: 2025-10-17 → 2025-10-17 | Train_n=980 | Test_n=1\n",
      "Run 64/230 | Train: 2021-11-16 → 2025-10-13 | Test: 2025-10-16 → 2025-10-16 | Train_n=980 | Test_n=1\n",
      "Run 65/230 | Train: 2021-11-15 → 2025-10-10 | Test: 2025-10-15 → 2025-10-15 | Train_n=980 | Test_n=1\n",
      "Run 66/230 | Train: 2021-11-12 → 2025-10-09 | Test: 2025-10-14 → 2025-10-14 | Train_n=980 | Test_n=1\n",
      "Run 67/230 | Train: 2021-11-11 → 2025-10-08 | Test: 2025-10-13 → 2025-10-13 | Train_n=980 | Test_n=1\n",
      "Run 68/230 | Train: 2021-11-10 → 2025-10-07 | Test: 2025-10-10 → 2025-10-10 | Train_n=980 | Test_n=1\n",
      "Run 69/230 | Train: 2021-11-09 → 2025-10-06 | Test: 2025-10-09 → 2025-10-09 | Train_n=980 | Test_n=1\n",
      "Run 70/230 | Train: 2021-11-08 → 2025-10-03 | Test: 2025-10-08 → 2025-10-08 | Train_n=980 | Test_n=1\n",
      "Run 71/230 | Train: 2021-11-05 → 2025-10-02 | Test: 2025-10-07 → 2025-10-07 | Train_n=980 | Test_n=1\n",
      "Run 72/230 | Train: 2021-11-04 → 2025-10-01 | Test: 2025-10-06 → 2025-10-06 | Train_n=980 | Test_n=1\n",
      "Run 73/230 | Train: 2021-11-03 → 2025-09-30 | Test: 2025-10-03 → 2025-10-03 | Train_n=980 | Test_n=1\n",
      "Run 74/230 | Train: 2021-11-02 → 2025-09-29 | Test: 2025-10-02 → 2025-10-02 | Train_n=980 | Test_n=1\n",
      "Run 75/230 | Train: 2021-11-01 → 2025-09-26 | Test: 2025-10-01 → 2025-10-01 | Train_n=980 | Test_n=1\n",
      "Run 76/230 | Train: 2021-10-29 → 2025-09-25 | Test: 2025-09-30 → 2025-09-30 | Train_n=980 | Test_n=1\n",
      "Run 77/230 | Train: 2021-10-28 → 2025-09-24 | Test: 2025-09-29 → 2025-09-29 | Train_n=980 | Test_n=1\n",
      "Run 78/230 | Train: 2021-10-27 → 2025-09-23 | Test: 2025-09-26 → 2025-09-26 | Train_n=980 | Test_n=1\n",
      "Run 79/230 | Train: 2021-10-26 → 2025-09-22 | Test: 2025-09-25 → 2025-09-25 | Train_n=980 | Test_n=1\n",
      "Run 80/230 | Train: 2021-10-25 → 2025-09-19 | Test: 2025-09-24 → 2025-09-24 | Train_n=980 | Test_n=1\n",
      "Run 81/230 | Train: 2021-10-22 → 2025-09-18 | Test: 2025-09-23 → 2025-09-23 | Train_n=980 | Test_n=1\n",
      "Run 82/230 | Train: 2021-10-21 → 2025-09-17 | Test: 2025-09-22 → 2025-09-22 | Train_n=980 | Test_n=1\n",
      "Run 83/230 | Train: 2021-10-20 → 2025-09-16 | Test: 2025-09-19 → 2025-09-19 | Train_n=980 | Test_n=1\n",
      "Run 84/230 | Train: 2021-10-19 → 2025-09-15 | Test: 2025-09-18 → 2025-09-18 | Train_n=980 | Test_n=1\n",
      "Run 85/230 | Train: 2021-10-18 → 2025-09-12 | Test: 2025-09-17 → 2025-09-17 | Train_n=980 | Test_n=1\n",
      "Run 86/230 | Train: 2021-10-15 → 2025-09-11 | Test: 2025-09-16 → 2025-09-16 | Train_n=980 | Test_n=1\n",
      "Run 87/230 | Train: 2021-10-14 → 2025-09-10 | Test: 2025-09-15 → 2025-09-15 | Train_n=980 | Test_n=1\n",
      "Run 88/230 | Train: 2021-10-13 → 2025-09-09 | Test: 2025-09-12 → 2025-09-12 | Train_n=980 | Test_n=1\n",
      "Run 89/230 | Train: 2021-10-12 → 2025-09-08 | Test: 2025-09-11 → 2025-09-11 | Train_n=980 | Test_n=1\n",
      "Run 90/230 | Train: 2021-10-11 → 2025-09-05 | Test: 2025-09-10 → 2025-09-10 | Train_n=980 | Test_n=1\n",
      "Run 91/230 | Train: 2021-10-08 → 2025-09-04 | Test: 2025-09-09 → 2025-09-09 | Train_n=980 | Test_n=1\n",
      "Run 92/230 | Train: 2021-10-07 → 2025-09-03 | Test: 2025-09-08 → 2025-09-08 | Train_n=980 | Test_n=1\n",
      "Run 93/230 | Train: 2021-10-06 → 2025-09-02 | Test: 2025-09-05 → 2025-09-05 | Train_n=980 | Test_n=1\n",
      "Run 94/230 | Train: 2021-10-05 → 2025-08-29 | Test: 2025-09-04 → 2025-09-04 | Train_n=980 | Test_n=1\n",
      "Run 95/230 | Train: 2021-10-04 → 2025-08-28 | Test: 2025-09-03 → 2025-09-03 | Train_n=980 | Test_n=1\n",
      "Run 96/230 | Train: 2021-10-01 → 2025-08-27 | Test: 2025-09-02 → 2025-09-02 | Train_n=980 | Test_n=1\n",
      "Run 97/230 | Train: 2021-09-30 → 2025-08-26 | Test: 2025-08-29 → 2025-08-29 | Train_n=980 | Test_n=1\n",
      "Run 98/230 | Train: 2021-09-29 → 2025-08-25 | Test: 2025-08-28 → 2025-08-28 | Train_n=980 | Test_n=1\n",
      "Run 99/230 | Train: 2021-09-28 → 2025-08-22 | Test: 2025-08-27 → 2025-08-27 | Train_n=980 | Test_n=1\n",
      "Run 100/230 | Train: 2021-09-27 → 2025-08-21 | Test: 2025-08-26 → 2025-08-26 | Train_n=980 | Test_n=1\n",
      "Run 101/230 | Train: 2021-09-24 → 2025-08-20 | Test: 2025-08-25 → 2025-08-25 | Train_n=980 | Test_n=1\n",
      "Run 102/230 | Train: 2021-09-23 → 2025-08-19 | Test: 2025-08-22 → 2025-08-22 | Train_n=980 | Test_n=1\n",
      "Run 103/230 | Train: 2021-09-22 → 2025-08-18 | Test: 2025-08-21 → 2025-08-21 | Train_n=980 | Test_n=1\n",
      "Run 104/230 | Train: 2021-09-21 → 2025-08-15 | Test: 2025-08-20 → 2025-08-20 | Train_n=980 | Test_n=1\n",
      "Run 105/230 | Train: 2021-09-20 → 2025-08-14 | Test: 2025-08-19 → 2025-08-19 | Train_n=980 | Test_n=1\n",
      "Run 106/230 | Train: 2021-09-17 → 2025-08-13 | Test: 2025-08-18 → 2025-08-18 | Train_n=980 | Test_n=1\n",
      "Run 107/230 | Train: 2021-09-16 → 2025-08-12 | Test: 2025-08-15 → 2025-08-15 | Train_n=980 | Test_n=1\n",
      "Run 108/230 | Train: 2021-09-15 → 2025-08-11 | Test: 2025-08-14 → 2025-08-14 | Train_n=980 | Test_n=1\n",
      "Run 109/230 | Train: 2021-09-14 → 2025-08-08 | Test: 2025-08-13 → 2025-08-13 | Train_n=980 | Test_n=1\n",
      "Run 110/230 | Train: 2021-09-13 → 2025-08-07 | Test: 2025-08-12 → 2025-08-12 | Train_n=980 | Test_n=1\n",
      "Run 111/230 | Train: 2021-09-10 → 2025-08-06 | Test: 2025-08-11 → 2025-08-11 | Train_n=980 | Test_n=1\n",
      "Run 112/230 | Train: 2021-09-09 → 2025-08-05 | Test: 2025-08-08 → 2025-08-08 | Train_n=980 | Test_n=1\n",
      "Run 113/230 | Train: 2021-09-08 → 2025-08-04 | Test: 2025-08-07 → 2025-08-07 | Train_n=980 | Test_n=1\n",
      "Run 114/230 | Train: 2021-09-07 → 2025-08-01 | Test: 2025-08-06 → 2025-08-06 | Train_n=980 | Test_n=1\n",
      "Run 115/230 | Train: 2021-09-03 → 2025-07-31 | Test: 2025-08-05 → 2025-08-05 | Train_n=980 | Test_n=1\n",
      "Run 116/230 | Train: 2021-09-02 → 2025-07-30 | Test: 2025-08-04 → 2025-08-04 | Train_n=980 | Test_n=1\n",
      "Run 117/230 | Train: 2021-09-01 → 2025-07-29 | Test: 2025-08-01 → 2025-08-01 | Train_n=980 | Test_n=1\n",
      "Run 118/230 | Train: 2021-08-31 → 2025-07-28 | Test: 2025-07-31 → 2025-07-31 | Train_n=980 | Test_n=1\n",
      "Run 119/230 | Train: 2021-08-30 → 2025-07-25 | Test: 2025-07-30 → 2025-07-30 | Train_n=980 | Test_n=1\n",
      "Run 120/230 | Train: 2021-08-27 → 2025-07-24 | Test: 2025-07-29 → 2025-07-29 | Train_n=980 | Test_n=1\n",
      "Run 121/230 | Train: 2021-08-26 → 2025-07-23 | Test: 2025-07-28 → 2025-07-28 | Train_n=980 | Test_n=1\n",
      "Run 122/230 | Train: 2021-08-25 → 2025-07-22 | Test: 2025-07-25 → 2025-07-25 | Train_n=980 | Test_n=1\n",
      "Run 123/230 | Train: 2021-08-24 → 2025-07-21 | Test: 2025-07-24 → 2025-07-24 | Train_n=980 | Test_n=1\n",
      "Run 124/230 | Train: 2021-08-23 → 2025-07-18 | Test: 2025-07-23 → 2025-07-23 | Train_n=980 | Test_n=1\n",
      "Run 125/230 | Train: 2021-08-20 → 2025-07-17 | Test: 2025-07-22 → 2025-07-22 | Train_n=980 | Test_n=1\n",
      "Run 126/230 | Train: 2021-08-19 → 2025-07-16 | Test: 2025-07-21 → 2025-07-21 | Train_n=980 | Test_n=1\n",
      "Run 127/230 | Train: 2021-08-18 → 2025-07-15 | Test: 2025-07-18 → 2025-07-18 | Train_n=980 | Test_n=1\n",
      "Run 128/230 | Train: 2021-08-17 → 2025-07-14 | Test: 2025-07-17 → 2025-07-17 | Train_n=980 | Test_n=1\n",
      "Run 129/230 | Train: 2021-08-16 → 2025-07-11 | Test: 2025-07-16 → 2025-07-16 | Train_n=980 | Test_n=1\n",
      "Run 130/230 | Train: 2021-08-13 → 2025-07-10 | Test: 2025-07-15 → 2025-07-15 | Train_n=980 | Test_n=1\n",
      "Run 131/230 | Train: 2021-08-12 → 2025-07-09 | Test: 2025-07-14 → 2025-07-14 | Train_n=980 | Test_n=1\n",
      "Run 132/230 | Train: 2021-08-11 → 2025-07-08 | Test: 2025-07-11 → 2025-07-11 | Train_n=980 | Test_n=1\n",
      "Run 133/230 | Train: 2021-08-10 → 2025-07-07 | Test: 2025-07-10 → 2025-07-10 | Train_n=980 | Test_n=1\n",
      "Run 134/230 | Train: 2021-08-09 → 2025-07-03 | Test: 2025-07-09 → 2025-07-09 | Train_n=980 | Test_n=1\n",
      "Run 135/230 | Train: 2021-08-06 → 2025-07-02 | Test: 2025-07-08 → 2025-07-08 | Train_n=980 | Test_n=1\n",
      "Run 136/230 | Train: 2021-08-05 → 2025-07-01 | Test: 2025-07-07 → 2025-07-07 | Train_n=980 | Test_n=1\n",
      "Run 137/230 | Train: 2021-08-04 → 2025-06-30 | Test: 2025-07-03 → 2025-07-03 | Train_n=980 | Test_n=1\n",
      "Run 138/230 | Train: 2021-08-03 → 2025-06-27 | Test: 2025-07-02 → 2025-07-02 | Train_n=980 | Test_n=1\n",
      "Run 139/230 | Train: 2021-08-02 → 2025-06-26 | Test: 2025-07-01 → 2025-07-01 | Train_n=980 | Test_n=1\n",
      "Run 140/230 | Train: 2021-07-30 → 2025-06-25 | Test: 2025-06-30 → 2025-06-30 | Train_n=980 | Test_n=1\n",
      "Run 141/230 | Train: 2021-07-29 → 2025-06-24 | Test: 2025-06-27 → 2025-06-27 | Train_n=980 | Test_n=1\n",
      "Run 142/230 | Train: 2021-07-28 → 2025-06-23 | Test: 2025-06-26 → 2025-06-26 | Train_n=980 | Test_n=1\n",
      "Run 143/230 | Train: 2021-07-27 → 2025-06-20 | Test: 2025-06-25 → 2025-06-25 | Train_n=980 | Test_n=1\n",
      "Run 144/230 | Train: 2021-07-26 → 2025-06-18 | Test: 2025-06-24 → 2025-06-24 | Train_n=980 | Test_n=1\n",
      "Run 145/230 | Train: 2021-07-23 → 2025-06-17 | Test: 2025-06-23 → 2025-06-23 | Train_n=980 | Test_n=1\n",
      "Run 146/230 | Train: 2021-07-22 → 2025-06-16 | Test: 2025-06-20 → 2025-06-20 | Train_n=980 | Test_n=1\n",
      "Run 147/230 | Train: 2021-07-21 → 2025-06-13 | Test: 2025-06-18 → 2025-06-18 | Train_n=980 | Test_n=1\n",
      "Run 148/230 | Train: 2021-07-20 → 2025-06-12 | Test: 2025-06-17 → 2025-06-17 | Train_n=980 | Test_n=1\n",
      "Run 149/230 | Train: 2021-07-19 → 2025-06-11 | Test: 2025-06-16 → 2025-06-16 | Train_n=980 | Test_n=1\n",
      "Run 150/230 | Train: 2021-07-16 → 2025-06-10 | Test: 2025-06-13 → 2025-06-13 | Train_n=980 | Test_n=1\n",
      "Run 151/230 | Train: 2021-07-15 → 2025-06-09 | Test: 2025-06-12 → 2025-06-12 | Train_n=980 | Test_n=1\n",
      "Run 152/230 | Train: 2021-07-14 → 2025-06-06 | Test: 2025-06-11 → 2025-06-11 | Train_n=980 | Test_n=1\n",
      "Run 153/230 | Train: 2021-07-13 → 2025-06-05 | Test: 2025-06-10 → 2025-06-10 | Train_n=980 | Test_n=1\n",
      "Run 154/230 | Train: 2021-07-12 → 2025-06-04 | Test: 2025-06-09 → 2025-06-09 | Train_n=980 | Test_n=1\n",
      "Run 155/230 | Train: 2021-07-09 → 2025-06-03 | Test: 2025-06-06 → 2025-06-06 | Train_n=980 | Test_n=1\n",
      "Run 156/230 | Train: 2021-07-08 → 2025-06-02 | Test: 2025-06-05 → 2025-06-05 | Train_n=980 | Test_n=1\n",
      "Run 157/230 | Train: 2021-07-07 → 2025-05-30 | Test: 2025-06-04 → 2025-06-04 | Train_n=980 | Test_n=1\n",
      "Run 158/230 | Train: 2021-07-06 → 2025-05-29 | Test: 2025-06-03 → 2025-06-03 | Train_n=980 | Test_n=1\n",
      "Run 159/230 | Train: 2021-07-02 → 2025-05-28 | Test: 2025-06-02 → 2025-06-02 | Train_n=980 | Test_n=1\n",
      "Run 160/230 | Train: 2021-07-01 → 2025-05-27 | Test: 2025-05-30 → 2025-05-30 | Train_n=980 | Test_n=1\n",
      "Run 161/230 | Train: 2021-06-30 → 2025-05-23 | Test: 2025-05-29 → 2025-05-29 | Train_n=980 | Test_n=1\n",
      "Run 162/230 | Train: 2021-06-29 → 2025-05-22 | Test: 2025-05-28 → 2025-05-28 | Train_n=980 | Test_n=1\n",
      "Run 163/230 | Train: 2021-06-28 → 2025-05-21 | Test: 2025-05-27 → 2025-05-27 | Train_n=980 | Test_n=1\n",
      "Run 164/230 | Train: 2021-06-25 → 2025-05-20 | Test: 2025-05-23 → 2025-05-23 | Train_n=980 | Test_n=1\n",
      "Run 165/230 | Train: 2021-06-24 → 2025-05-19 | Test: 2025-05-22 → 2025-05-22 | Train_n=980 | Test_n=1\n",
      "Run 166/230 | Train: 2021-06-23 → 2025-05-16 | Test: 2025-05-21 → 2025-05-21 | Train_n=980 | Test_n=1\n",
      "Run 167/230 | Train: 2021-06-22 → 2025-05-15 | Test: 2025-05-20 → 2025-05-20 | Train_n=980 | Test_n=1\n",
      "Run 168/230 | Train: 2021-06-21 → 2025-05-14 | Test: 2025-05-19 → 2025-05-19 | Train_n=980 | Test_n=1\n",
      "Run 169/230 | Train: 2021-06-18 → 2025-05-13 | Test: 2025-05-16 → 2025-05-16 | Train_n=980 | Test_n=1\n",
      "Run 170/230 | Train: 2021-06-17 → 2025-05-12 | Test: 2025-05-15 → 2025-05-15 | Train_n=980 | Test_n=1\n",
      "Run 171/230 | Train: 2021-06-16 → 2025-05-09 | Test: 2025-05-14 → 2025-05-14 | Train_n=980 | Test_n=1\n",
      "Run 172/230 | Train: 2021-06-15 → 2025-05-08 | Test: 2025-05-13 → 2025-05-13 | Train_n=980 | Test_n=1\n",
      "Run 173/230 | Train: 2021-06-14 → 2025-05-07 | Test: 2025-05-12 → 2025-05-12 | Train_n=980 | Test_n=1\n",
      "Run 174/230 | Train: 2021-06-11 → 2025-05-06 | Test: 2025-05-09 → 2025-05-09 | Train_n=980 | Test_n=1\n",
      "Run 175/230 | Train: 2021-06-10 → 2025-05-05 | Test: 2025-05-08 → 2025-05-08 | Train_n=980 | Test_n=1\n",
      "Run 176/230 | Train: 2021-06-09 → 2025-05-02 | Test: 2025-05-07 → 2025-05-07 | Train_n=980 | Test_n=1\n",
      "Run 177/230 | Train: 2021-06-08 → 2025-05-01 | Test: 2025-05-06 → 2025-05-06 | Train_n=980 | Test_n=1\n",
      "Run 178/230 | Train: 2021-06-07 → 2025-04-30 | Test: 2025-05-05 → 2025-05-05 | Train_n=980 | Test_n=1\n",
      "Run 179/230 | Train: 2021-06-04 → 2025-04-29 | Test: 2025-05-02 → 2025-05-02 | Train_n=980 | Test_n=1\n",
      "Run 180/230 | Train: 2021-06-03 → 2025-04-28 | Test: 2025-05-01 → 2025-05-01 | Train_n=980 | Test_n=1\n",
      "Run 181/230 | Train: 2021-06-02 → 2025-04-25 | Test: 2025-04-30 → 2025-04-30 | Train_n=980 | Test_n=1\n",
      "Run 182/230 | Train: 2021-06-01 → 2025-04-24 | Test: 2025-04-29 → 2025-04-29 | Train_n=980 | Test_n=1\n",
      "Run 183/230 | Train: 2021-05-28 → 2025-04-23 | Test: 2025-04-28 → 2025-04-28 | Train_n=980 | Test_n=1\n",
      "Run 184/230 | Train: 2021-05-27 → 2025-04-22 | Test: 2025-04-25 → 2025-04-25 | Train_n=980 | Test_n=1\n",
      "Run 185/230 | Train: 2021-05-26 → 2025-04-21 | Test: 2025-04-24 → 2025-04-24 | Train_n=980 | Test_n=1\n",
      "Run 186/230 | Train: 2021-05-25 → 2025-04-17 | Test: 2025-04-23 → 2025-04-23 | Train_n=980 | Test_n=1\n",
      "Run 187/230 | Train: 2021-05-24 → 2025-04-16 | Test: 2025-04-22 → 2025-04-22 | Train_n=980 | Test_n=1\n",
      "Run 188/230 | Train: 2021-05-21 → 2025-04-15 | Test: 2025-04-21 → 2025-04-21 | Train_n=980 | Test_n=1\n",
      "Run 189/230 | Train: 2021-05-20 → 2025-04-14 | Test: 2025-04-17 → 2025-04-17 | Train_n=980 | Test_n=1\n",
      "Run 190/230 | Train: 2021-05-19 → 2025-04-11 | Test: 2025-04-16 → 2025-04-16 | Train_n=980 | Test_n=1\n",
      "Run 191/230 | Train: 2021-05-18 → 2025-04-10 | Test: 2025-04-15 → 2025-04-15 | Train_n=980 | Test_n=1\n",
      "Run 192/230 | Train: 2021-05-17 → 2025-04-09 | Test: 2025-04-14 → 2025-04-14 | Train_n=980 | Test_n=1\n",
      "Run 193/230 | Train: 2021-05-14 → 2025-04-08 | Test: 2025-04-11 → 2025-04-11 | Train_n=980 | Test_n=1\n",
      "Run 194/230 | Train: 2021-05-13 → 2025-04-07 | Test: 2025-04-10 → 2025-04-10 | Train_n=980 | Test_n=1\n",
      "Run 195/230 | Train: 2021-05-12 → 2025-04-04 | Test: 2025-04-09 → 2025-04-09 | Train_n=980 | Test_n=1\n",
      "Run 196/230 | Train: 2021-05-11 → 2025-04-03 | Test: 2025-04-08 → 2025-04-08 | Train_n=980 | Test_n=1\n",
      "Run 197/230 | Train: 2021-05-10 → 2025-04-02 | Test: 2025-04-07 → 2025-04-07 | Train_n=980 | Test_n=1\n",
      "Run 198/230 | Train: 2021-05-07 → 2025-04-01 | Test: 2025-04-04 → 2025-04-04 | Train_n=980 | Test_n=1\n",
      "Run 199/230 | Train: 2021-05-06 → 2025-03-31 | Test: 2025-04-03 → 2025-04-03 | Train_n=980 | Test_n=1\n",
      "Run 200/230 | Train: 2021-05-05 → 2025-03-28 | Test: 2025-04-02 → 2025-04-02 | Train_n=980 | Test_n=1\n",
      "Run 201/230 | Train: 2021-05-04 → 2025-03-27 | Test: 2025-04-01 → 2025-04-01 | Train_n=980 | Test_n=1\n",
      "Run 202/230 | Train: 2021-05-03 → 2025-03-26 | Test: 2025-03-31 → 2025-03-31 | Train_n=980 | Test_n=1\n",
      "Run 203/230 | Train: 2021-04-30 → 2025-03-25 | Test: 2025-03-28 → 2025-03-28 | Train_n=980 | Test_n=1\n",
      "Run 204/230 | Train: 2021-04-29 → 2025-03-24 | Test: 2025-03-27 → 2025-03-27 | Train_n=980 | Test_n=1\n",
      "Run 205/230 | Train: 2021-04-28 → 2025-03-21 | Test: 2025-03-26 → 2025-03-26 | Train_n=980 | Test_n=1\n",
      "Run 206/230 | Train: 2021-04-27 → 2025-03-20 | Test: 2025-03-25 → 2025-03-25 | Train_n=980 | Test_n=1\n",
      "Run 207/230 | Train: 2021-04-26 → 2025-03-19 | Test: 2025-03-24 → 2025-03-24 | Train_n=980 | Test_n=1\n",
      "Run 208/230 | Train: 2021-04-23 → 2025-03-18 | Test: 2025-03-21 → 2025-03-21 | Train_n=980 | Test_n=1\n",
      "Run 209/230 | Train: 2021-04-22 → 2025-03-17 | Test: 2025-03-20 → 2025-03-20 | Train_n=980 | Test_n=1\n",
      "Run 210/230 | Train: 2021-04-21 → 2025-03-14 | Test: 2025-03-19 → 2025-03-19 | Train_n=980 | Test_n=1\n",
      "Run 211/230 | Train: 2021-04-20 → 2025-03-13 | Test: 2025-03-18 → 2025-03-18 | Train_n=980 | Test_n=1\n",
      "Run 212/230 | Train: 2021-04-19 → 2025-03-12 | Test: 2025-03-17 → 2025-03-17 | Train_n=980 | Test_n=1\n",
      "Run 213/230 | Train: 2021-04-16 → 2025-03-11 | Test: 2025-03-14 → 2025-03-14 | Train_n=980 | Test_n=1\n",
      "Run 214/230 | Train: 2021-04-15 → 2025-03-10 | Test: 2025-03-13 → 2025-03-13 | Train_n=980 | Test_n=1\n",
      "Run 215/230 | Train: 2021-04-14 → 2025-03-07 | Test: 2025-03-12 → 2025-03-12 | Train_n=980 | Test_n=1\n",
      "Run 216/230 | Train: 2021-04-13 → 2025-03-06 | Test: 2025-03-11 → 2025-03-11 | Train_n=980 | Test_n=1\n",
      "Run 217/230 | Train: 2021-04-12 → 2025-03-05 | Test: 2025-03-10 → 2025-03-10 | Train_n=980 | Test_n=1\n",
      "Run 218/230 | Train: 2021-04-09 → 2025-03-04 | Test: 2025-03-07 → 2025-03-07 | Train_n=980 | Test_n=1\n",
      "Run 219/230 | Train: 2021-04-08 → 2025-03-03 | Test: 2025-03-06 → 2025-03-06 | Train_n=980 | Test_n=1\n",
      "Run 220/230 | Train: 2021-04-07 → 2025-02-28 | Test: 2025-03-05 → 2025-03-05 | Train_n=980 | Test_n=1\n",
      "Run 221/230 | Train: 2021-04-06 → 2025-02-27 | Test: 2025-03-04 → 2025-03-04 | Train_n=980 | Test_n=1\n",
      "Run 222/230 | Train: 2021-04-05 → 2025-02-26 | Test: 2025-03-03 → 2025-03-03 | Train_n=980 | Test_n=1\n",
      "Run 223/230 | Train: 2021-04-01 → 2025-02-25 | Test: 2025-02-28 → 2025-02-28 | Train_n=980 | Test_n=1\n",
      "Run 224/230 | Train: 2021-03-31 → 2025-02-24 | Test: 2025-02-27 → 2025-02-27 | Train_n=980 | Test_n=1\n",
      "Run 225/230 | Train: 2021-03-30 → 2025-02-21 | Test: 2025-02-26 → 2025-02-26 | Train_n=980 | Test_n=1\n",
      "Run 226/230 | Train: 2021-03-29 → 2025-02-20 | Test: 2025-02-25 → 2025-02-25 | Train_n=980 | Test_n=1\n",
      "Run 227/230 | Train: 2021-03-26 → 2025-02-19 | Test: 2025-02-24 → 2025-02-24 | Train_n=980 | Test_n=1\n",
      "Run 228/230 | Train: 2021-03-25 → 2025-02-18 | Test: 2025-02-21 → 2025-02-21 | Train_n=980 | Test_n=1\n",
      "Run 229/230 | Train: 2021-03-24 → 2025-02-14 | Test: 2025-02-20 → 2025-02-20 | Train_n=980 | Test_n=1\n",
      "Run 230/230 | Train: 2021-03-23 → 2025-02-13 | Test: 2025-02-19 → 2025-02-19 | Train_n=980 | Test_n=1\n",
      "Ran permutation importance | Len: 918 | Old: 130 | New: 9\n",
      "Run 1/230 | Train: 2021-02-19 → 2026-01-05 | Test: 2026-01-13 → 2026-01-13 | Train_n=1225 | Test_n=1\n",
      "Run 2/230 | Train: 2021-02-18 → 2026-01-02 | Test: 2026-01-12 → 2026-01-12 | Train_n=1225 | Test_n=1\n",
      "Run 3/230 | Train: 2021-02-17 → 2025-12-31 | Test: 2026-01-09 → 2026-01-09 | Train_n=1225 | Test_n=1\n",
      "Run 4/230 | Train: 2021-02-16 → 2025-12-30 | Test: 2026-01-08 → 2026-01-08 | Train_n=1225 | Test_n=1\n",
      "Run 5/230 | Train: 2021-02-12 → 2025-12-29 | Test: 2026-01-07 → 2026-01-07 | Train_n=1225 | Test_n=1\n",
      "Run 6/230 | Train: 2021-02-11 → 2025-12-26 | Test: 2026-01-06 → 2026-01-06 | Train_n=1225 | Test_n=1\n",
      "Run 7/230 | Train: 2021-02-10 → 2025-12-24 | Test: 2026-01-05 → 2026-01-05 | Train_n=1225 | Test_n=1\n",
      "Run 8/230 | Train: 2021-02-09 → 2025-12-23 | Test: 2026-01-02 → 2026-01-02 | Train_n=1225 | Test_n=1\n",
      "Run 9/230 | Train: 2021-02-08 → 2025-12-22 | Test: 2025-12-31 → 2025-12-31 | Train_n=1225 | Test_n=1\n",
      "Run 10/230 | Train: 2021-02-05 → 2025-12-19 | Test: 2025-12-30 → 2025-12-30 | Train_n=1225 | Test_n=1\n",
      "Run 11/230 | Train: 2021-02-04 → 2025-12-18 | Test: 2025-12-29 → 2025-12-29 | Train_n=1225 | Test_n=1\n",
      "Run 12/230 | Train: 2021-02-03 → 2025-12-17 | Test: 2025-12-26 → 2025-12-26 | Train_n=1225 | Test_n=1\n",
      "Run 13/230 | Train: 2021-02-02 → 2025-12-16 | Test: 2025-12-24 → 2025-12-24 | Train_n=1225 | Test_n=1\n",
      "Run 14/230 | Train: 2021-02-01 → 2025-12-15 | Test: 2025-12-23 → 2025-12-23 | Train_n=1225 | Test_n=1\n",
      "Run 15/230 | Train: 2021-01-29 → 2025-12-12 | Test: 2025-12-22 → 2025-12-22 | Train_n=1225 | Test_n=1\n",
      "Run 16/230 | Train: 2021-01-28 → 2025-12-11 | Test: 2025-12-19 → 2025-12-19 | Train_n=1225 | Test_n=1\n",
      "Run 17/230 | Train: 2021-01-27 → 2025-12-10 | Test: 2025-12-18 → 2025-12-18 | Train_n=1225 | Test_n=1\n",
      "Run 18/230 | Train: 2021-01-26 → 2025-12-09 | Test: 2025-12-17 → 2025-12-17 | Train_n=1225 | Test_n=1\n",
      "Run 19/230 | Train: 2021-01-25 → 2025-12-08 | Test: 2025-12-16 → 2025-12-16 | Train_n=1225 | Test_n=1\n",
      "Run 20/230 | Train: 2021-01-22 → 2025-12-05 | Test: 2025-12-15 → 2025-12-15 | Train_n=1225 | Test_n=1\n",
      "Run 21/230 | Train: 2021-01-21 → 2025-12-04 | Test: 2025-12-12 → 2025-12-12 | Train_n=1225 | Test_n=1\n",
      "Run 22/230 | Train: 2021-01-20 → 2025-12-03 | Test: 2025-12-11 → 2025-12-11 | Train_n=1225 | Test_n=1\n",
      "Run 23/230 | Train: 2021-01-19 → 2025-12-02 | Test: 2025-12-10 → 2025-12-10 | Train_n=1225 | Test_n=1\n",
      "Run 24/230 | Train: 2021-01-15 → 2025-12-01 | Test: 2025-12-09 → 2025-12-09 | Train_n=1225 | Test_n=1\n",
      "Run 25/230 | Train: 2021-01-14 → 2025-11-28 | Test: 2025-12-08 → 2025-12-08 | Train_n=1225 | Test_n=1\n",
      "Run 26/230 | Train: 2021-01-13 → 2025-11-26 | Test: 2025-12-05 → 2025-12-05 | Train_n=1225 | Test_n=1\n",
      "Run 27/230 | Train: 2021-01-12 → 2025-11-25 | Test: 2025-12-04 → 2025-12-04 | Train_n=1225 | Test_n=1\n",
      "Run 28/230 | Train: 2021-01-11 → 2025-11-24 | Test: 2025-12-03 → 2025-12-03 | Train_n=1225 | Test_n=1\n",
      "Run 29/230 | Train: 2021-01-08 → 2025-11-21 | Test: 2025-12-02 → 2025-12-02 | Train_n=1225 | Test_n=1\n",
      "Run 30/230 | Train: 2021-01-07 → 2025-11-20 | Test: 2025-12-01 → 2025-12-01 | Train_n=1225 | Test_n=1\n",
      "Run 31/230 | Train: 2021-01-06 → 2025-11-19 | Test: 2025-11-28 → 2025-11-28 | Train_n=1225 | Test_n=1\n",
      "Run 32/230 | Train: 2021-01-05 → 2025-11-18 | Test: 2025-11-26 → 2025-11-26 | Train_n=1225 | Test_n=1\n",
      "Run 33/230 | Train: 2021-01-04 → 2025-11-17 | Test: 2025-11-25 → 2025-11-25 | Train_n=1225 | Test_n=1\n",
      "Run 34/230 | Train: 2020-12-31 → 2025-11-14 | Test: 2025-11-24 → 2025-11-24 | Train_n=1225 | Test_n=1\n",
      "Run 35/230 | Train: 2020-12-30 → 2025-11-13 | Test: 2025-11-21 → 2025-11-21 | Train_n=1225 | Test_n=1\n",
      "Run 36/230 | Train: 2020-12-29 → 2025-11-12 | Test: 2025-11-20 → 2025-11-20 | Train_n=1225 | Test_n=1\n",
      "Run 37/230 | Train: 2020-12-28 → 2025-11-11 | Test: 2025-11-19 → 2025-11-19 | Train_n=1225 | Test_n=1\n",
      "Run 38/230 | Train: 2020-12-24 → 2025-11-10 | Test: 2025-11-18 → 2025-11-18 | Train_n=1225 | Test_n=1\n",
      "Run 39/230 | Train: 2020-12-23 → 2025-11-07 | Test: 2025-11-17 → 2025-11-17 | Train_n=1225 | Test_n=1\n",
      "Run 40/230 | Train: 2020-12-22 → 2025-11-06 | Test: 2025-11-14 → 2025-11-14 | Train_n=1225 | Test_n=1\n",
      "Run 41/230 | Train: 2020-12-21 → 2025-11-05 | Test: 2025-11-13 → 2025-11-13 | Train_n=1225 | Test_n=1\n",
      "Run 42/230 | Train: 2020-12-18 → 2025-11-04 | Test: 2025-11-12 → 2025-11-12 | Train_n=1225 | Test_n=1\n",
      "Run 43/230 | Train: 2020-12-17 → 2025-11-03 | Test: 2025-11-11 → 2025-11-11 | Train_n=1225 | Test_n=1\n",
      "Run 44/230 | Train: 2020-12-16 → 2025-10-31 | Test: 2025-11-10 → 2025-11-10 | Train_n=1225 | Test_n=1\n",
      "Run 45/230 | Train: 2020-12-15 → 2025-10-30 | Test: 2025-11-07 → 2025-11-07 | Train_n=1225 | Test_n=1\n",
      "Run 46/230 | Train: 2020-12-14 → 2025-10-29 | Test: 2025-11-06 → 2025-11-06 | Train_n=1225 | Test_n=1\n",
      "Run 47/230 | Train: 2020-12-11 → 2025-10-28 | Test: 2025-11-05 → 2025-11-05 | Train_n=1225 | Test_n=1\n",
      "Run 48/230 | Train: 2020-12-10 → 2025-10-27 | Test: 2025-11-04 → 2025-11-04 | Train_n=1225 | Test_n=1\n",
      "Run 49/230 | Train: 2020-12-09 → 2025-10-24 | Test: 2025-11-03 → 2025-11-03 | Train_n=1225 | Test_n=1\n",
      "Run 50/230 | Train: 2020-12-08 → 2025-10-23 | Test: 2025-10-31 → 2025-10-31 | Train_n=1225 | Test_n=1\n",
      "Run 51/230 | Train: 2020-12-07 → 2025-10-22 | Test: 2025-10-30 → 2025-10-30 | Train_n=1225 | Test_n=1\n",
      "Run 52/230 | Train: 2020-12-04 → 2025-10-21 | Test: 2025-10-29 → 2025-10-29 | Train_n=1225 | Test_n=1\n",
      "Run 53/230 | Train: 2020-12-03 → 2025-10-20 | Test: 2025-10-28 → 2025-10-28 | Train_n=1225 | Test_n=1\n",
      "Run 54/230 | Train: 2020-12-02 → 2025-10-17 | Test: 2025-10-27 → 2025-10-27 | Train_n=1225 | Test_n=1\n",
      "Run 55/230 | Train: 2020-12-01 → 2025-10-16 | Test: 2025-10-24 → 2025-10-24 | Train_n=1225 | Test_n=1\n",
      "Run 56/230 | Train: 2020-11-30 → 2025-10-15 | Test: 2025-10-23 → 2025-10-23 | Train_n=1225 | Test_n=1\n",
      "Run 57/230 | Train: 2020-11-27 → 2025-10-14 | Test: 2025-10-22 → 2025-10-22 | Train_n=1225 | Test_n=1\n",
      "Run 58/230 | Train: 2020-11-25 → 2025-10-13 | Test: 2025-10-21 → 2025-10-21 | Train_n=1225 | Test_n=1\n",
      "Run 59/230 | Train: 2020-11-24 → 2025-10-10 | Test: 2025-10-20 → 2025-10-20 | Train_n=1225 | Test_n=1\n",
      "Run 60/230 | Train: 2020-11-23 → 2025-10-09 | Test: 2025-10-17 → 2025-10-17 | Train_n=1225 | Test_n=1\n",
      "Run 61/230 | Train: 2020-11-20 → 2025-10-08 | Test: 2025-10-16 → 2025-10-16 | Train_n=1225 | Test_n=1\n",
      "Run 62/230 | Train: 2020-11-19 → 2025-10-07 | Test: 2025-10-15 → 2025-10-15 | Train_n=1225 | Test_n=1\n",
      "Run 63/230 | Train: 2020-11-18 → 2025-10-06 | Test: 2025-10-14 → 2025-10-14 | Train_n=1225 | Test_n=1\n",
      "Run 64/230 | Train: 2020-11-17 → 2025-10-03 | Test: 2025-10-13 → 2025-10-13 | Train_n=1225 | Test_n=1\n",
      "Run 65/230 | Train: 2020-11-16 → 2025-10-02 | Test: 2025-10-10 → 2025-10-10 | Train_n=1225 | Test_n=1\n",
      "Run 66/230 | Train: 2020-11-13 → 2025-10-01 | Test: 2025-10-09 → 2025-10-09 | Train_n=1225 | Test_n=1\n",
      "Run 67/230 | Train: 2020-11-12 → 2025-09-30 | Test: 2025-10-08 → 2025-10-08 | Train_n=1225 | Test_n=1\n",
      "Run 68/230 | Train: 2020-11-11 → 2025-09-29 | Test: 2025-10-07 → 2025-10-07 | Train_n=1225 | Test_n=1\n",
      "Run 69/230 | Train: 2020-11-10 → 2025-09-26 | Test: 2025-10-06 → 2025-10-06 | Train_n=1225 | Test_n=1\n",
      "Run 70/230 | Train: 2020-11-09 → 2025-09-25 | Test: 2025-10-03 → 2025-10-03 | Train_n=1225 | Test_n=1\n",
      "Run 71/230 | Train: 2020-11-06 → 2025-09-24 | Test: 2025-10-02 → 2025-10-02 | Train_n=1225 | Test_n=1\n",
      "Run 72/230 | Train: 2020-11-05 → 2025-09-23 | Test: 2025-10-01 → 2025-10-01 | Train_n=1225 | Test_n=1\n",
      "Run 73/230 | Train: 2020-11-04 → 2025-09-22 | Test: 2025-09-30 → 2025-09-30 | Train_n=1225 | Test_n=1\n",
      "Run 74/230 | Train: 2020-11-03 → 2025-09-19 | Test: 2025-09-29 → 2025-09-29 | Train_n=1225 | Test_n=1\n",
      "Run 75/230 | Train: 2020-11-02 → 2025-09-18 | Test: 2025-09-26 → 2025-09-26 | Train_n=1225 | Test_n=1\n",
      "Run 76/230 | Train: 2020-10-30 → 2025-09-17 | Test: 2025-09-25 → 2025-09-25 | Train_n=1225 | Test_n=1\n",
      "Run 77/230 | Train: 2020-10-29 → 2025-09-16 | Test: 2025-09-24 → 2025-09-24 | Train_n=1225 | Test_n=1\n",
      "Run 78/230 | Train: 2020-10-28 → 2025-09-15 | Test: 2025-09-23 → 2025-09-23 | Train_n=1225 | Test_n=1\n",
      "Run 79/230 | Train: 2020-10-27 → 2025-09-12 | Test: 2025-09-22 → 2025-09-22 | Train_n=1225 | Test_n=1\n",
      "Run 80/230 | Train: 2020-10-26 → 2025-09-11 | Test: 2025-09-19 → 2025-09-19 | Train_n=1225 | Test_n=1\n",
      "Run 81/230 | Train: 2020-10-23 → 2025-09-10 | Test: 2025-09-18 → 2025-09-18 | Train_n=1225 | Test_n=1\n",
      "Run 82/230 | Train: 2020-10-22 → 2025-09-09 | Test: 2025-09-17 → 2025-09-17 | Train_n=1225 | Test_n=1\n",
      "Run 83/230 | Train: 2020-10-21 → 2025-09-08 | Test: 2025-09-16 → 2025-09-16 | Train_n=1225 | Test_n=1\n",
      "Run 84/230 | Train: 2020-10-20 → 2025-09-05 | Test: 2025-09-15 → 2025-09-15 | Train_n=1225 | Test_n=1\n",
      "Run 85/230 | Train: 2020-10-19 → 2025-09-04 | Test: 2025-09-12 → 2025-09-12 | Train_n=1225 | Test_n=1\n",
      "Run 86/230 | Train: 2020-10-16 → 2025-09-03 | Test: 2025-09-11 → 2025-09-11 | Train_n=1225 | Test_n=1\n",
      "Run 87/230 | Train: 2020-10-15 → 2025-09-02 | Test: 2025-09-10 → 2025-09-10 | Train_n=1225 | Test_n=1\n",
      "Run 88/230 | Train: 2020-10-14 → 2025-08-29 | Test: 2025-09-09 → 2025-09-09 | Train_n=1225 | Test_n=1\n",
      "Run 89/230 | Train: 2020-10-13 → 2025-08-28 | Test: 2025-09-08 → 2025-09-08 | Train_n=1225 | Test_n=1\n",
      "Run 90/230 | Train: 2020-10-12 → 2025-08-27 | Test: 2025-09-05 → 2025-09-05 | Train_n=1225 | Test_n=1\n",
      "Run 91/230 | Train: 2020-10-09 → 2025-08-26 | Test: 2025-09-04 → 2025-09-04 | Train_n=1225 | Test_n=1\n",
      "Run 92/230 | Train: 2020-10-08 → 2025-08-25 | Test: 2025-09-03 → 2025-09-03 | Train_n=1225 | Test_n=1\n",
      "Run 93/230 | Train: 2020-10-07 → 2025-08-22 | Test: 2025-09-02 → 2025-09-02 | Train_n=1225 | Test_n=1\n",
      "Run 94/230 | Train: 2020-10-06 → 2025-08-21 | Test: 2025-08-29 → 2025-08-29 | Train_n=1225 | Test_n=1\n",
      "Run 95/230 | Train: 2020-10-05 → 2025-08-20 | Test: 2025-08-28 → 2025-08-28 | Train_n=1225 | Test_n=1\n",
      "Run 96/230 | Train: 2020-10-02 → 2025-08-19 | Test: 2025-08-27 → 2025-08-27 | Train_n=1225 | Test_n=1\n",
      "Run 97/230 | Train: 2020-10-01 → 2025-08-18 | Test: 2025-08-26 → 2025-08-26 | Train_n=1225 | Test_n=1\n",
      "Run 98/230 | Train: 2020-09-30 → 2025-08-15 | Test: 2025-08-25 → 2025-08-25 | Train_n=1225 | Test_n=1\n",
      "Run 99/230 | Train: 2020-09-29 → 2025-08-14 | Test: 2025-08-22 → 2025-08-22 | Train_n=1225 | Test_n=1\n",
      "Run 100/230 | Train: 2020-09-28 → 2025-08-13 | Test: 2025-08-21 → 2025-08-21 | Train_n=1225 | Test_n=1\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Feature Sets\n",
    "# -----------------------------\n",
    "ma_all_cols = feature_sets['ma']\n",
    "ma_lag = [c for c in ma_all_cols if \"lag\" in c.lower()]\n",
    "ma_rel = [c for c in ma_all_cols if \"rel_\" in c.lower()]\n",
    "ma_sma = [c for c in ma_all_cols if (\"sma_\" in c.lower()) and (\"lag\" not in c.lower())]\n",
    "ma_num = [c for c in ma_all_cols if (\"num\" in c.lower()) or (\"since\" in c.lower())]\n",
    "rsi_cols = feature_sets['rsi']\n",
    "macd_cols = feature_sets['macd']\n",
    "volu_cols = feature_sets['volume']\n",
    "atr_adx_cols = feature_sets['atr_adx']\n",
    "vola_cols = feature_sets['volatility']\n",
    "vix_skew_cols = feature_sets['vix_skew']\n",
    "experimental_slope_cols = feature_sets['experimental_slope']\n",
    "\n",
    "sets = [ma_lag, ma_rel, ma_sma, ma_num, rsi_cols + macd_cols, volu_cols, atr_adx_cols + vola_cols, vix_skew_cols, experimental_slope_cols]\n",
    "set_names = [\"ma_lag\", \"ma_rel\", \"ma_sma\", \"ma_num\", \"rsi_macd\", \"volu\", \"atr_adx\" + \"vola\", \"vix_skew\", \"experimental_slope\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Models\n",
    "# -----------------------------\n",
    "models = {\n",
    "    #\"xgboost-4\": XGBClassifier(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    #\"xgboost-6\": XGBClassifier(n_estimators=600, random_state=42, n_jobs=-1),\n",
    "    \"xgb_first_pass\": XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=5,\n",
    "    min_child_weight=10,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    gamma=0.3,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=15,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "}\n",
    "\n",
    "models = {\n",
    "    #\"xgboost-4\": XGBClassifier(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    \"xgboost-6\": XGBClassifier(n_estimators=600, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def _compute_dist(y):\n",
    "    \"\"\"Distribution stats for y in {0,1}.\"\"\"\n",
    "    n = int(len(y))\n",
    "    n_pos = int((y == 1).sum())\n",
    "    n_neg = int((y == 0).sum())\n",
    "    return {\n",
    "        \"test_n\": n,\n",
    "        \"test_pos_n\": n_pos,\n",
    "        \"test_neg_n\": n_neg,\n",
    "        \"test_pos_frac\": (n_pos / n) if n else np.nan,\n",
    "        \"test_neg_frac\": (n_neg / n) if n else np.nan,\n",
    "    }\n",
    "\n",
    "def walkback_runs(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    *,\n",
    "    date_col=\"Date\",\n",
    "    train_years=6,\n",
    "    test_days=5,\n",
    "    step_days=5,\n",
    "    runs=20,\n",
    "    horizon_days=1,        # r (used for purge)\n",
    "    purge_days=None,       # defaults to horizon_days\n",
    "    fill_inf=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Deployment-aligned evaluation:\n",
    "      - For each run, take a 5-day OOT test window stepping back by 5 days.\n",
    "      - Train on the prior N years (fixed-length window) ending right before test.\n",
    "      - Purge 'purge_days' from the end of train to avoid overlap leakage for forward-return labels.\n",
    "      - Score ONLY on the OOT test window (distribution + metrics).\n",
    "    Returns: long DataFrame with one row per (feature_set/run/model).\n",
    "    \"\"\"\n",
    "    dfw = df.sort_values(\"Date\").reset_index(drop=True).copy()\n",
    "\n",
    "    # Drop any accidental return cols from features (belt+suspenders)\n",
    "    safe_feature_cols = [c for c in feature_cols if \"Return\" not in c]\n",
    "\n",
    "    # Basic numeric cleaning\n",
    "    dfw[safe_feature_cols] = dfw[safe_feature_cols].replace([np.inf, -np.inf], fill_inf)\n",
    "\n",
    "    n = len(dfw)\n",
    "    train_size = 245 * int(train_years)\n",
    "    test_size = int(test_days)\n",
    "    step = int(step_days)\n",
    "    purge = int(purge_days) if purge_days is not None else 0 #int(horizon_days)\n",
    "\n",
    "    X_all = dfw[safe_feature_cols].to_numpy()\n",
    "    #y_all = _to_binary(dfw[target_col].to_numpy())\n",
    "    y_all = dfw[target_col].to_numpy()\n",
    "    dates = dfw[date_col].to_numpy() if date_col in dfw.columns else None\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for k in range(runs):\n",
    "        test_end = n - k * step\n",
    "        test_start = test_end - test_size\n",
    "        if test_start < 0:\n",
    "            break\n",
    "\n",
    "        train_end = test_start - purge\n",
    "        train_start = train_end - train_size\n",
    "        if train_start < 0 or train_end <= train_start:\n",
    "            break\n",
    "\n",
    "        print(\n",
    "            f\"Run {k+1}/{runs} | \"\n",
    "            f\"Train: {dates[train_start]} → {dates[train_end-1]} | \"\n",
    "            f\"Test: {dates[test_start]} → {dates[test_end-1]} | \"\n",
    "            f\"Train_n={train_end-train_start} | Test_n={test_end-test_start}\"\n",
    "        )\n",
    "\n",
    "        X_train = X_all[train_start:train_end]\n",
    "        y_train = y_all[train_start:train_end]\n",
    "        X_test  = X_all[test_start:test_end]\n",
    "        y_test  = y_all[test_start:test_end]\n",
    "\n",
    "        dist = _compute_dist(y_test)\n",
    "        single_class_test = (np.unique(y_test).size < 2)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            #start_time = time.time()\n",
    "            m = clone(model)\n",
    "            m.fit(X_train, y_train)\n",
    "\n",
    "            preds = m.predict(X_test)\n",
    "            proba = np.nan\n",
    "            if hasattr(m, \"predict_proba\"):\n",
    "                proba = float(m.predict_proba(X_test)[0, 1])   # prob(class=1)\n",
    "            elif hasattr(m, \"decision_function\"):\n",
    "                s = float(m.decision_function(X_test)[0])\n",
    "                proba = float(1.0 / (1.0 + np.exp(-s)))        # squash to (0,1)\n",
    "            proba = np.nan if np.isnan(proba) else round(round(proba / 0.05) * 0.05, 2)\n",
    "\n",
    "\n",
    "\n",
    "            rows.append({\n",
    "                \"run\": k + 1,\n",
    "                \"model\": model_name,\n",
    "                \"test_days\": test_days,\n",
    "                \"pred\": round(proba,2),\n",
    "\n",
    "                # core metrics\n",
    "                #\"bal_acc\": float(balanced_accuracy_score(y_test, preds)),\n",
    "                \"acc\": float(accuracy_score(y_test, preds)),\n",
    "                #\"sign_acc\": 2 * float(accuracy_score(y_test, preds)) - 1,\n",
    "                #\"mcc\": float(matthews_corrcoef(y_test, preds)),\n",
    "\n",
    "                # only meaningful if test has both classes\n",
    "                #\"f1\": np.nan if single_class_test else float(f1_score(y_test, preds, zero_division=0)),\n",
    "                #\"precision\": np.nan if single_class_test else float(precision_score(y_test, preds, zero_division=0)),\n",
    "                #\"recall\": np.nan if single_class_test else float(recall_score(y_test, preds, zero_division=0)),\n",
    "\n",
    "                **dist,\n",
    "\n",
    "                \"train_n\": int(len(y_train)),\n",
    "                \"train_start\": dates[train_start] if dates is not None else train_start,\n",
    "                \"train_end\": dates[train_end - 1] if dates is not None else train_end - 1,\n",
    "                \"test_start\": dates[test_start] if dates is not None else test_start,\n",
    "                \"test_end\": dates[test_end - 1] if dates is not None else test_end - 1,\n",
    "                \"train_years\": train_years,\n",
    "                \"horizon_days\": horizon_days,\n",
    "                \"n_features\": len(safe_feature_cols),\n",
    "            })\n",
    "\n",
    "            #total_time = time.time() - start_time\n",
    "            #print(f\"{model_name} - {total_time}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def perm_list(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    *,\n",
    "    date_col=\"Date\",\n",
    "    train_years=6,\n",
    "    test_days=5,\n",
    "    step_days=5,\n",
    "    purge_days=None, \n",
    "    fill_inf=0.0,\n",
    "    k=1\n",
    "):\n",
    "\n",
    "    dfw = df.sort_values(\"Date\").reset_index(drop=True).copy()\n",
    "\n",
    "    # Drop any accidental return cols from features (belt+suspenders)\n",
    "    safe_feature_cols = [c for c in feature_cols if \"Return\" not in c]\n",
    "\n",
    "    # Basic numeric cleaning\n",
    "    dfw[safe_feature_cols] = dfw[safe_feature_cols].replace([np.inf, -np.inf], fill_inf)\n",
    "\n",
    "    n = len(dfw)\n",
    "    train_size = 245 * int(train_years)\n",
    "    test_size = int(test_days)\n",
    "    step = int(step_days)\n",
    "    purge = int(purge_days) if purge_days is not None else 0 #int(horizon_days)\n",
    "\n",
    "    X_all = dfw[safe_feature_cols].to_numpy()\n",
    "    #y_all = _to_binary(dfw[target_col].to_numpy())\n",
    "    y_all = dfw[target_col].to_numpy()\n",
    "    dates = dfw[date_col].to_numpy() if date_col in dfw.columns else None\n",
    "\n",
    "    test_end = n - k * step\n",
    "    test_start = test_end - test_size\n",
    "    train_end = test_start - purge\n",
    "    train_start = train_end - train_size\n",
    "\n",
    "    X_train = X_all[train_start:train_end]\n",
    "    y_train = y_all[train_start:train_end]\n",
    "\n",
    "    N_PI = int(len(X_train) * 0.75)\n",
    "    X_pi = X_train[-N_PI:]\n",
    "    y_pi = y_train[-N_PI:]\n",
    "\n",
    "    # fit model\n",
    "    m = clone(model).fit(X_train, y_train)\n",
    "\n",
    "    # permutation importance on training-only slice\n",
    "    pi = permutation_importance(\n",
    "        m,\n",
    "        X_pi,\n",
    "        y_pi,\n",
    "        scoring=\"neg_log_loss\",   # or \"accuracy\", \"neg_log_loss\", etc.\n",
    "        n_repeats=50,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # pi.importances_mean aligns to feature_cols order\n",
    "    pi_df = pd.DataFrame({\n",
    "        \"feature\": feature_cols,                 # same order used to build X_train\n",
    "        \"pi_mean\": pi.importances_mean,\n",
    "        \"pi_std\":  pi.importances_std,\n",
    "    }).sort_values(\"pi_mean\", ascending=False)\n",
    "\n",
    "    # keep only features with PI > 0\n",
    "    pi_cols = pi_df['feature'][pi_df['pi_mean'] > .003].to_list()\n",
    "    print(f\"Ran permutation importance | Len: {N_PI} | Old: {len(feature_cols)} | New: {len(pi_cols)}\")\n",
    "    \n",
    "    return pi_cols\n",
    "\n",
    "# -----------------------------\n",
    "# Run grid (feature sets x horizon x train_years, etc.)\n",
    "# -----------------------------\n",
    "returns = [2, 5, 10, 20, 30]\n",
    "#train_years_grid = [4, 5, 6]#[3, 5, 7] \n",
    "days_assessed = 230\n",
    "test_days = [1]\n",
    "#results= []\n",
    "#results_df = pd.DataFrame()\n",
    "\n",
    "for test_day in test_days:\n",
    "\n",
    "    runs = int(days_assessed / test_day)\n",
    "\n",
    "    for r in returns:\n",
    "\n",
    "        #fs_map = horizon_feature_cols[r]   # dict: feature_set_name\n",
    "\n",
    "        #for list_name in fs_map.keys():\n",
    "\n",
    "        #cols = feature_lists[list_name] + new_feats\n",
    "        if r == 2:\n",
    "            base_cols = experimental_slope_cols + ma_lag + ma_sma\n",
    "            list_name = \"initial+rsi+macd\" #worse\n",
    "            list_name = \"initial+sma\" #worse\n",
    "            train_years = 4\n",
    "            #cols = experimental_slope_cols + ma_lag + rsi_cols + macd_cols + volu_cols\n",
    "        elif r == 5:\n",
    "            base_cols = experimental_slope_cols + ma_lag + ma_num + rsi_cols + macd_cols + volu_cols + vix_skew_cols\n",
    "            list_name = \"initial+atradx\" #worse\n",
    "            list_name = \"initial+sma\" #worse\n",
    "            list_name = \"initial+vixskew\" #much worse\n",
    "            train_years = 5\n",
    "            #cols = atr_adx_cols + vola_cols + experimental_slope_cols + ma_lag + ma_num + ma_rel + ma_sma + rsi_cols + macd_cols + volu_cols + vix_skew_cols\n",
    "        elif r == 10:\n",
    "            base_cols = atr_adx_cols + vola_cols + ma_num + volu_cols + ma_sma + ma_lag\n",
    "            list_name = \"initial+sma\" # better\n",
    "            list_name = \"initial+sma+lag\" #worse\n",
    "            train_years = 5\n",
    "            #cols = atr_adx_cols + vola_cols + ma_num + ma_rel + ma_sma + volu_cols + vix_skew_cols\n",
    "        elif r == 20:\n",
    "            base_cols = atr_adx_cols + vola_cols + ma_num + ma_sma + ma_lag\n",
    "            list_name = \"initial+volu\" #worse\n",
    "            list_name = \"initial+lag\" #much worse\n",
    "            train_years = 6\n",
    "        else:\n",
    "            base_cols = atr_adx_cols + vola_cols + ma_num + ma_sma + volu_cols #rsi_cols + macd_cols + \n",
    "            list_name = \"initial+volu\" #worse\n",
    "            list_name = \"initial-rsimacd+volu\" #better\n",
    "            train_years = 5\n",
    "\n",
    "        target_col = f\"Return_{r}\"\n",
    "        # Trime unknown (recent) outcomes\n",
    "        df_final = df_main.iloc[r:].copy()\n",
    "\n",
    "        perm_cols = perm_list(\n",
    "            df=df_final,\n",
    "            feature_cols=base_cols,\n",
    "            target_col=target_col,\n",
    "            date_col=\"Date\",\n",
    "            train_years=train_years,\n",
    "            test_days=test_day,\n",
    "            step_days=test_day,\n",
    "            purge_days=r, \n",
    "            fill_inf=0.0,\n",
    "        )\n",
    "\n",
    "        #for train_years in train_years_grid:\n",
    "        df_scores = walkback_runs(\n",
    "            df=df_final,\n",
    "            feature_cols=perm_cols,\n",
    "            target_col=target_col,\n",
    "            date_col=\"Date\",\n",
    "            train_years=train_years,\n",
    "            test_days=test_day,\n",
    "            step_days=test_day,\n",
    "            runs=runs,\n",
    "            horizon_days=r,\n",
    "            purge_days=r, \n",
    "            fill_inf=0.0,\n",
    "        )\n",
    "\n",
    "        df_scores[\"feature_set\"] = \"pi_top_model\" #list_name\n",
    "        df_scores[\"horizon\"] = r\n",
    "\n",
    "        results.append(df_scores)\n",
    "\n",
    "results_df = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(results, ignore_index=True)\n",
    "df_new = results_df[cols].copy()\n",
    "df_new.to_csv('baseline_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"baseline_performance.csv\")\n",
    "cols = ['model', 'test_days', 'pred', 'acc', 'test_n', 'test_pos_n', 'train_n', 'test_start', 'test_end', 'train_years', 'feature_set', 'horizon']\n",
    "df_new = results_df[cols].copy()\n",
    "df_concat = pd.concat([df2, df_new], ignore_index=True)\n",
    "df_concat.to_csv('baseline_performance.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
