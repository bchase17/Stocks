{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Feature Sets: dict_keys(['ma', 'rsi', 'macd', 'volume', 'atr_adx', 'volatility', 'vix_skew', 'experimental_slope'])\n"
     ]
    }
   ],
   "source": [
    "import min_features, daily_return\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\", message=\"y_pred contains classes not in y_true\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import time\n",
    "\n",
    "importlib.reload(min_features)\n",
    "importlib.reload(daily_return)\n",
    "\n",
    "min_feats = \"N\"\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "\n",
    "if min_feats != 'N':\n",
    "    df_min = min_features.min_features()\n",
    "    df_daily, feature_sets = daily_return.pull_daily('QQQ', returns) \n",
    "\n",
    "    df_main = pd.merge(df_min, df_daily, how='inner', on='Date')\n",
    "    df_main = df_main.sort_values(by='Date', ascending=False)\n",
    "\n",
    "    return_cols = df_main.columns[df_main.columns.str.contains(\"Return_\")].to_list()\n",
    "    daily_cols = [\n",
    "        c for c in df_daily.iloc[:, 1:].columns\n",
    "        if \"return\" not in c.lower()\n",
    "    ]\n",
    "    close_cols = df_min.columns[(df_min.columns.str.contains(\"close_\")) | (df_min.columns.str.contains(\"post_\")) | (df_min.columns.str.contains(\"overnight_\"))].to_list()\n",
    "    min_cols = (\n",
    "        df_min\n",
    "        .loc[:, ~df_min.columns.isin(close_cols)]  # drop close_ columns\n",
    "        .iloc[:, 1:]                               # drop first column\n",
    "        .columns\n",
    "        .to_list()\n",
    "    )\n",
    "else:\n",
    "    df_daily, feature_sets = daily_return.pull_daily('QQQ', returns) \n",
    "    return_cols = df_daily.columns[df_daily.columns.str.contains(\"Return_\")].to_list()\n",
    "    past_return_cols = df_daily.columns[df_daily.columns.str.contains(\"Past_Ret\")].to_list()\n",
    "    daily_cols = [\n",
    "        c for c in df_daily.iloc[:, 1:].columns\n",
    "        if \"return\" not in c.lower()\n",
    "    ]\n",
    "    df_main = df_daily[df_daily['Date'] <= '2026-01-21'].copy()\n",
    "\n",
    "#top_models = pd.read_csv(\"top_performers2.csv\")\n",
    "print(f'Available Feature Sets: {feature_sets.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(df): \n",
    "    \n",
    "    # Percent return over 1, 3, 5, 10 days?\n",
    "    # Win rate over 10, 20, 30, 50 days?\n",
    "    # Num days pos over th\n",
    "    # Num days neg over th\n",
    "\n",
    "    df = df.sort_values(by='Date', ascending=True)\n",
    "\n",
    "    # =======================\n",
    "    # Basic SMAs and Ratios\n",
    "    # =======================\n",
    "    sma_windows = [10, 25, 50, 100, 200]\n",
    "    for sma_window in sma_windows:\n",
    "        \n",
    "        df[f'SMA_{sma_window}'] = df['Close'].rolling(window=sma_window).mean()\n",
    "\n",
    "        # Current close relativet to n_day high | max 1\n",
    "        df[f'Close_Rel_Max{sma_window}'] = (df['Close'] / df['High'].rolling(window=sma_window).max()).round(2)\n",
    "        # Current close relativet to n_day low | min 1\n",
    "        df[f'Close_Rel_Min{sma_window}'] = (df['Close'] / df['Low'].rolling(window=sma_window).min()).round(2)\n",
    "\n",
    "    lag_periods = [10, 25, 50, 100, 150, 200]\n",
    "    for sma_window in sma_windows:\n",
    "        new_cols = {}\n",
    "        for col in df.columns:\n",
    "            if col == f'SMA_{sma_window}':\n",
    "                for lag in lag_periods:\n",
    "                        new_cols[f'{col}_Lag{lag}_min'] = (df[col] / df[col].rolling(window=lag).min()).round(2)\n",
    "                        new_cols[f'{col}_Lag{lag}_max'] = (df[col] / df[col].rolling(window=lag).max()).round(2)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(new_cols, index=df.index)], axis=1)\n",
    "    \n",
    "    for window in [50, 100, 200]:\n",
    "        df[f'num_days_{window}'] = 0\n",
    "        for i in range(1, len(df)):\n",
    "            prev = df.loc[i - 1, f'num_days_{window}']\n",
    "            price = df.loc[i, 'Close']\n",
    "            sma = df.loc[i, f'SMA_{window}']\n",
    "            if price > sma:\n",
    "                df.loc[i, f'num_days_{window}'] = prev + 1 if prev >= 0 else 0\n",
    "            elif price < sma:\n",
    "                df.loc[i, f'num_days_{window}'] = prev - 1 if prev <= 0 else 0\n",
    "            else:\n",
    "                df.loc[i, f'num_days_{window}'] = 0\n",
    "\n",
    "    # ============================\n",
    "    # Relative Position Features\n",
    "    # ============================\n",
    "    def rows_since_max(x): return len(x) - x.argmax() - 1\n",
    "    def rows_since_min(x): return len(x) - x.argmin() - 1\n",
    "\n",
    "    for window in [10, 30, 60, 120, 240]:\n",
    "\n",
    "        df[f'Rel_Max_{window}'] = (df['High'] / df['High'].rolling(window=window).max()).round(2)\n",
    "        df[f'Rel_Min_{window}'] = (df['Low'] / df['Low'].rolling(window=window).min()).round(2)\n",
    "        df[f'Max_{window}_Rows_Since'] = df['High'].rolling(window=window).apply(rows_since_max, raw=True)\n",
    "        df[f'Min_{window}_Rows_Since'] = df['Low'].rolling(window=window).apply(rows_since_min, raw=True)\n",
    "\n",
    "    for a, b in [(50, 100), (50, 200), (100, 200), (10, 25), (10, 50), (10, 100), (10, 200), (25, 50), (25, 100), (25, 200)]:    \n",
    "        df[f'{a}_SMA_{b}'] = (df[f'SMA_{a}'] / df[f'SMA_{b}']).round(2)\n",
    "\n",
    "    for window in sma_windows:\n",
    "\n",
    "        df[f'SMA_{window}'] = (df['Close'] / df[f'SMA_{window}']).round(2)\n",
    "        #df[f'EMA_{window}'] = (df['Close'] / df[f'EMA_{window}']).round(2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Past_Return_1</th>\n",
       "      <th>Past_Return%_1</th>\n",
       "      <th>Past_Return_2</th>\n",
       "      <th>Past_Return%_2</th>\n",
       "      <th>Past_Return_3</th>\n",
       "      <th>Past_Return%_3</th>\n",
       "      <th>Past_Return_5</th>\n",
       "      <th>Past_Return%_5</th>\n",
       "      <th>Past_Return_10</th>\n",
       "      <th>Past_Return%_10</th>\n",
       "      <th>Past_Return_20</th>\n",
       "      <th>Past_Return%_20</th>\n",
       "      <th>Past_Return_30</th>\n",
       "      <th>Past_Return%_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008081</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008925</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011586</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.013622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.021708</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022564</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.018896</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.031428</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016331</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008016</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008676</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034804</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007173</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008669</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017397</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.010798</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012299</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011460</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027913</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.024969</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019975</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6759 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Past_Return_1  Past_Return%_1  Past_Return_2  Past_Return%_2  \\\n",
       "6758              1        0.013338              0       -0.008081   \n",
       "6757              0       -0.021708              0       -0.022564   \n",
       "6756              0       -0.000837              1        0.002753   \n",
       "6755              1        0.003587              0       -0.007173   \n",
       "6754              0       -0.010798              0       -0.012299   \n",
       "...             ...             ...            ...             ...   \n",
       "4                 1        0.008423              1        0.036101   \n",
       "3                 1        0.027913              1        0.003641   \n",
       "2                 0       -0.024969              0       -0.019975   \n",
       "1                 1        0.004872              0             NaN   \n",
       "0                 0             NaN              0             NaN   \n",
       "\n",
       "      Past_Return_3  Past_Return%_3  Past_Return_5  Past_Return%_5  \\\n",
       "6758              0       -0.008925              0       -0.016161   \n",
       "6757              0       -0.018896              0       -0.031428   \n",
       "6756              0       -0.008016              0       -0.008676   \n",
       "6755              0       -0.008669              1        0.002107   \n",
       "6754              0       -0.011460              0       -0.007215   \n",
       "...             ...             ...            ...             ...   \n",
       "4                 1        0.012034              0             NaN   \n",
       "3                 1        0.008496              0             NaN   \n",
       "2                 0             NaN              0             NaN   \n",
       "1                 0             NaN              0             NaN   \n",
       "0                 0             NaN              0             NaN   \n",
       "\n",
       "      Past_Return_10  Past_Return%_10  Past_Return_20  Past_Return%_20  \\\n",
       "6758               0        -0.011586               1         0.000039   \n",
       "6757               0        -0.016331               0        -0.000438   \n",
       "6756               1         0.013102               1         0.034804   \n",
       "6755               1         0.012014               1         0.017397   \n",
       "6754               1         0.000194               1         0.015811   \n",
       "...              ...              ...             ...              ...   \n",
       "4                  0              NaN               0              NaN   \n",
       "3                  0              NaN               0              NaN   \n",
       "2                  0              NaN               0              NaN   \n",
       "1                  0              NaN               0              NaN   \n",
       "0                  0              NaN               0              NaN   \n",
       "\n",
       "      Past_Return_30  Past_Return%_30  \n",
       "6758               0        -0.013622  \n",
       "6757               0        -0.023153  \n",
       "6756               0        -0.002346  \n",
       "6755               1         0.000933  \n",
       "6754               1         0.005123  \n",
       "...              ...              ...  \n",
       "4                  0              NaN  \n",
       "3                  0              NaN  \n",
       "2                  0              NaN  \n",
       "1                  0              NaN  \n",
       "0                  0              NaN  \n",
       "\n",
       "[6759 rows x 14 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[past_return_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA_10_Lag10_min</th>\n",
       "      <th>SMA_10_Lag10_max</th>\n",
       "      <th>SMA_10_Lag25_min</th>\n",
       "      <th>SMA_10_Lag25_max</th>\n",
       "      <th>SMA_10_Lag50_min</th>\n",
       "      <th>SMA_10_Lag50_max</th>\n",
       "      <th>SMA_10_Lag100_min</th>\n",
       "      <th>SMA_10_Lag100_max</th>\n",
       "      <th>SMA_10_Lag150_min</th>\n",
       "      <th>SMA_10_Lag150_max</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA_200_Lag25_min</th>\n",
       "      <th>SMA_200_Lag25_max</th>\n",
       "      <th>SMA_200_Lag50_min</th>\n",
       "      <th>SMA_200_Lag50_max</th>\n",
       "      <th>SMA_200_Lag100_min</th>\n",
       "      <th>SMA_200_Lag100_max</th>\n",
       "      <th>SMA_200_Lag150_min</th>\n",
       "      <th>SMA_200_Lag150_max</th>\n",
       "      <th>SMA_200_Lag200_min</th>\n",
       "      <th>SMA_200_Lag200_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6759 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SMA_10_Lag10_min  SMA_10_Lag10_max  SMA_10_Lag25_min  SMA_10_Lag25_max  \\\n",
       "6758              1.00               1.0              1.01               1.0   \n",
       "6757              1.00               1.0              1.01               1.0   \n",
       "6756              1.01               1.0              1.01               1.0   \n",
       "6755              1.01               1.0              1.01               1.0   \n",
       "6754              1.01               1.0              1.01               1.0   \n",
       "...                ...               ...               ...               ...   \n",
       "4                  NaN               NaN               NaN               NaN   \n",
       "3                  NaN               NaN               NaN               NaN   \n",
       "2                  NaN               NaN               NaN               NaN   \n",
       "1                  NaN               NaN               NaN               NaN   \n",
       "0                  NaN               NaN               NaN               NaN   \n",
       "\n",
       "      SMA_10_Lag50_min  SMA_10_Lag50_max  SMA_10_Lag100_min  \\\n",
       "6758              1.03              1.00               1.09   \n",
       "6757              1.03              1.00               1.09   \n",
       "6756              1.04              1.00               1.10   \n",
       "6755              1.03              1.00               1.09   \n",
       "6754              1.03              0.99               1.09   \n",
       "...                ...               ...                ...   \n",
       "4                  NaN               NaN                NaN   \n",
       "3                  NaN               NaN                NaN   \n",
       "2                  NaN               NaN                NaN   \n",
       "1                  NaN               NaN                NaN   \n",
       "0                  NaN               NaN                NaN   \n",
       "\n",
       "      SMA_10_Lag100_max  SMA_10_Lag150_min  SMA_10_Lag150_max  ...  \\\n",
       "6758               0.99               1.18               0.99  ...   \n",
       "6757               1.00               1.18               1.00  ...   \n",
       "6756               1.00               1.18               1.00  ...   \n",
       "6755               1.00               1.18               1.00  ...   \n",
       "6754               0.99               1.18               0.99  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "4                   NaN                NaN                NaN  ...   \n",
       "3                   NaN                NaN                NaN  ...   \n",
       "2                   NaN                NaN                NaN  ...   \n",
       "1                   NaN                NaN                NaN  ...   \n",
       "0                   NaN                NaN                NaN  ...   \n",
       "\n",
       "      SMA_200_Lag25_min  SMA_200_Lag25_max  SMA_200_Lag50_min  \\\n",
       "6758               1.03                1.0               1.05   \n",
       "6757               1.03                1.0               1.05   \n",
       "6756               1.03                1.0               1.05   \n",
       "6755               1.03                1.0               1.05   \n",
       "6754               1.03                1.0               1.05   \n",
       "...                 ...                ...                ...   \n",
       "4                   NaN                NaN                NaN   \n",
       "3                   NaN                NaN                NaN   \n",
       "2                   NaN                NaN                NaN   \n",
       "1                   NaN                NaN                NaN   \n",
       "0                   NaN                NaN                NaN   \n",
       "\n",
       "      SMA_200_Lag50_max  SMA_200_Lag100_min  SMA_200_Lag100_max  \\\n",
       "6758                1.0                1.10                 1.0   \n",
       "6757                1.0                1.10                 1.0   \n",
       "6756                1.0                1.10                 1.0   \n",
       "6755                1.0                1.09                 1.0   \n",
       "6754                1.0                1.09                 1.0   \n",
       "...                 ...                 ...                 ...   \n",
       "4                   NaN                 NaN                 NaN   \n",
       "3                   NaN                 NaN                 NaN   \n",
       "2                   NaN                 NaN                 NaN   \n",
       "1                   NaN                 NaN                 NaN   \n",
       "0                   NaN                 NaN                 NaN   \n",
       "\n",
       "      SMA_200_Lag150_min  SMA_200_Lag150_max  SMA_200_Lag200_min  \\\n",
       "6758                1.14                 1.0                1.16   \n",
       "6757                1.14                 1.0                1.16   \n",
       "6756                1.14                 1.0                1.16   \n",
       "6755                1.14                 1.0                1.15   \n",
       "6754                1.14                 1.0                1.15   \n",
       "...                  ...                 ...                 ...   \n",
       "4                    NaN                 NaN                 NaN   \n",
       "3                    NaN                 NaN                 NaN   \n",
       "2                    NaN                 NaN                 NaN   \n",
       "1                    NaN                 NaN                 NaN   \n",
       "0                    NaN                 NaN                 NaN   \n",
       "\n",
       "      SMA_200_Lag200_max  \n",
       "6758                 1.0  \n",
       "6757                 1.0  \n",
       "6756                 1.0  \n",
       "6755                 1.0  \n",
       "6754                 1.0  \n",
       "...                  ...  \n",
       "4                    NaN  \n",
       "3                    NaN  \n",
       "2                    NaN  \n",
       "1                    NaN  \n",
       "0                    NaN  \n",
       "\n",
       "[6759 rows x 60 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[ma_lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran permutation importance for horizon 2 | Len: 735 | Old: 195 | New: 7\n",
      "['Past_Return%_5', 'Vol_Ratio_50_zscore', 'VROC_10', 'ADX', 'VIX_1_change', 'skew_10_change', 'VROC_5']\n",
      "Run 1/1 | Train: 2022-02-16 → 2026-01-13 | Test: 2026-01-16 → 2026-01-16 | Train_n=980 | Test_n=1\n",
      "Ran permutation importance for horizon 5 | Len: 918 | Old: 195 | New: 6\n",
      "['SMA_10_Lag200_min', 'num_days_200', 'Vol_Ratio_50', 'Max_120_Rows_Since', 'ATR_14', 'Vol_Ratio_25_zscore']\n",
      "Run 1/1 | Train: 2021-02-19 → 2026-01-05 | Test: 2026-01-13 → 2026-01-13 | Train_n=1225 | Test_n=1\n",
      "Ran permutation importance for horizon 10 | Len: 918 | Old: 195 | New: 8\n",
      "['num_days_200', 'Max_120_Rows_Since', 'SMA_10_Lag200_min', 'ADL', 'BB_Mid', 'Vol_Ratio_50', 'Min_240_Rows_Since', 'SMA_25_Lag150_min']\n",
      "Run 1/1 | Train: 2021-02-04 → 2025-12-18 | Test: 2026-01-06 → 2026-01-06 | Train_n=1225 | Test_n=1\n",
      "Ran permutation importance for horizon 20 | Len: 1102 | Old: 54 | New: 12\n",
      "['num_days_200', 'Min_240_Rows_Since', 'Max_120_Rows_Since', 'num_days_100', '100_SMA_200', '50_SMA_200', 'ADX', 'SMA_200', 'SMA_50', 'num_days_50', 'Min_120_Rows_Since', 'Price_Vol_Ratio_10']\n",
      "Run 1/1 | Train: 2020-01-16 → 2025-11-19 | Test: 2025-12-19 → 2025-12-19 | Train_n=1470 | Test_n=1\n",
      "Ran permutation importance for horizon 30 | Len: 918 | Old: 195 | New: 8\n",
      "['num_days_200', 'Min_240_Rows_Since', 'SMA_100_Lag200_min', 'Max_120_Rows_Since', 'SMA_200', 'Vol_Ratio_25', 'SMA_50_Lag100_max', 'num_days_100']\n",
      "Run 1/1 | Train: 2020-12-07 → 2025-10-22 | Test: 2025-12-05 → 2025-12-05 | Train_n=1225 | Test_n=1\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Feature Sets\n",
    "# -----------------------------\n",
    "ma_all_cols = feature_sets['ma']\n",
    "ma_lag = [c for c in ma_all_cols if \"lag\" in c.lower()]\n",
    "ma_rel = [c for c in ma_all_cols if \"rel_\" in c.lower()]\n",
    "ma_sma = [c for c in ma_all_cols if (\"sma_\" in c.lower()) and (\"lag\" not in c.lower())]\n",
    "ma_num = [c for c in ma_all_cols if (\"num\" in c.lower()) or (\"since\" in c.lower())]\n",
    "rsi_cols = feature_sets['rsi']\n",
    "macd_cols = feature_sets['macd']\n",
    "volu_cols = feature_sets['volume']\n",
    "atr_adx_cols = feature_sets['atr_adx']\n",
    "vola_cols = feature_sets['volatility']\n",
    "vix_skew_cols = feature_sets['vix_skew']\n",
    "experimental_slope_cols = feature_sets['experimental_slope']\n",
    "\n",
    "sets = [ma_lag, ma_rel, ma_sma, ma_num, rsi_cols + macd_cols, volu_cols, atr_adx_cols + vola_cols, vix_skew_cols, experimental_slope_cols]\n",
    "set_names = [\"ma_lag\", \"ma_rel\", \"ma_sma\", \"ma_num\", \"rsi_macd\", \"volu\", \"atr_adx\" + \"vola\", \"vix_skew\", \"experimental_slope\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Models\n",
    "# -----------------------------\n",
    "models = {\n",
    "    #\"xgboost-4\": XGBClassifier(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    #\"xgboost-6\": XGBClassifier(n_estimators=600, random_state=42, n_jobs=-1),\n",
    "    \"xgb_first_pass\": XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=5,\n",
    "    min_child_weight=10,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    gamma=0.3,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=15,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"xgboost-2\": XGBClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    \"xgboost-4\": XGBClassifier(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    #\"xgboost-6\": XGBClassifier(n_estimators=600, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def _compute_dist(y):\n",
    "    \"\"\"Distribution stats for y in {0,1}.\"\"\"\n",
    "    n = int(len(y))\n",
    "    n_pos = int((y == 1).sum())\n",
    "    n_neg = int((y == 0).sum())\n",
    "    return {\n",
    "        \"test_n\": n,\n",
    "        \"test_pos_n\": n_pos,\n",
    "        \"test_neg_n\": n_neg,\n",
    "        \"test_pos_frac\": (n_pos / n) if n else np.nan,\n",
    "        \"test_neg_frac\": (n_neg / n) if n else np.nan,\n",
    "    }\n",
    "\n",
    "def walkback_runs(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    *,\n",
    "    date_col=\"Date\",\n",
    "    train_years=6,\n",
    "    test_days=5,\n",
    "    step_days=5,\n",
    "    runs=20,\n",
    "    horizon_days=1,        # r (used for purge)\n",
    "    purge_days=None,       # defaults to horizon_days\n",
    "    fill_inf=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Deployment-aligned evaluation:\n",
    "      - For each run, take a 5-day OOT test window stepping back by 5 days.\n",
    "      - Train on the prior N years (fixed-length window) ending right before test.\n",
    "      - Purge 'purge_days' from the end of train to avoid overlap leakage for forward-return labels.\n",
    "      - Score ONLY on the OOT test window (distribution + metrics).\n",
    "    Returns: long DataFrame with one row per (feature_set/run/model).\n",
    "    \"\"\"\n",
    "    dfw = df.sort_values(\"Date\").reset_index(drop=True).copy()\n",
    "\n",
    "    # Drop any accidental return cols from features (belt+suspenders)\n",
    "    safe_feature_cols = [c for c in feature_cols if \"Return\" not in c]\n",
    "\n",
    "    # Basic numeric cleaning\n",
    "    dfw[safe_feature_cols] = dfw[safe_feature_cols].replace([np.inf, -np.inf], fill_inf)\n",
    "\n",
    "    n = len(dfw)\n",
    "    train_size = 245 * int(train_years)\n",
    "    test_size = int(test_days)\n",
    "    step = int(step_days)\n",
    "    purge = int(purge_days) if purge_days is not None else 0 #int(horizon_days)\n",
    "\n",
    "    X_all = dfw[safe_feature_cols].to_numpy()\n",
    "    #y_all = _to_binary(dfw[target_col].to_numpy())\n",
    "    y_all = dfw[target_col].to_numpy()\n",
    "    dates = dfw[date_col].to_numpy() if date_col in dfw.columns else None\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for k in range(runs):\n",
    "        test_end = n - k * step\n",
    "        test_start = test_end - test_size\n",
    "        if test_start < 0:\n",
    "            break\n",
    "\n",
    "        train_end = test_start - purge\n",
    "        train_start = train_end - train_size\n",
    "        if train_start < 0 or train_end <= train_start:\n",
    "            break\n",
    "\n",
    "        print(\n",
    "            f\"Run {k+1}/{runs} | \"\n",
    "            f\"Train: {dates[train_start]} → {dates[train_end-1]} | \"\n",
    "            f\"Test: {dates[test_start]} → {dates[test_end-1]} | \"\n",
    "            f\"Train_n={train_end-train_start} | Test_n={test_end-test_start}\"\n",
    "        )\n",
    "\n",
    "        X_train = X_all[train_start:train_end]\n",
    "        y_train = y_all[train_start:train_end]\n",
    "        X_test  = X_all[test_start:test_end]\n",
    "        y_test  = y_all[test_start:test_end]\n",
    "\n",
    "        dist = _compute_dist(y_test)\n",
    "        single_class_test = (np.unique(y_test).size < 2)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            #start_time = time.time()\n",
    "            m = clone(model)\n",
    "            m.fit(X_train, y_train)\n",
    "\n",
    "            preds = m.predict(X_test)\n",
    "            proba = np.nan\n",
    "            if hasattr(m, \"predict_proba\"):\n",
    "                proba = float(m.predict_proba(X_test)[0, 1])   # prob(class=1)\n",
    "            elif hasattr(m, \"decision_function\"):\n",
    "                s = float(m.decision_function(X_test)[0])\n",
    "                proba = float(1.0 / (1.0 + np.exp(-s)))        # squash to (0,1)\n",
    "            proba = np.nan if np.isnan(proba) else round(round(proba / 0.05) * 0.05, 2)\n",
    "\n",
    "\n",
    "\n",
    "            rows.append({\n",
    "                \"run\": k + 1,\n",
    "                \"model\": model_name,\n",
    "                \"test_days\": test_days,\n",
    "                \"pred\": round(proba,2),\n",
    "\n",
    "                # core metrics\n",
    "                #\"bal_acc\": float(balanced_accuracy_score(y_test, preds)),\n",
    "                \"acc\": float(accuracy_score(y_test, preds)),\n",
    "                #\"sign_acc\": 2 * float(accuracy_score(y_test, preds)) - 1,\n",
    "                #\"mcc\": float(matthews_corrcoef(y_test, preds)),\n",
    "\n",
    "                # only meaningful if test has both classes\n",
    "                #\"f1\": np.nan if single_class_test else float(f1_score(y_test, preds, zero_division=0)),\n",
    "                #\"precision\": np.nan if single_class_test else float(precision_score(y_test, preds, zero_division=0)),\n",
    "                #\"recall\": np.nan if single_class_test else float(recall_score(y_test, preds, zero_division=0)),\n",
    "\n",
    "                **dist,\n",
    "\n",
    "                \"train_n\": int(len(y_train)),\n",
    "                \"train_start\": dates[train_start] if dates is not None else train_start,\n",
    "                \"train_end\": dates[train_end - 1] if dates is not None else train_end - 1,\n",
    "                \"test_start\": dates[test_start] if dates is not None else test_start,\n",
    "                \"test_end\": dates[test_end - 1] if dates is not None else test_end - 1,\n",
    "                \"train_years\": train_years,\n",
    "                \"horizon_days\": horizon_days,\n",
    "                \"n_features\": len(safe_feature_cols),\n",
    "            })\n",
    "\n",
    "            #total_time = time.time() - start_time\n",
    "            #print(f\"{model_name} - {total_time}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def perm_list(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    *,\n",
    "    date_col=\"Date\",\n",
    "    train_years=6,\n",
    "    test_days=5,\n",
    "    step_days=5,\n",
    "    purge_days=None, \n",
    "    fill_inf=0.0,\n",
    "    k=1\n",
    "):\n",
    "\n",
    "    dfw = df.sort_values(\"Date\").reset_index(drop=True).copy()\n",
    "\n",
    "    # Drop any accidental return cols from features (belt+suspenders)\n",
    "    safe_feature_cols = [c for c in feature_cols if not (c.startswith(\"Return\"))]\n",
    "\n",
    "    # Basic numeric cleaning\n",
    "    dfw[safe_feature_cols] = dfw[safe_feature_cols].replace([np.inf, -np.inf], fill_inf)\n",
    "\n",
    "    n = len(dfw)\n",
    "    train_size = 245 * int(train_years)\n",
    "    test_size = int(test_days)\n",
    "    step = int(step_days)\n",
    "    purge = int(purge_days) if purge_days is not None else 0 #int(horizon_days)\n",
    "\n",
    "    X_all = dfw[safe_feature_cols].to_numpy()\n",
    "    #y_all = _to_binary(dfw[target_col].to_numpy())\n",
    "    y_all = dfw[target_col].to_numpy()\n",
    "    dates = dfw[date_col].to_numpy() if date_col in dfw.columns else None\n",
    "\n",
    "    test_end = n - k * step\n",
    "    test_start = test_end - test_size\n",
    "    train_end = test_start - purge\n",
    "    train_start = train_end - train_size\n",
    "\n",
    "    X_train = X_all[train_start:train_end]\n",
    "    y_train = y_all[train_start:train_end]\n",
    "\n",
    "    N_PI = int(len(X_train) * 0.75)\n",
    "    X_pi = X_train[-N_PI:]\n",
    "    y_pi = y_train[-N_PI:]\n",
    "\n",
    "    # fit model\n",
    "    m = clone(model).fit(X_train, y_train)\n",
    "\n",
    "    # permutation importance on training-only slice\n",
    "    pi = permutation_importance(\n",
    "        m,\n",
    "        X_pi,\n",
    "        y_pi,\n",
    "        scoring=\"neg_log_loss\",   # or \"accuracy\", \"neg_log_loss\", etc.\n",
    "        n_repeats=50,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # pi.importances_mean aligns to feature_cols order\n",
    "    pi_df = pd.DataFrame({\n",
    "        \"feature\": feature_cols,                 # same order used to build X_train\n",
    "        \"pi_mean\": pi.importances_mean,\n",
    "        \"pi_std\":  pi.importances_std,\n",
    "    }).sort_values(\"pi_mean\", ascending=False)\n",
    "\n",
    "    # keep only features with PI > 0\n",
    "    pi_cols = pi_df['feature'][pi_df['pi_mean'] > .003].to_list()\n",
    "\n",
    "    if len(pi_cols) < 6:\n",
    "        pi_cols = (\n",
    "            pi_df.sort_values(\"pi_mean\", ascending=False)\n",
    "                .head(6)[\"feature\"]\n",
    "                .tolist()\n",
    "        )\n",
    "    print(f\"Ran permutation importance for horizon {purge_days} | Len: {N_PI} | Old: {len(feature_cols)} | New: {len(pi_cols)}\")\n",
    "    \n",
    "    return pi_cols\n",
    "\n",
    "# -----------------------------\n",
    "# Run grid (feature sets x horizon x train_years, etc.)\n",
    "# -----------------------------\n",
    "returns = [2, 5, 10, 20, 30]\n",
    "#train_years_grid = [4, 5, 6]#[3, 5, 7] \n",
    "days_assessed = 1\n",
    "test_days = [1]\n",
    "results= []\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for test_day in test_days:\n",
    "\n",
    "    runs = int(days_assessed / test_day)\n",
    "\n",
    "    for r in returns:\n",
    "\n",
    "        #fs_map = horizon_feature_cols[r]   # dict: feature_set_name\n",
    "\n",
    "        #for list_name in fs_map.keys():\n",
    "\n",
    "        #cols = feature_lists[list_name] + new_feats\n",
    "        if r == 2:\n",
    "            base_cols = experimental_slope_cols + ma_lag + rsi_cols + macd_cols + volu_cols\n",
    "            base_cols = ma_lag + ma_rel + ma_sma + ma_num + rsi_cols + macd_cols + volu_cols + atr_adx_cols + vola_cols + vix_skew_cols + experimental_slope_cols\n",
    "            list_name = \"initial+rsi+macd\" #worse\n",
    "            list_name = \"initial+sma\" #worse\n",
    "            train_years = 4\n",
    "            #cols = experimental_slope_cols + ma_lag + rsi_cols + macd_cols + volu_cols\n",
    "        elif r == 5:\n",
    "            base_cols = experimental_slope_cols + ma_lag + ma_num + rsi_cols + macd_cols + volu_cols\n",
    "            base_cols = ma_lag + ma_rel + ma_sma + ma_num + rsi_cols + macd_cols + volu_cols + atr_adx_cols + vola_cols + vix_skew_cols + experimental_slope_cols\n",
    "            list_name = \"initial+atradx\" #worse\n",
    "            list_name = \"initial+sma\" #worse\n",
    "            list_name = \"initial+vixskew\" #much worse\n",
    "            train_years = 5\n",
    "            #cols = atr_adx_cols + vola_cols + experimental_slope_cols + ma_lag + ma_num + ma_rel + ma_sma + rsi_cols + macd_cols + volu_cols + vix_skew_cols\n",
    "        elif r == 10:\n",
    "            base_cols = atr_adx_cols + vola_cols + ma_num + volu_cols + ma_sma\n",
    "            base_cols = ma_lag + ma_rel + ma_sma + ma_num + rsi_cols + macd_cols + volu_cols + atr_adx_cols + vola_cols + vix_skew_cols + experimental_slope_cols\n",
    "            list_name = \"initial+sma\" # better\n",
    "            list_name = \"initial+sma+lag\" #worse\n",
    "            train_years = 5\n",
    "            #cols = atr_adx_cols + vola_cols + ma_num + ma_rel + ma_sma + volu_cols + vix_skew_cols\n",
    "        elif r == 20:\n",
    "            base_cols = atr_adx_cols + vola_cols + ma_num + ma_sma\n",
    "            #base_cols = ma_lag + ma_rel + ma_sma + ma_num + rsi_cols + macd_cols + volu_cols + atr_adx_cols + vola_cols + vix_skew_cols + experimental_slope_cols\n",
    "            list_name = \"initial+volu\" #worse\n",
    "            list_name = \"initial+lag\" #much worse\n",
    "            train_years = 6\n",
    "        else:\n",
    "            base_cols = atr_adx_cols + vola_cols + ma_num + ma_sma + volu_cols + rsi_cols + macd_cols\n",
    "            base_cols = ma_lag + ma_rel + ma_sma + ma_num + rsi_cols + macd_cols + volu_cols + atr_adx_cols + vola_cols + vix_skew_cols + experimental_slope_cols\n",
    "            list_name = \"initial+volu\" #worse\n",
    "            list_name = \"initial-rsimacd+volu\" #better\n",
    "            train_years = 5\n",
    "\n",
    "        target_col = f\"Return_{r}\"\n",
    "        # Trime unknown (recent) outcomes\n",
    "        df_final = df_main.iloc[r:].copy()\n",
    "\n",
    "        base_cols += past_return_cols\n",
    "\n",
    "        perm_cols = perm_list(\n",
    "            df=df_final,\n",
    "            feature_cols=base_cols,\n",
    "            target_col=target_col,\n",
    "            date_col=\"Date\",\n",
    "            train_years=train_years,\n",
    "            test_days=test_day,\n",
    "            step_days=test_day,\n",
    "            purge_days=r, \n",
    "            fill_inf=0.0,\n",
    "        )\n",
    "\n",
    "        print(perm_cols)\n",
    "        #for train_years in train_years_grid:\n",
    "        df_scores = walkback_runs(\n",
    "            df=df_final,\n",
    "            feature_cols=perm_cols,\n",
    "            target_col=target_col,\n",
    "            date_col=\"Date\",\n",
    "            train_years=train_years,\n",
    "            test_days=test_day,\n",
    "            step_days=test_day,\n",
    "            runs=runs,\n",
    "            horizon_days=r,\n",
    "            purge_days=r, \n",
    "            fill_inf=0.0,\n",
    "        )\n",
    "\n",
    "        df_scores[\"feature_set\"] = \"pi_base\" #list_name\n",
    "        df_scores[\"horizon\"] = r\n",
    "\n",
    "        results.append(df_scores)\n",
    "\n",
    "results_df = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"performance.csv\")\n",
    "df.to_csv('performance_backup.csv', index=False)\n",
    "cols = ['model', 'test_days', 'pred', 'acc', 'test_n', 'test_pos_n', 'train_n', 'test_start', 'test_end', 'train_years', 'feature_set', 'horizon']\n",
    "df_new = results_df[cols].copy()\n",
    "df_concat = pd.concat([df, df_new], ignore_index=True)\n",
    "df_concat.to_csv('performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['model', 'test_days', 'pred', 'acc', 'test_n', 'test_pos_n', 'train_n', 'test_start', 'test_end', 'train_years', 'feature_set', 'horizon']\n",
    "df_new = results_df[cols].copy()\n",
    "df_new.to_csv('performance.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
