{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Feature Sets: dict_keys(['ma', 'rsi', 'macd', 'volume', 'atr_adx', 'volatility', 'vix_skew', 'experimental_slope', 'past_return'])\n"
     ]
    }
   ],
   "source": [
    "import performance_flow\n",
    "import importlib\n",
    "importlib.reload(performance_flow)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import train_flow\n",
    "importlib.reload(train_flow)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "ticker = 'QQQ'\n",
    "include_minute_feats = \"N\"\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "df_daily, feature_sets, return_cols, daily_cols, feature_dict, features = train_flow.import_data(ticker, include_minute_feats, returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Run\n",
    "- Retrain ALL models through most recent aod\n",
    "- Calculate performance\n",
    "- Select and save top n\n",
    "- Make predictions\n",
    "- Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 | run_separately | ma_lag-ma_rel | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-ma_sma | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-ma_num | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-rsi_macd | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-volu | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-atr_adxvola | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-vix_skew | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_lag-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-ma_sma | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-ma_num | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-rsi_macd | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-volu | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-atr_adxvola | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-vix_skew | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_rel-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_sma-ma_num | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_sma-rsi_macd | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_sma-volu | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_sma-atr_adxvola | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_sma-vix_skew | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_sma-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_sma-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_num-rsi_macd | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_num-volu | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_num-atr_adxvola | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_num-vix_skew | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_num-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | ma_num-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | rsi_macd-volu | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | rsi_macd-atr_adxvola | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | rsi_macd-vix_skew | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | rsi_macd-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | rsi_macd-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | volu-atr_adxvola | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | volu-vix_skew | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | volu-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | volu-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | atr_adxvola-vix_skew | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | atr_adxvola-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | atr_adxvola-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | vix_skew-experimental_slope | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | vix_skew-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "30 | run_separately | experimental_slope-past_return | 3 | 1.5 | 4 | 4\n",
      "Running actualized predictions for horizon 30 | run_separately\n",
      "Retrainig Done\n",
      "Horizon 30 Top 2 Models Saved\n",
      "30 | run_separately | ma_lag-ma_sma | 3 | 1.5 | 4 | 30\n",
      "Running new predictions for horizon 30 | run_separately\n",
      "Horizon 30 Top 2 Models Predicted\n",
      "30 | run_separately | ma_lag-vix_skew | 3 | 1.5 | 4 | 30\n",
      "Running new predictions for horizon 30 | run_separately\n",
      "Horizon 30 Top 2 Models Predicted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Predicted_Price</th>\n",
       "      <th>Last_Close</th>\n",
       "      <th>LC_R_PP</th>\n",
       "      <th>ensemble_edge</th>\n",
       "      <th>ensemble_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-08</td>\n",
       "      <td>620.47</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-09</td>\n",
       "      <td>626.65</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>627.17</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>626.24</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>619.55</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>621.78</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>621.26</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>608.06</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2026-01-21</td>\n",
       "      <td>616.28</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2026-01-22</td>\n",
       "      <td>620.76</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>622.72</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>625.46</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>631.13</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2026-01-28</td>\n",
       "      <td>633.22</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2026-01-29</td>\n",
       "      <td>629.43</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>621.87</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2026-02-02</td>\n",
       "      <td>626.14</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2026-02-03</td>\n",
       "      <td>616.52</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>605.75</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>597.03</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2026-02-06</td>\n",
       "      <td>609.65</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>614.32</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>611.47</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2026-02-11</td>\n",
       "      <td>613.11</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2026-02-12</td>\n",
       "      <td>600.64</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2026-02-13</td>\n",
       "      <td>601.92</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2026-02-17</td>\n",
       "      <td>601.30</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2026-02-18</td>\n",
       "      <td>605.79</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2026-02-19</td>\n",
       "      <td>603.47</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2026-02-20</td>\n",
       "      <td>608.81</td>\n",
       "      <td>608.81</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Predicted_Price  Last_Close  LC_R_PP  ensemble_edge  \\\n",
       "0   2026-01-08           620.47      608.81   -0.019          -0.13   \n",
       "1   2026-01-09           626.65      608.81   -0.028           0.11   \n",
       "2   2026-01-12           627.17      608.81   -0.029          -0.13   \n",
       "3   2026-01-13           626.24      608.81   -0.028          -0.13   \n",
       "4   2026-01-14           619.55      608.81   -0.017          -0.13   \n",
       "5   2026-01-15           621.78      608.81   -0.021          -0.13   \n",
       "6   2026-01-16           621.26      608.81   -0.020           0.11   \n",
       "7   2026-01-20           608.06      608.81    0.001           0.11   \n",
       "8   2026-01-21           616.28      608.81   -0.012           0.11   \n",
       "9   2026-01-22           620.76      608.81   -0.019           0.56   \n",
       "10  2026-01-23           622.72      608.81   -0.022           0.56   \n",
       "11  2026-01-26           625.46      608.81   -0.027           0.11   \n",
       "12  2026-01-27           631.13      608.81   -0.035           0.11   \n",
       "13  2026-01-28           633.22      608.81   -0.039           0.11   \n",
       "14  2026-01-29           629.43      608.81   -0.033           0.56   \n",
       "15  2026-01-30           621.87      608.81   -0.021           0.56   \n",
       "16  2026-02-02           626.14      608.81   -0.028           0.56   \n",
       "17  2026-02-03           616.52      608.81   -0.013           0.56   \n",
       "18  2026-02-04           605.75      608.81    0.005           0.56   \n",
       "19  2026-02-05           597.03      608.81    0.020           0.56   \n",
       "20  2026-02-06           609.65      608.81   -0.001           0.56   \n",
       "21  2026-02-09           614.32      608.81   -0.009           0.56   \n",
       "22  2026-02-10           611.47      608.81   -0.004           0.56   \n",
       "23  2026-02-11           613.11      608.81   -0.007           0.56   \n",
       "24  2026-02-12           600.64      608.81    0.014           0.56   \n",
       "25  2026-02-13           601.92      608.81    0.011           0.56   \n",
       "26  2026-02-17           601.30      608.81    0.012           0.56   \n",
       "27  2026-02-18           605.79      608.81    0.005           0.56   \n",
       "28  2026-02-19           603.47      608.81    0.009           0.56   \n",
       "29  2026-02-20           608.81      608.81    0.000           0.56   \n",
       "\n",
       "    ensemble_pred  \n",
       "0            0.44  \n",
       "1            0.56  \n",
       "2            0.44  \n",
       "3            0.44  \n",
       "4            0.44  \n",
       "5            0.44  \n",
       "6            0.56  \n",
       "7            0.56  \n",
       "8            0.56  \n",
       "9            0.78  \n",
       "10           0.78  \n",
       "11           0.56  \n",
       "12           0.56  \n",
       "13           0.56  \n",
       "14           0.78  \n",
       "15           0.78  \n",
       "16           0.78  \n",
       "17           0.78  \n",
       "18           0.78  \n",
       "19           0.78  \n",
       "20           0.78  \n",
       "21           0.78  \n",
       "22           0.78  \n",
       "23           0.78  \n",
       "24           0.78  \n",
       "25           0.78  \n",
       "26           0.78  \n",
       "27           0.78  \n",
       "28           0.78  \n",
       "29           0.78  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import deployment_flow, performance_flow\n",
    "import importlib\n",
    "importlib.reload(deployment_flow)\n",
    "importlib.reload(performance_flow)\n",
    "\n",
    "def resolve_feature_cols(feature_set_name: str, features_dict: dict, sep: str = \"-\") -> list[str]:\n",
    "\n",
    "    # --- Kitchen sink case ---\n",
    "    if feature_set_name == \"kitch_sink\":\n",
    "        all_cols = chain.from_iterable(features_dict.values())\n",
    "        # dedupe preserve order\n",
    "        seen = set()\n",
    "        out = []\n",
    "        for c in all_cols:\n",
    "            if c not in seen:\n",
    "                seen.add(c)\n",
    "                out.append(c)\n",
    "        return out\n",
    "\n",
    "    # --- Normal composite case ---\n",
    "    parts = feature_set_name.split(sep)\n",
    "\n",
    "    cols = []\n",
    "    for p in parts:\n",
    "        if p not in features_dict:\n",
    "            raise KeyError(f\"{p} not in features_dict\")\n",
    "        cols.append(features_dict[p])\n",
    "\n",
    "    # flatten + dedupe\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for c in chain.from_iterable(cols):\n",
    "        if c not in seen:\n",
    "            seen.add(c)\n",
    "            out.append(c)\n",
    "\n",
    "    return out\n",
    "\n",
    "h=[30]\n",
    "master_results = []\n",
    "master_preds = []\n",
    "n = 2 # number of top models to select \n",
    "file_ext = \"performance_all\"\n",
    "min_th = 0.55\n",
    "cov_th = 0.75\n",
    "perf_cutoff_date = '2025-09-01'\n",
    "\n",
    "# Retrain ALL\n",
    "for r in h:\n",
    "    \n",
    "    df = pd.read_csv(f\"h{r}_{file_ext}.csv\")\n",
    "    df = df.dropna().copy()\n",
    "    #df = df.rename(columns={\"feature_set\": \"features\"})\n",
    "\n",
    "    df[\"feature_cols\"] = df[\"features\"].apply(lambda x: resolve_feature_cols(x, feature_dict))\n",
    "\n",
    "    grain_cols = [\"horizon\",\"features\",\"train_years\",\"min_feats\",\"pi_size\",\"model\",\"pi_handling\"]\n",
    "\n",
    "    max_train = (\n",
    "        df.groupby(grain_cols, as_index=False)[\"test_start\"]\n",
    "        .max()\n",
    "        .rename(columns={\"test_start\": \"max_test_start\"})\n",
    "    )\n",
    "\n",
    "    models = (\n",
    "        df[grain_cols].drop_duplicates(subset=grain_cols, keep=\"first\")\n",
    "        .merge(df[grain_cols + [\"feature_cols\"]].drop_duplicates(subset=grain_cols), on=grain_cols, how=\"left\")\n",
    "        .merge(max_train, on=grain_cols, how=\"left\")   # <-- this is the missing piece\n",
    "    )\n",
    "    \n",
    "    for row in models.itertuples(index=False):\n",
    "\n",
    "        target_horizon = row.horizon\n",
    "        pi_handling    = 'run_separately' #row.pi_handling\n",
    "        type           = 'Actualized'\n",
    "        feature_cols   = row.feature_cols   # list-of-cols wrapped in a list\n",
    "        list_name      = row.features\n",
    "        train_year     = row.train_years\n",
    "        pi_year        = row.pi_size\n",
    "        min_feat       = row.min_feats\n",
    "        max_test_start = row.max_test_start\n",
    "        days_assessed  = len(df_daily.iloc[r:][df_daily['Date'] > max_test_start].copy())\n",
    "        groups = list_name.split(\"-\")\n",
    "\n",
    "        if days_assessed > 0:\n",
    "\n",
    "            model = XGBClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "            model_name = \"xgboost-3\"\n",
    "\n",
    "            print(f\"{target_horizon} | {pi_handling} | {list_name} | {train_year} | {pi_year} | {min_feat} | {days_assessed}\")\n",
    "            results_df = deployment_flow.run_deploy_flow(days_assessed, r, pi_handling, feature_cols, df_daily, model_name, model,\n",
    "                            train_year, pi_year, min_feat, list_name, feature_dict, groups, type)\n",
    "            \n",
    "            master_results.append(results_df)\n",
    "\n",
    "        else:\n",
    "            1\n",
    "            #print(f\"{list_name} already trained through most recent as_of_date\")\n",
    "    \n",
    "    print(f\"Retrainig Done\")\n",
    "    if len(master_results) > 0: \n",
    "        \n",
    "        master_results_df = pd.concat(master_results, ignore_index=True)\n",
    "        performance_df = pd.read_csv(f\"h{r}_{file_ext}.csv\")\n",
    "        df_concat = pd.concat([performance_df, master_results_df], ignore_index=True)    \n",
    "        df_concat.to_csv(f\"h{r}_{file_ext}.csv\", index=False)\n",
    "\n",
    "# Performance and Top n\n",
    "for r in h:\n",
    "\n",
    "    keys = [\"horizon\", \"features\", \"train_years\", \"min_feats\", \"pi_size\", \"pi_handling\", \"model\"]\n",
    "\n",
    "    results_file_name = f\"h{r}_{file_ext}.csv\" # Match prior cell saved as file name horizon_2_baseline_new\n",
    "    return_cols, perf_df = performance_flow.import_data(results_file_name, df_daily)\n",
    "    perf_df = perf_df[perf_df['test_start'] >= perf_cutoff_date].rename(columns={\"feature_set\": \"features\"})\n",
    "    composite_score = performance_flow.run_performance(perf_df[perf_df['horizon'] == r].dropna(), min_th, cov_th)\n",
    "    bucket_df = performance_flow.bucket_scores(df_daily.dropna(), perf_df[perf_df['horizon'] == r].dropna(), returns, min_th, keys)\n",
    "\n",
    "    top_n = (\n",
    "    composite_score.sort_values(\"composite\", ascending=False)\n",
    "    .drop_duplicates(subset=[\"features\"], keep=\"first\").head(n).copy())\n",
    "\n",
    "    # Ensure dtypes match so the join actually hits\n",
    "    for df in (top_n, perf_df):\n",
    "\n",
    "        df[\"horizon\"] = r\n",
    "        df[\"features\"] = df[\"features\"].astype(str)\n",
    "        df[\"model\"]       = df[\"model\"].astype(str)\n",
    "        df[\"pi_size\"]     = df[\"pi_size\"]\n",
    "        df[\"pi_handling\"]     = df[\"pi_handling\"].astype(str)\n",
    "        df[\"train_years\"] = df[\"train_years\"].astype(int)\n",
    "        df[\"min_feats\"]   = df[\"min_feats\"].astype(int)\n",
    "\n",
    "    # Filter master predictions to only rows matching one of the 10 configs\n",
    "    pred_filtered = perf_df.merge(top_n[keys].drop_duplicates(), on=keys, how=\"inner\")\n",
    "    #print(len(pred_filtered))\n",
    "    pred_filtered.to_csv(f\"h{r}_top{n}_{file_ext}.csv\", index=False)\n",
    "    print(f\"Horizon {r} Top {n} Models Saved\")\n",
    "\n",
    "# Predictions Top n\n",
    "for r in h:\n",
    "    \n",
    "    days_assessed = len(df_daily[df_daily[f\"Return_{r}\"].isna()])\n",
    "\n",
    "    df = pd.read_csv(f\"h{r}_top{n}_{file_ext}.csv\")\n",
    "\n",
    "    df[\"feature_cols\"] = df[\"features\"].apply(lambda x: resolve_feature_cols(x, feature_dict))\n",
    "\n",
    "    grain_cols = [\"horizon\",\"features\",\"train_years\",\"min_feats\",\"pi_size\",\"model\",\"pi_handling\"]\n",
    "\n",
    "    top_n = (\n",
    "        df[grain_cols].drop_duplicates(subset=grain_cols, keep=\"first\")\n",
    "        .merge(df[grain_cols + [\"feature_cols\"]].drop_duplicates(subset=grain_cols), on=grain_cols, how=\"left\"))\n",
    "    \n",
    "    for row in top_n.itertuples(index=False):\n",
    "\n",
    "        target_horizon = row.horizon\n",
    "        pi_handling    = 'run_separately' #row.pi_handling\n",
    "        type           = 'New_Predict'\n",
    "        feature_cols   = row.feature_cols   # list-of-cols wrapped in a list\n",
    "        list_name      = row.features\n",
    "        train_year     = row.train_years\n",
    "        pi_year        = row.pi_size\n",
    "        min_feat       = row.min_feats\n",
    "        groups = list_name.split(\"-\")\n",
    "\n",
    "        model = XGBClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "        model_name = \"xgboost-3\"\n",
    "\n",
    "        print(f\"{target_horizon} | {pi_handling} | {list_name} | {train_year} | {pi_year} | {min_feat} | {days_assessed}\")\n",
    "        results_df = deployment_flow.run_deploy_flow(days_assessed, r, pi_handling, feature_cols, df_daily, model_name, model,\n",
    "                        train_year, pi_year, min_feat, list_name, feature_dict, groups, type)\n",
    "        \n",
    "        master_preds.append(results_df)\n",
    "        print(f\"Horizon {r} Top {n} Models Predicted\")\n",
    "\n",
    "    master_preds_df = pd.concat(master_preds, ignore_index=True)\n",
    "    predictions_df = master_preds_df.copy()\n",
    "    composite_score[['pprec', 'nprec'] + keys].drop_duplicates().merge(predictions_df, on=keys, how=\"inner\")\n",
    "\n",
    "#predictions_df.sort_values(by='test_start', ascending=False).head(n)\n",
    "\n",
    "output_df = composite_score[['pprec', 'nprec'] + keys].drop_duplicates().merge(predictions_df, on=keys, how=\"inner\")\n",
    "output_df = output_df.rename(columns={\"test_start\": \"Date\"})\n",
    "cols = ['Date', 'features', 'pred', 'pprec', 'nprec']\n",
    "output_df = output_df[cols].sort_values(by='Date').copy()\n",
    "output_df = output_df.merge(df_daily[['Close', 'Date']].round(2), on='Date', how=\"inner\")\n",
    "output_df = output_df.rename(columns={\"Close\": \"Predicted_Price\"})\n",
    "last_close = (df_daily.sort_values(\"Date\", ascending=False).iloc[0][\"Close\"].round(2))\n",
    "output_df['Last_Close'] = last_close\n",
    "output_df['LC_R_PP'] = round(output_df['Last_Close'] / output_df['Predicted_Price'] - 1, 3)\n",
    "\n",
    "output_df.loc[output_df['pred'] < 0.45, 'pred'] = output_df['pred'] - 1\n",
    "\n",
    "output_df['pred_edge'] = np.where(output_df['pred'] > 0, output_df['pprec'] - 0.5, -output_df['nprec'] + 0.5).round(2)\n",
    "\n",
    "ensemble_df = (\n",
    "    output_df\n",
    "    .groupby('Date', as_index=False)\n",
    "    .agg({\n",
    "        'Date': 'first',\n",
    "        'Predicted_Price': 'first',\n",
    "        'Last_Close': 'first',\n",
    "        'LC_R_PP': 'first',\n",
    "        'pred_edge': 'sum'\n",
    "    })\n",
    "    .rename(columns={'pred_edge': 'ensemble_edge'})\n",
    ")\n",
    "ensemble_df['ensemble_pred'] = (ensemble_df['ensemble_edge'] / n + .5).round(2)\n",
    "ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>features</th>\n",
       "      <th>pred</th>\n",
       "      <th>pprec</th>\n",
       "      <th>nprec</th>\n",
       "      <th>Predicted_Price</th>\n",
       "      <th>Last_Close</th>\n",
       "      <th>LC_R_PP</th>\n",
       "      <th>pred_edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-08</td>\n",
       "      <td>ma_lag-ma_sma</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>620.47</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-08</td>\n",
       "      <td>ma_lag-vix_skew</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.52</td>\n",
       "      <td>620.47</td>\n",
       "      <td>608.81</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         features  pred  pprec  nprec  Predicted_Price  \\\n",
       "0  2026-01-08    ma_lag-ma_sma -0.90   0.84   0.61           620.47   \n",
       "1  2026-01-08  ma_lag-vix_skew -0.65   0.72   0.52           620.47   \n",
       "\n",
       "   Last_Close  LC_R_PP  pred_edge  \n",
       "0      608.81   -0.019      -0.11  \n",
       "1      608.81   -0.019      -0.02  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df[output_df['Date'] == '2026-01-08']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
