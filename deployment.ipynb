{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dict with top models for each horizon\n",
    "- Trainflow where number of runs equals horizon\n",
    "- Append each training day to master list for performance tracking?\n",
    "- Pull in performance over last n_days (120 min?, 30 and 10?)\n",
    "    - Focused on precision\n",
    "- Also ensemble scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Feature Sets: dict_keys(['ma', 'rsi', 'macd', 'volume', 'atr_adx', 'volatility', 'vix_skew', 'experimental_slope', 'past_return'])\n"
     ]
    }
   ],
   "source": [
    "import performance_flow\n",
    "import importlib\n",
    "importlib.reload(performance_flow)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import train_flow\n",
    "importlib.reload(train_flow)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "ticker = 'QQQ'\n",
    "include_minute_feats = \"N\"\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "df_daily, feature_sets, return_cols, daily_cols, feature_dict, features = train_flow.import_data(ticker, include_minute_feats, returns)\n",
    "\n",
    "# ---------- #\n",
    "# UPDATE ME  #\n",
    "# ---------- #\n",
    "# Add any new features\n",
    "#df_daily[[f\"{c}_sum10\" for c in df_daily.columns if c.startswith(\"Past_Return_\")]] = (df_daily.sort_values(by=\"Date\", ascending=True).filter(like=\"Past_Return_\").rolling(10, min_periods=1).sum())\n",
    "#past_ret_cols = [c for c in df_daily.columns if c.startswith(\"Past_Return%\") or c.endswith(\"sum10\")]\n",
    "#past_perc_cols = [c for c in df_daily.columns if c.startswith(\"Past_Return%\")]\n",
    "#past_sum_cols = [c for c in df_daily.columns if c.endswith(\"sum10\")]\n",
    "#cutoff_date = '2026-02-06' # Unlessretraining all baseline models, leave alone\n",
    "\n",
    "# --------- #\n",
    "# LEAVE ME  #\n",
    "# --------- #\n",
    "#df_main = df_daily[df_daily['Date'] <= cutoff_date].copy() #cutoff date for baseline performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Top Models per Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(performance_flow)\n",
    "# ---------- #\n",
    "# UPDATE ME  #\n",
    "# ---------- #\n",
    "min_th = 0.55\n",
    "cov_th = 0.75\n",
    "horizons = [2, 5, 10, 20, 30]\n",
    "\n",
    "for r in horizons:\n",
    "    \n",
    "    results_file_name = f\"h{r}_baseline.csv\" # Match prior cell saved as file name horizon_2_baseline_new\n",
    "    return_cols, perf_df = performance_flow.import_data(results_file_name, df_main)\n",
    "    composite_score = performance_flow.run_performance(perf_df[perf_df['horizon'] == r], min_th, cov_th)\n",
    "    bucket_df = performance_flow.bucket_scores(df_main, perf_df[perf_df['horizon'] == r], returns, min_th)\n",
    "\n",
    "    top_10_r = (\n",
    "    composite_score.sort_values(\"composite\", ascending=False)\n",
    "    .drop_duplicates(subset=[\"features\"], keep=\"first\").head(10).copy())\n",
    "\n",
    "    keys = [\"horizon\", \"features\", \"train_years\", \"min_feats\", \"pi_size\", \"pi_handling\", \"model\"]\n",
    "\n",
    "    # Ensure dtypes match so the join actually hits\n",
    "    for df in (top_10_r, perf_df):\n",
    "\n",
    "        df[\"horizon\"] = r\n",
    "        df[\"features\"] = df[\"features\"].astype(str)\n",
    "        df[\"model\"]       = df[\"model\"].astype(str)\n",
    "        df[\"pi_size\"]     = df[\"pi_size\"]\n",
    "        df[\"pi_handling\"]     = df[\"pi_handling\"].astype(str)\n",
    "        df[\"train_years\"] = df[\"train_years\"].astype(int)\n",
    "        df[\"min_feats\"]   = df[\"min_feats\"].astype(int)\n",
    "\n",
    "    # Filter master predictions to only rows matching one of the 10 configs\n",
    "    pred_filtered = perf_df.merge(top_10_r[keys].drop_duplicates(), on=keys, how=\"inner\")\n",
    "    #print(len(pred_filtered))\n",
    "    pred_filtered.to_csv(f\"h{r}_top10_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 | include_new | ma_sma | 6 | 1.5 | 8 | 126\n",
      "Running for horizon 30 | include_new\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_25']\n",
      "Run 1/126 | Train: 2020-01-13 → 2025-11-14 | Test: 2025-12-31 → 2025-12-31 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_25']\n",
      "Run 2/126 | Train: 2020-01-10 → 2025-11-13 | Test: 2025-12-30 → 2025-12-30 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '25_SMA_200', '50_SMA_100', 'SMA_100', 'SMA_25']\n",
      "Run 3/126 | Train: 2020-01-09 → 2025-11-12 | Test: 2025-12-29 → 2025-12-29 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 9 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_200', 'SMA_25']\n",
      "Run 4/126 | Train: 2020-01-08 → 2025-11-11 | Test: 2025-12-26 → 2025-12-26 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 9 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '25_SMA_200', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_200']\n",
      "Run 5/126 | Train: 2020-01-07 → 2025-11-10 | Test: 2025-12-24 → 2025-12-24 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_200']\n",
      "Run 6/126 | Train: 2020-01-06 → 2025-11-07 | Test: 2025-12-23 → 2025-12-23 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 9 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_200', 'SMA_25']\n",
      "Run 7/126 | Train: 2020-01-03 → 2025-11-06 | Test: 2025-12-22 → 2025-12-22 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_25']\n",
      "Run 8/126 | Train: 2020-01-02 → 2025-11-05 | Test: 2025-12-19 → 2025-12-19 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '25_SMA_50', '50_SMA_100', '50_SMA_200', 'SMA_200']\n",
      "Run 9/126 | Train: 2019-12-31 → 2025-11-04 | Test: 2025-12-18 → 2025-12-18 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '50_SMA_100', '50_SMA_200', 'SMA_100', 'SMA_200']\n",
      "Run 10/126 | Train: 2019-12-30 → 2025-11-03 | Test: 2025-12-17 → 2025-12-17 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "15 | 8 | All Cols: ['100_SMA_200', '10_SMA_100', '10_SMA_50', '25_SMA_100', '25_SMA_200', '50_SMA_100', '50_SMA_200', 'SMA_100']\n",
      "Run 11/126 | Train: 2019-12-27 → 2025-10-31 | Test: 2025-12-16 → 2025-12-16 | Train_n=1470 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/brettchase/Stocks/deployment.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brettchase/Stocks/deployment.ipynb#X31sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxgboost-3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brettchase/Stocks/deployment.ipynb#X31sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtarget_horizon\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mpi_handling\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mlist_name\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mtrain_year\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mpi_year\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mmin_feat\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mdays_assessed\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brettchase/Stocks/deployment.ipynb#X31sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m results_df \u001b[39m=\u001b[39m deployment_flow\u001b[39m.\u001b[39;49mrun_deploy_flow(days_assessed, r, pi_handling, feature_cols, df_daily, model_name, model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brettchase/Stocks/deployment.ipynb#X31sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m                 train_year, pi_year, min_feat, list_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brettchase/Stocks/deployment.ipynb#X31sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m performance_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m_baseline.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brettchase/Stocks/deployment.ipynb#X31sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m df_concat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([performance_df, results_df], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)    \n",
      "File \u001b[0;32m~/Stocks/deployment_flow.py:227\u001b[0m, in \u001b[0;36mrun_deploy_flow\u001b[0;34m(days_assessed, r, pi_handling, feature_cols, df, model_name, model, train_year, pi_year, min_feat, list_name)\u001b[0m\n\u001b[1;32m    223\u001b[0m df_final \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[r:]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    225\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRunning for horizon \u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mpi_handling\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 227\u001b[0m df_scores \u001b[39m=\u001b[39m walkback_runs(\n\u001b[1;32m    228\u001b[0m     df\u001b[39m=\u001b[39;49mdf_final,\n\u001b[1;32m    229\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    230\u001b[0m     model_name\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m    231\u001b[0m     feature_cols\u001b[39m=\u001b[39;49mbase_cols,\n\u001b[1;32m    232\u001b[0m     target_col\u001b[39m=\u001b[39;49mtarget_col,\n\u001b[1;32m    233\u001b[0m     pi_year\u001b[39m=\u001b[39;49mpi_year,\n\u001b[1;32m    234\u001b[0m     date_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    235\u001b[0m     train_years\u001b[39m=\u001b[39;49mtrain_year,\n\u001b[1;32m    236\u001b[0m     test_days\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    237\u001b[0m     step_days\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    238\u001b[0m     runs\u001b[39m=\u001b[39;49mruns,\n\u001b[1;32m    239\u001b[0m     purge_days\u001b[39m=\u001b[39;49mr, \n\u001b[1;32m    240\u001b[0m     fill_inf\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m    241\u001b[0m     min_feat\u001b[39m=\u001b[39;49mmin_feat,\n\u001b[1;32m    242\u001b[0m     pi_handling\u001b[39m=\u001b[39;49mpi_handling,\n\u001b[1;32m    243\u001b[0m )\n\u001b[1;32m    245\u001b[0m df_scores[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m list_name\n\u001b[1;32m    246\u001b[0m df_scores[\u001b[39m\"\u001b[39m\u001b[39mhorizon\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m r\n",
      "File \u001b[0;32m~/Stocks/deployment_flow.py:135\u001b[0m, in \u001b[0;36mwalkback_runs\u001b[0;34m(df, model, model_name, feature_cols, target_col, pi_year, date_col, train_years, test_days, step_days, runs, purge_days, fill_inf, min_feat, pi_handling, new_features)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39m#pi_value = f\"{str(pi_year)}-{pi_handling[0]}\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39melif\u001b[39;00m pi_handling \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39minclude_new\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     perm_cols, p_df \u001b[39m=\u001b[39m train_flow\u001b[39m.\u001b[39;49mperm_list(\n\u001b[1;32m    136\u001b[0m         df\u001b[39m=\u001b[39;49mdfpi,\n\u001b[1;32m    137\u001b[0m         feature_cols\u001b[39m=\u001b[39;49mfeature_cols,\n\u001b[1;32m    138\u001b[0m         target_col\u001b[39m=\u001b[39;49mtarget_col,\n\u001b[1;32m    139\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    140\u001b[0m         fill_inf\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m    141\u001b[0m         pi_year\u001b[39m=\u001b[39;49mpi_year,\n\u001b[1;32m    142\u001b[0m         min_feats\u001b[39m=\u001b[39;49mmin_feat\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    145\u001b[0m     \u001b[39m#pi_value = f\"{str(pi_year)}-{pi_handling[0]}\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(feature_cols)\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(perm_cols)\u001b[39m}\u001b[39;00m\u001b[39m | All Cols: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msorted\u001b[39m(perm_cols)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Stocks/train_flow.py:328\u001b[0m, in \u001b[0;36mperm_list\u001b[0;34m(df, feature_cols, target_col, model, fill_inf, pi_year, min_feats, feat_type)\u001b[0m\n\u001b[1;32m    325\u001b[0m y_pi \u001b[39m=\u001b[39m y_train[\u001b[39m-\u001b[39mN_PI:]\n\u001b[1;32m    327\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m m \u001b[39m=\u001b[39m clone(model)\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m    330\u001b[0m \u001b[39m# permutation importance on training-only slice\u001b[39;00m\n\u001b[1;32m    331\u001b[0m pi \u001b[39m=\u001b[39m permutation_importance(\n\u001b[1;32m    332\u001b[0m     m,\n\u001b[1;32m    333\u001b[0m     X_pi,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1532\u001b[0m     params,\n\u001b[1;32m   1533\u001b[0m     train_dmatrix,\n\u001b[1;32m   1534\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1535\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1536\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1537\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1538\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1539\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1540\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1541\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1542\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[1;32m   1543\u001b[0m )\n\u001b[1;32m   1545\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, iteration\u001b[39m=\u001b[39;49mi, fobj\u001b[39m=\u001b[39;49mobj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[1;32m   2102\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[1;32m   2103\u001b[0m         )\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import deployment_flow\n",
    "import importlib\n",
    "importlib.reload(deployment_flow)\n",
    "\n",
    "def resolve_feature_cols(feature_set_name: str, features_dict: dict, sep: str = \"-\") -> list[str]:\n",
    "\n",
    "    # --- Kitchen sink case ---\n",
    "    if feature_set_name == \"kitch_sink\":\n",
    "        all_cols = chain.from_iterable(features_dict.values())\n",
    "        # dedupe preserve order\n",
    "        seen = set()\n",
    "        out = []\n",
    "        for c in all_cols:\n",
    "            if c not in seen:\n",
    "                seen.add(c)\n",
    "                out.append(c)\n",
    "        return out\n",
    "\n",
    "    # --- Normal composite case ---\n",
    "    parts = feature_set_name.split(sep)\n",
    "\n",
    "    cols = []\n",
    "    for p in parts:\n",
    "        if p not in features_dict:\n",
    "            raise KeyError(f\"{p} not in features_dict\")\n",
    "        cols.append(features_dict[p])\n",
    "\n",
    "    # flatten + dedupe\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for c in chain.from_iterable(cols):\n",
    "        if c not in seen:\n",
    "            seen.add(c)\n",
    "            out.append(c)\n",
    "\n",
    "    return out\n",
    "\n",
    "h=[30]\n",
    "for r in h:\n",
    "    \n",
    "    df = pd.read_csv(f\"h{r}_top10_raw.csv\")\n",
    "    df[\"feature_cols\"] = df[\"features\"].apply(\n",
    "        lambda x: resolve_feature_cols(x, feature_dict)\n",
    "    )\n",
    "\n",
    "    grain_cols = [\"horizon\", \"features\", \"train_years\", \"min_feats\", \"pi_size\", \"model\", \"pi_handling\", \"test_start\"]\n",
    "    top_10_unique = (df[grain_cols].sort_values(by='test_start', ascending=True).drop_duplicates(subset=grain_cols, keep=\"first\").copy())\n",
    "\n",
    "    top_10_unique = (\n",
    "        top_10_unique.merge(\n",
    "            df[grain_cols + [\"feature_cols\"]].drop_duplicates(subset=grain_cols),\n",
    "            on=grain_cols,\n",
    "            how=\"left\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for row in top_10_unique.itertuples(index=False):\n",
    "\n",
    "        target_horizon = row.horizon\n",
    "        pi_handling    = 'include_new' #row.pi_handling\n",
    "        feature_cols   = row.feature_cols   # list-of-cols wrapped in a list\n",
    "        list_name      = row.features\n",
    "        train_year     = row.train_years\n",
    "        pi_year        = row.pi_size\n",
    "        min_feat       = 8 #row.min_feats\n",
    "        max_train_date = row.test_start\n",
    "        days_assessed  = len(df_daily.iloc[r:][df_daily['Date'] > max_train_date].copy())\n",
    "\n",
    "        model = XGBClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "        model_name = \"xgboost-3\"\n",
    "\n",
    "        print(f\"{target_horizon} | {pi_handling} | {list_name} | {train_year} | {pi_year} | {min_feat} | {days_assessed}\")\n",
    "        results_df = deployment_flow.run_deploy_flow(days_assessed, r, pi_handling, feature_cols, df_daily, model_name, model,\n",
    "                        train_year, pi_year, min_feat, list_name)\n",
    "\n",
    "        performance_df = pd.read_csv(f\"h{r}_baseline.csv\")\n",
    "        df_concat = pd.concat([performance_df, results_df], ignore_index=True)    \n",
    "        df_concat.to_csv(f\"h{r}_baseline_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model</th>\n",
       "      <th>train_years</th>\n",
       "      <th>features</th>\n",
       "      <th>pi_size</th>\n",
       "      <th>pi_handling</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>records</th>\n",
       "      <th>bal_prec</th>\n",
       "      <th>bal_prec_|0.75|</th>\n",
       "      <th>brier</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>mcc</th>\n",
       "      <th>pprec</th>\n",
       "      <th>nprec</th>\n",
       "      <th>cov_|0.75|</th>\n",
       "      <th>pprec_|0.75|</th>\n",
       "      <th>nprec_|0.75|</th>\n",
       "      <th>composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_sma-experimental_slope</td>\n",
       "      <td>1.5</td>\n",
       "      <td>run_separately</td>\n",
       "      <td>4</td>\n",
       "      <td>0.81</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag-experimental_slope</td>\n",
       "      <td>1.5</td>\n",
       "      <td>run_separately</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.13</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag-ma_sma</td>\n",
       "      <td>1.5</td>\n",
       "      <td>run_separately</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_sma-vix_skew</td>\n",
       "      <td>1.5</td>\n",
       "      <td>run_separately</td>\n",
       "      <td>4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_sma-past_return</td>\n",
       "      <td>1.5</td>\n",
       "      <td>run_separately</td>\n",
       "      <td>4</td>\n",
       "      <td>0.81</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>ma_sma</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>100</td>\n",
       "      <td>0.83</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag-past_return</td>\n",
       "      <td>1.5</td>\n",
       "      <td>run_separately</td>\n",
       "      <td>4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>6</td>\n",
       "      <td>ma_sma</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_sma-rsi_macd</td>\n",
       "      <td>1.5</td>\n",
       "      <td>run_separately</td>\n",
       "      <td>4</td>\n",
       "      <td>0.81</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-3</td>\n",
       "      <td>4</td>\n",
       "      <td>ma_sma</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     horizon      model  train_years                   features  pi_size  \\\n",
       "82        30  xgboost-3            5  ma_sma-experimental_slope      1.5   \n",
       "69        30  xgboost-3            5  ma_lag-experimental_slope      1.5   \n",
       "63        30  xgboost-3            5              ma_lag-ma_sma      1.5   \n",
       "81        30  xgboost-3            5            ma_sma-vix_skew      1.5   \n",
       "100       30  xgboost-3            5         ma_sma-past_return      1.5   \n",
       "25        30  xgboost-3            6                     ma_sma      1.5   \n",
       "98        30  xgboost-3            5         ma_lag-past_return      1.5   \n",
       "45        30  xgboost-3            6                     ma_sma      1.5   \n",
       "78        30  xgboost-3            5            ma_sma-rsi_macd      1.5   \n",
       "24        30  xgboost-3            4                     ma_sma      1.5   \n",
       "\n",
       "        pi_handling  min_feats  pos_rate  records  bal_prec  bal_prec_|0.75|  \\\n",
       "82   run_separately          4      0.81    117.0      0.72             0.73   \n",
       "69   run_separately          4      0.83    116.0      0.71             0.69   \n",
       "63   run_separately          4      0.83    116.0      0.70             0.71   \n",
       "81   run_separately          4      0.82    113.0      0.70             0.72   \n",
       "100  run_separately          4      0.81    116.0      0.69             0.72   \n",
       "25      include_new        100      0.83    117.0      0.69             0.67   \n",
       "98   run_separately          4      0.82    118.0      0.69             0.70   \n",
       "45      include_new          6      0.84    118.0      0.68             0.71   \n",
       "78   run_separately          4      0.81    115.0      0.68             0.69   \n",
       "24      include_new        100      0.85    113.0      0.67             0.66   \n",
       "\n",
       "     brier  log_loss   mcc  pprec  nprec  cov_|0.75|  pprec_|0.75|  \\\n",
       "82    0.20      3.29  0.54   0.99   0.45        0.95          0.98   \n",
       "69    0.19      4.13  0.53   0.97   0.45        0.94          0.97   \n",
       "63    0.18      4.63  0.51   0.96   0.45        0.96          0.96   \n",
       "81    0.19      1.98  0.50   0.97   0.42        0.89          0.97   \n",
       "100   0.21      3.34  0.47   0.96   0.42        0.91          0.97   \n",
       "25    0.23      5.00  0.49   0.99   0.39        0.94          0.98   \n",
       "98    0.19      4.83  0.46   0.94   0.44        0.88          0.97   \n",
       "45    0.18      2.42  0.45   0.95   0.41        0.90          0.97   \n",
       "78    0.26      4.09  0.46   0.98   0.38        0.93          0.98   \n",
       "24    0.24      5.49  0.47   0.99   0.36        0.95          0.98   \n",
       "\n",
       "     nprec_|0.75|  composite  \n",
       "82           0.47       0.67  \n",
       "69           0.42       0.65  \n",
       "63           0.46       0.65  \n",
       "81           0.47       0.64  \n",
       "100          0.46       0.63  \n",
       "25           0.36       0.63  \n",
       "98           0.44       0.62  \n",
       "45           0.44       0.62  \n",
       "78           0.40       0.61  \n",
       "24           0.34       0.61  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composite_score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for horizon 2 | include_new\n",
      "71 | 8 | All Cols: ['Close_slope10', 'SMA_10_Lag100_min', 'SMA_10_Lag10_max', 'SMA_10_Lag200_min', 'Williams_%R_5', 'Zscore_10', 'Zscore_5', 'Zscore_50']\n",
      "Run 1/5 | Train: 2021-03-24 → 2026-02-06 | Test: 2026-02-11 → 2026-02-11 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "71 | 8 | All Cols: ['CCI_14', 'Close_slope10', 'Close_slope25', 'SMA_10_Lag200_min', 'Williams_%R_5', 'Zscore_10', 'Zscore_5', 'Zscore_50']\n",
      "Run 2/5 | Train: 2021-03-23 → 2026-02-05 | Test: 2026-02-10 → 2026-02-10 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "71 | 8 | All Cols: ['Close_slope10', 'Close_slope25', 'SMA_10_Lag10_max', 'SMA_10_Lag200_min', 'Williams_%R_5', 'Zscore_10', 'Zscore_5', 'Zscore_50']\n",
      "Run 3/5 | Train: 2021-03-22 → 2026-02-04 | Test: 2026-02-09 → 2026-02-09 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "71 | 8 | All Cols: ['CCI_14', 'Close_slope10', 'Close_slope25', 'SMA_10_Lag200_min', 'SMA_50_Lag150_min', 'Williams_%R_5', 'Zscore_10', 'Zscore_50']\n",
      "Run 4/5 | Train: 2021-03-19 → 2026-02-03 | Test: 2026-02-06 → 2026-02-06 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n",
      "71 | 8 | All Cols: ['CCI_5', 'Close_slope10', 'Close_slope50', 'SMA_10_Lag10_max', 'SMA_10_Lag200_min', 'Zscore_10', 'Zscore_5', 'Zscore_50']\n",
      "Run 5/5 | Train: 2021-03-18 → 2026-02-02 | Test: 2026-02-05 → 2026-02-05 | Train_n=1225 | Test_n=1 | (PI Years: 1.5 - Feats: 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>model</th>\n",
       "      <th>test_days</th>\n",
       "      <th>pred</th>\n",
       "      <th>acc</th>\n",
       "      <th>test_n</th>\n",
       "      <th>test_pos_n</th>\n",
       "      <th>test_neg_n</th>\n",
       "      <th>test_pos_frac</th>\n",
       "      <th>test_neg_frac</th>\n",
       "      <th>...</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>train_years</th>\n",
       "      <th>n_features</th>\n",
       "      <th>pi_size</th>\n",
       "      <th>pi_handling</th>\n",
       "      <th>min_feats</th>\n",
       "      <th>features</th>\n",
       "      <th>horizon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>xgboost-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-06</td>\n",
       "      <td>2026-02-11</td>\n",
       "      <td>2026-02-11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>8</td>\n",
       "      <td>ma_lag-experimental_slope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>8</td>\n",
       "      <td>ma_lag-experimental_slope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>xgboost-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>8</td>\n",
       "      <td>ma_lag-experimental_slope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>xgboost-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-03</td>\n",
       "      <td>2026-02-06</td>\n",
       "      <td>2026-02-06</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>8</td>\n",
       "      <td>ma_lag-experimental_slope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>xgboost-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2026-02-02</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>include_new</td>\n",
       "      <td>8</td>\n",
       "      <td>ma_lag-experimental_slope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run      model  test_days  pred  acc  test_n  test_pos_n  test_neg_n  \\\n",
       "0    1  xgboost-1          1  0.80  0.0       1           0           1   \n",
       "1    2  xgboost-1          1  0.30  1.0       1           0           1   \n",
       "2    3  xgboost-1          1  0.00  1.0       1           0           1   \n",
       "3    4  xgboost-1          1  0.05  0.0       1           1           0   \n",
       "4    5  xgboost-1          1  0.70  1.0       1           1           0   \n",
       "\n",
       "   test_pos_frac  test_neg_frac  ...   train_end  test_start    test_end  \\\n",
       "0            0.0            1.0  ...  2026-02-06  2026-02-11  2026-02-11   \n",
       "1            0.0            1.0  ...  2026-02-05  2026-02-10  2026-02-10   \n",
       "2            0.0            1.0  ...  2026-02-04  2026-02-09  2026-02-09   \n",
       "3            1.0            0.0  ...  2026-02-03  2026-02-06  2026-02-06   \n",
       "4            1.0            0.0  ...  2026-02-02  2026-02-05  2026-02-05   \n",
       "\n",
       "  train_years n_features  pi_size  pi_handling  min_feats  \\\n",
       "0           5          8      1.5  include_new          8   \n",
       "1           5          8      1.5  include_new          8   \n",
       "2           5          8      1.5  include_new          8   \n",
       "3           5          8      1.5  include_new          8   \n",
       "4           5          8      1.5  include_new          8   \n",
       "\n",
       "                    features  horizon  \n",
       "0  ma_lag-experimental_slope        2  \n",
       "1  ma_lag-experimental_slope        2  \n",
       "2  ma_lag-experimental_slope        2  \n",
       "3  ma_lag-experimental_slope        2  \n",
       "4  ma_lag-experimental_slope        2  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "grain_cols = [\"horizon\", \"features\", \"train_years\", \"min_feats\", \"pi_size\", \"model\", \"pi_handling\", \"test_start\"]\n",
    "top_10_unique = (df[grain_cols].sort_values(by='test_start', ascending=True).drop_duplicates(subset=grain_cols, keep=\"first\").copy())\n",
    "\n",
    "top_10_unique = (\n",
    "    top_10_unique.merge(\n",
    "        df[grain_cols + [\"feature_cols\"]].drop_duplicates(subset=grain_cols),\n",
    "        on=grain_cols,\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "r = 2\n",
    "for row in top_10_unique.itertuples(index=False):\n",
    "\n",
    "    target_horizon = row.horizon\n",
    "    pi_handling    = 'include_new' #row.pi_handling\n",
    "    feature_cols   = row.feature_cols   # list-of-cols wrapped in a list\n",
    "    list_name      = row.features\n",
    "    train_year     = row.train_years\n",
    "    pi_year        = row.pi_size\n",
    "    min_feat       = 8 #row.min_feats\n",
    "    max_train_date = row.test_start\n",
    "    days_assessed  = len(df_daily.iloc[r:][df_daily['Date'] > max_train_date].copy())\n",
    "\n",
    "model = XGBClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "model_name = \"xgboost-3\"\n",
    "\n",
    "#print(f\"{target_horizon} | {pi_handling} | {list_name} | {train_year} | {pi_year} | {min_feat} | {days_assessed} | {feature_cols}\")\n",
    "results_df = deployment_flow.run_deploy_flow(days_assessed, r, pi_handling, feature_cols, df_daily, model_name, model,\n",
    "                   train_year, pi_year, min_feat, list_name)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train through most recent actualized data (Done)\n",
    "- Append all actuals to raw files\n",
    "- Recalc performance\n",
    "- Predict on new horizon\n",
    "- Show prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_csvs():\n",
    "    \n",
    "    for r in returns:\n",
    "        \n",
    "        past_performance = pd.read_csv(f\"h{r}_baseline.csv\") # Match prior cell saved as file name horizon_2_baseline_new\n",
    "        \"\"\"\n",
    "        past_performance[\"features\"] = (\n",
    "        past_performance[\"feature_set\"]\n",
    "            .str.replace(\"_ba$\", \"\", regex=True)\n",
    "            .str.replace(\"-baseline$\", \"\", regex=True)\n",
    "            .str.replace(\"-pr$\", \"-past_return\", regex=True)\n",
    "            .str.replace(\"past_ret_cols\", \"past_return\", regex=False)\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        past_performance[\"pi_handling\"] = (\n",
    "        past_performance[\"pi_size\"]\n",
    "        .str.replace(\"1.5-r\", \"run_separately\", regex=False)\n",
    "        .str.replace(\"1.5\", \"include_new\", regex=False)\n",
    "        )\n",
    "\n",
    "        past_performance[\"pi_size\"] = 1.5\n",
    "        past_performance.to_csv(f\"h{r}_baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
