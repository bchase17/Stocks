{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5513588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import min_features, daily_return\n",
    "import importlib\n",
    "importlib.reload(min_features)\n",
    "importlib.reload(daily_return)\n",
    "\n",
    "perf_df = pd.read_csv(\"all_sets.csv\")\n",
    "perf_df['Date'] = perf_df['test_start']\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "df_daily, feats = daily_return.pull_daily('QQQ', returns) \n",
    "return_cols = df_daily.columns[df_daily.columns.str.contains(\"Return_\")].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "743fa500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Feature Sets: dict_keys(['ma', 'rsi', 'macd', 'volume', 'atr_adx', 'volatility', 'vix_skew', 'experimental_slope'])\n",
      "\n",
      "Horizon 2\n",
      "  ma_lag-rsi_macd: 100 cols\n",
      "  ma_no_rel_aa_volu: 116 cols\n",
      "\n",
      "Horizon 5\n",
      "  ma_lag-rsi_macd: 100 cols\n",
      "  ma_no_rel_aa_volu: 116 cols\n",
      "\n",
      "Horizon 10\n",
      "  ma_lag-rsi_macd: 100 cols\n",
      "  ma_no_rel_aa_volu: 116 cols\n",
      "\n",
      "Horizon 20\n",
      "  ma_lag-rsi_macd: 100 cols\n",
      "  ma_no_rel_aa_volu: 116 cols\n",
      "\n",
      "Horizon 30\n",
      "  ma_lag-rsi_macd: 100 cols\n",
      "  ma_no_rel_aa_volu: 116 cols\n"
     ]
    }
   ],
   "source": [
    "# feature_lists maps feature_set NAME -> list of column names\n",
    "# top_models has columns: [\"horizon\", \"feature_set\"]\n",
    "\n",
    "min_feats = \"N\"\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "\n",
    "if min_feats != 'N':\n",
    "    df_min = min_features.min_features()\n",
    "    df_daily, feature_sets = daily_return.pull_daily('QQQ', returns) \n",
    "\n",
    "    df_main = pd.merge(df_min, df_daily, how='inner', on='Date')\n",
    "    df_main = df_main.sort_values(by='Date', ascending=False)\n",
    "\n",
    "    return_cols = df_main.columns[df_main.columns.str.contains(\"Return_\")].to_list()\n",
    "    daily_cols = [\n",
    "        c for c in df_daily.iloc[:, 1:].columns\n",
    "        if \"return\" not in c.lower()\n",
    "    ]\n",
    "    close_cols = df_min.columns[(df_min.columns.str.contains(\"close_\")) | (df_min.columns.str.contains(\"post_\")) | (df_min.columns.str.contains(\"overnight_\"))].to_list()\n",
    "    min_cols = (\n",
    "        df_min\n",
    "        .loc[:, ~df_min.columns.isin(close_cols)]  # drop close_ columns\n",
    "        .iloc[:, 1:]                               # drop first column\n",
    "        .columns\n",
    "        .to_list()\n",
    "    )\n",
    "else:\n",
    "    df_daily, feature_sets = daily_return.pull_daily('QQQ', returns) \n",
    "    return_cols = df_daily.columns[df_daily.columns.str.contains(\"Return_\")].to_list()\n",
    "    daily_cols = [\n",
    "        c for c in df_daily.iloc[:, 1:].columns\n",
    "        if \"return\" not in c.lower()\n",
    "    ]\n",
    "    df_main = df_daily[df_daily['Date'] <= '2026-01-21'].copy()\n",
    "\n",
    "top_models = pd.read_csv(\"top_performers2.csv\")\n",
    "print(f'Available Feature Sets: {feature_sets.keys()}')\n",
    "\n",
    "ma_all_cols = feature_sets['ma']\n",
    "rsi_cols = feature_sets['rsi']\n",
    "macd_cols = feature_sets['macd']\n",
    "volu_cols = feature_sets['volume']\n",
    "atr_adx_cols = feature_sets['atr_adx']\n",
    "vola_cols = feature_sets['volatility']\n",
    "#ma_no_days_cols = [c for c in ma_all_cols if not c.startswith(\"num_days\")]\n",
    "\n",
    "ma_no_lag = [c for c in ma_all_cols if \"lag_\" not in c.lower()]\n",
    "ma_lag = [c for c in ma_all_cols if \"rel_\" not in c.lower()]\n",
    "ma_no_rel = [c for c in ma_lag if \"rel_\" not in c.lower()]\n",
    "ma_no_rel_rsi = ma_no_rel + rsi_cols\n",
    "ma_lag_rsi = ma_lag + rsi_cols\n",
    "ma_no_rel_macd = ma_no_rel + macd_cols\n",
    "ma_lag_rsi_macd = ma_lag_rsi + macd_cols\n",
    "ma_no_rel_volu = ma_no_rel + volu_cols\n",
    "ma_no_rel_aa = ma_no_rel + atr_adx_cols\n",
    "ma_lag_aa = ma_lag + atr_adx_cols\n",
    "\n",
    "feature_lists = {\n",
    "    \"ma_lag-rsi_macd\": ma_lag_rsi_macd,\n",
    "    \"ma_no_rel_aa_volu\": ma_no_rel_aa + volu_cols,\n",
    "}\n",
    "\n",
    "# build: horizon -> { feature_set_name -> columns_list }\n",
    "horizon_feature_cols = {\n",
    "    r: {\n",
    "        fs: feature_lists[fs]\n",
    "        for fs in top_models.loc[top_models[\"horizon\"] == r, \"feature_set\"].unique()\n",
    "        if fs in feature_lists\n",
    "    }\n",
    "    for r in top_models[\"horizon\"].unique()\n",
    "}\n",
    "\n",
    "# (optional) quick validation print\n",
    "for r, fs_map in horizon_feature_cols.items():\n",
    "    print(f\"\\nHorizon {r}\")\n",
    "    for fs_name, cols in fs_map.items():\n",
    "        print(f\"  {fs_name}: {len(cols)} cols\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ccd8fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model</th>\n",
       "      <th>train_years</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>n_1_c</th>\n",
       "      <th>acc_1_c</th>\n",
       "      <th>n_-1_c</th>\n",
       "      <th>acc_-1_c</th>\n",
       "      <th>bal_acc_1_o</th>\n",
       "      <th>bal_acc_2_o</th>\n",
       "      <th>bal_acc_3_o</th>\n",
       "      <th>bal_acc_3p_o</th>\n",
       "      <th>wba_open</th>\n",
       "      <th>wba_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>volu</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>atr_adxvola</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>volu</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>rsi_macd</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>experimental_slope</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>30</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>vix_skew</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_rel</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>30</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_rel</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    horizon          model  train_years         feature_set  n_1_c  acc_1_c  \\\n",
       "8         2  random_forest            5                volu   35.0     0.69   \n",
       "0         2  random_forest            5         atr_adxvola   35.0     0.74   \n",
       "17        2        xgboost            5                volu   35.0     0.60   \n",
       "6         2  random_forest            5            rsi_macd   35.0     0.74   \n",
       "10        2        xgboost            5  experimental_slope   35.0     0.69   \n",
       "..      ...            ...          ...                 ...    ...      ...   \n",
       "56       30  random_forest            5              ma_lag    6.0     0.17   \n",
       "70       30        xgboost            5            vix_skew    6.0     0.83   \n",
       "67       30        xgboost            5              ma_rel    6.0     0.17   \n",
       "58       30  random_forest            5              ma_rel    6.0     0.17   \n",
       "65       30        xgboost            5              ma_lag    6.0     0.17   \n",
       "\n",
       "    n_-1_c  acc_-1_c  bal_acc_1_o  bal_acc_2_o  bal_acc_3_o  bal_acc_3p_o  \\\n",
       "8     35.0      0.29         0.61         0.51         0.53          0.52   \n",
       "0     35.0      0.17         0.59         0.52         0.51          0.53   \n",
       "17    35.0      0.46         0.56         0.48         0.59          0.53   \n",
       "6     35.0      0.29         0.58         0.57         0.47          0.45   \n",
       "10    35.0      0.46         0.55         0.44         0.53          0.57   \n",
       "..     ...       ...          ...          ...          ...           ...   \n",
       "56     7.0      0.86         0.38         0.45         0.58          0.46   \n",
       "70     7.0      0.00         0.48         0.38         0.50          0.41   \n",
       "67     7.0      0.57         0.55         0.28         0.54          0.44   \n",
       "58     7.0      0.57         0.46         0.28         0.42          0.39   \n",
       "65     7.0      0.57         0.45         0.18         0.29          0.45   \n",
       "\n",
       "    wba_open  wba_close  \n",
       "8       0.55       0.52  \n",
       "0       0.54       0.52  \n",
       "17      0.54       0.52  \n",
       "6       0.53       0.50  \n",
       "10      0.52       0.50  \n",
       "..       ...        ...  \n",
       "56      0.46       0.43  \n",
       "70      0.45       0.42  \n",
       "67      0.46       0.40  \n",
       "58      0.39       0.37  \n",
       "65      0.35       0.35  \n",
       "\n",
       "[72 rows x 14 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flip_bucket_tables_multi_dual(\n",
    "    df_daily,\n",
    "    perf_df,\n",
    "    returns,\n",
    "    *,\n",
    "    K=3,\n",
    "    date_col=\"Date\",\n",
    "    close_col=\"Close\",\n",
    "    w=None,\n",
    "    perf_filter=None,  # optional callable to filter perf_df per horizon\n",
    "):\n",
    "    \"\"\"\n",
    "    For each horizon r:\n",
    "      - builds streak + streak_lag1 from Return_r\n",
    "      - merges into perf_df rows for (horizon=r) (and any extra filters you provide)\n",
    "      - buckets BOTH streak and streak_lag1 into [-K..K] plus tails as +/- (K+1) labeled \"3+\"\n",
    "      - computes:\n",
    "          - wba_close (from streak) and wba_open (from streak_lag1)\n",
    "          - bal_acc pair scores for +/-1, +/-2, +/-3 for both contexts\n",
    "          - (optional) keeps acc/n wide columns for each context with suffixes _c and _o\n",
    "\n",
    "    Returns:\n",
    "      by_r: dict[r] -> wide table (flat columns)\n",
    "      all_out: concat of all horizons with horizon as index level (flat columns)\n",
    "    \"\"\"\n",
    "    if w is None:\n",
    "        # weights: ±1 -> 2.0, ±2 -> 1.5, ±3 -> 1.25, ±3+ -> 1.0\n",
    "        w = {1: 2.0, 2: 1.5, 3: 1.25, \"3+\": 1.0}\n",
    "\n",
    "    max_score = float(sum(w.values()))\n",
    "    gcols = [\"model\", \"train_years\", \"feature_set\"]\n",
    "\n",
    "    def _add_streak(df_base, ret_col):\n",
    "        d = df_base[[date_col, close_col, ret_col]].sort_values(date_col).copy()\n",
    "        s = d[ret_col].astype(\"int8\")\n",
    "        grp = s.ne(s.shift()).cumsum()\n",
    "        streak_len = s.groupby(grp).cumcount() + 1\n",
    "        d[\"streak\"] = streak_len.where(s.eq(1), -streak_len).astype(\"int32\")\n",
    "        d[\"streak_lag1\"] = d[\"streak\"].shift(1).fillna(0).astype(\"Int64\")\n",
    "        return d\n",
    "\n",
    "    def _bucketize(series: pd.Series) -> pd.Series:\n",
    "        b = series.clip(lower=-K, upper=K).astype(\"int32\")\n",
    "        b = b.copy()\n",
    "        b.loc[series < -K] = -(K + 1)\n",
    "        b.loc[series >  K] =  (K + 1)\n",
    "        return b\n",
    "\n",
    "    def _make_context_table(d: pd.DataFrame, bucket_col: str, suffix: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        suffix: \"_c\" for streak (close), \"_o\" for streak_lag1 (open)\n",
    "        returns a flat-column wide df indexed by gcols, containing:\n",
    "          - acc_{bucket}{suffix}, n_{bucket}{suffix} for buckets {1,-1,2,-2,3,-3,3+,-3+}\n",
    "          - bal_acc_{1/2/3}{suffix}\n",
    "          - wba_{close/open} (handled outside)\n",
    "        \"\"\"\n",
    "        flip_perf = (\n",
    "            d.groupby(gcols + [bucket_col], sort=False)\n",
    "             .agg(n=(\"acc\", \"size\"), acc=(\"acc\", \"mean\"))\n",
    "        )\n",
    "\n",
    "        wide = pd.concat(\n",
    "            {\"acc\": flip_perf[\"acc\"].unstack(bucket_col),\n",
    "             \"n\":   flip_perf[\"n\"].unstack(bucket_col)},\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # enforce order: +1/-1, +2/-2, +3/-3, 3+/-3+\n",
    "        ordered_cols = []\n",
    "        for k in [1, 2, 3, \"3+\"]:\n",
    "            pb = (K + 1) if k == \"3+\" else k\n",
    "            nb = -(K + 1) if k == \"3+\" else -k\n",
    "            ordered_cols += [(\"acc\", pb), (\"acc\", nb), (\"n\", pb), (\"n\", nb)]\n",
    "        wide = wide.reindex(columns=pd.MultiIndex.from_tuples(ordered_cols))\n",
    "\n",
    "        # relabel bucket keys to strings (\"3+\", \"-3+\", etc.)\n",
    "        rename_cols = []\n",
    "        for metric, b in wide.columns:\n",
    "            if b == (K + 1): lab = \"3+\"\n",
    "            elif b == -(K + 1): lab = \"-3+\"\n",
    "            else: lab = str(b)\n",
    "            rename_cols.append((metric, lab))\n",
    "        wide.columns = pd.MultiIndex.from_tuples(rename_cols)\n",
    "\n",
    "        # flatten to single-level names: acc_1_c, n_-2_o, etc.\n",
    "        flat = wide.copy()\n",
    "        flat.columns = [f\"{m}_{b}{suffix}\" for (m, b) in flat.columns]\n",
    "\n",
    "        # pair bal_acc for +/-1,2,3 (no 3+ requested here)\n",
    "        def _pair(acc_pos, acc_neg):\n",
    "            return (acc_pos + acc_neg) / 2\n",
    "\n",
    "        flat[f\"bal_acc_1{suffix}\"] = _pair(flat.get(f\"acc_1{suffix}\"),  flat.get(f\"acc_-1{suffix}\"))\n",
    "        flat[f\"bal_acc_2{suffix}\"] = _pair(flat.get(f\"acc_2{suffix}\"),  flat.get(f\"acc_-2{suffix}\"))\n",
    "        flat[f\"bal_acc_3{suffix}\"] = _pair(flat.get(f\"acc_3{suffix}\"),  flat.get(f\"acc_-3{suffix}\"))\n",
    "        flat[f\"bal_acc_3p{suffix}\"] = _pair(flat.get(f\"acc_3+{suffix}\"), flat.get(f\"acc_-3+{suffix}\"))\n",
    "\n",
    "        return flat\n",
    "\n",
    "    base = df_daily[[date_col, close_col] + [f\"Return_{r}\" for r in returns]].copy()\n",
    "\n",
    "    by_r = {}\n",
    "\n",
    "    for r in returns:\n",
    "        ret_col = f\"Return_{r}\"\n",
    "        df_r = _add_streak(base, ret_col)\n",
    "\n",
    "        # merge with perf\n",
    "        perf_r = perf_df[perf_df[\"horizon\"] == r]\n",
    "        if perf_filter is not None:\n",
    "            perf_r = perf_filter(perf_r)\n",
    "\n",
    "        d = df_r.merge(perf_r, on=date_col, how=\"inner\")\n",
    "\n",
    "        other = perf_r.copy()\n",
    "        # bucket both contexts\n",
    "        d[\"bucket_c\"] = _bucketize(d[\"streak\"])       # close-context\n",
    "        d[\"bucket_o\"] = _bucketize(d[\"streak_lag1\"])  # open-context\n",
    "        \n",
    "        #other = d[['Date', \"bucket_c\"]]\n",
    "\n",
    "        tab_c = _make_context_table(d, \"bucket_c\", \"_c\")\n",
    "        tab_o = _make_context_table(d, \"bucket_o\", \"_o\")\n",
    "\n",
    "        # combine side-by-side\n",
    "        out = tab_c.join(tab_o, how=\"outer\")\n",
    "\n",
    "        # compute wba_close / wba_open from each context’s pair balances\n",
    "        out[\"wba_close\"] = (\n",
    "            w[1]   * out[\"bal_acc_1_c\"] +\n",
    "            w[2]   * out[\"bal_acc_2_c\"] +\n",
    "            w[3]   * out[\"bal_acc_3_c\"] +\n",
    "            w[\"3+\"] * out[\"bal_acc_3p_c\"]\n",
    "        ) / max_score\n",
    "\n",
    "        out[\"wba_open\"] = (\n",
    "            w[1]   * out[\"bal_acc_1_o\"] +\n",
    "            w[2]   * out[\"bal_acc_2_o\"] +\n",
    "            w[3]   * out[\"bal_acc_3_o\"] +\n",
    "            w[\"3+\"] * out[\"bal_acc_3p_o\"]\n",
    "        ) / max_score\n",
    "\n",
    "        out[\"wba_close\"] = out[\"wba_close\"].round(2)\n",
    "        out[\"wba_open\"]  = out[\"wba_open\"].round(2)\n",
    "\n",
    "        # optional: keep horizon as a column too (handy for later concat)\n",
    "        out = out.reset_index()\n",
    "        out.insert(0, \"horizon\", r)\n",
    "\n",
    "        by_r[r] = out\n",
    "\n",
    "    all_out = pd.concat(by_r.values(), ignore_index=True)\n",
    "    return by_r, all_out, other\n",
    "\n",
    "# ---- usage ----\n",
    "returns = [2, 5, 10, 20, 30]\n",
    "by_r, all_out, d = flip_bucket_tables_multi_dual(\n",
    "    df_daily=df_daily,\n",
    "    perf_df=perf_df,\n",
    "    returns=returns,\n",
    "    K=3,\n",
    ")\n",
    "\n",
    "# horizon 10 table\n",
    "by_r[10].sort_values([\"wba_close\", \"wba_open\"], ascending=False).head(25)\n",
    "\n",
    "# all horizons combined\n",
    "perf_columns = ['horizon', 'model', 'train_years', 'feature_set', 'n_1_c', 'acc_1_c', 'n_-1_c', 'acc_-1_c',\n",
    "                 'bal_acc_1_o', 'bal_acc_2_o', 'bal_acc_3_o', 'bal_acc_3p_o', 'wba_open', 'wba_close']\n",
    "\n",
    "# top per horizon (ranked by MCC desc, then Brier asc)\n",
    "top_by_horizon = (\n",
    "    all_out\n",
    "    .sort_values([\"horizon\", 'wba_close', 'wba_open'], ascending=[True, False, False])\n",
    "    .groupby(\"horizon\", as_index=False, sort=False)\n",
    "    .head(50)\n",
    ")\n",
    "\n",
    "# top 2 per horizon + anything containing \"-rsi\" in feature_set\n",
    "top2 = (\n",
    "    all_out\n",
    "    .sort_values([\"horizon\", \"wba_open\", \"wba_close\"], ascending=[True, False, False])\n",
    "    .groupby(\"horizon\", sort=False)\n",
    "    .head(6)\n",
    ")\n",
    "\"\"\"\n",
    "rsi = all_out[all_out[\"feature_set\"].astype(str).str.contains(r\"-rsi\", case=False, na=False)]\n",
    "\n",
    "top_by_horizon = (\n",
    "    pd.concat([top2, rsi], ignore_index=False)\n",
    "      .drop_duplicates(subset=[\"horizon\", \"feature_set\"], keep=\"first\")\n",
    "      .sort_values([\"horizon\", \"wba_close\", \"wba_open\"], ascending=[True, False, False])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "top_by_horizon[perf_columns].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7125b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model</th>\n",
       "      <th>train_years</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>brier</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>mcc</th>\n",
       "      <th>cov_|0.6|</th>\n",
       "      <th>acc_|0.6|</th>\n",
       "      <th>composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag</td>\n",
       "      <td>0.569565</td>\n",
       "      <td>0.519932</td>\n",
       "      <td>0.369391</td>\n",
       "      <td>3.588157</td>\n",
       "      <td>0.039969</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.313733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>experimental_slope</td>\n",
       "      <td>0.569565</td>\n",
       "      <td>0.516462</td>\n",
       "      <td>0.365913</td>\n",
       "      <td>4.524742</td>\n",
       "      <td>0.034545</td>\n",
       "      <td>0.926087</td>\n",
       "      <td>0.539906</td>\n",
       "      <td>0.326206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>rsi_macd</td>\n",
       "      <td>0.569565</td>\n",
       "      <td>0.509291</td>\n",
       "      <td>0.265620</td>\n",
       "      <td>0.730046</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.647826</td>\n",
       "      <td>0.530201</td>\n",
       "      <td>0.052827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>volu</td>\n",
       "      <td>0.569565</td>\n",
       "      <td>0.504781</td>\n",
       "      <td>0.359870</td>\n",
       "      <td>3.663870</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.926087</td>\n",
       "      <td>0.530516</td>\n",
       "      <td>0.313953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>volu</td>\n",
       "      <td>0.569565</td>\n",
       "      <td>0.502892</td>\n",
       "      <td>0.256772</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.007580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_lag</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.470098</td>\n",
       "      <td>0.380109</td>\n",
       "      <td>5.935268</td>\n",
       "      <td>-0.054680</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.545872</td>\n",
       "      <td>0.301279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_rel</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.481391</td>\n",
       "      <td>11.468517</td>\n",
       "      <td>-0.087942</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.288629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>30</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>experimental_slope</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.241565</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>-0.136521</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.619792</td>\n",
       "      <td>0.178269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>30</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>5</td>\n",
       "      <td>ma_rel</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.347467</td>\n",
       "      <td>0.963860</td>\n",
       "      <td>-0.161748</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.105241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>vix_skew</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.394608</td>\n",
       "      <td>0.378022</td>\n",
       "      <td>6.063782</td>\n",
       "      <td>-0.216989</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.214564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    horizon          model  train_years         feature_set  pos_rate  \\\n",
       "0         2        xgboost            5              ma_lag  0.569565   \n",
       "16        2        xgboost            5  experimental_slope  0.569565   \n",
       "9         2  random_forest            5            rsi_macd  0.569565   \n",
       "10        2        xgboost            5                volu  0.569565   \n",
       "11        2  random_forest            5                volu  0.569565   \n",
       "..      ...            ...          ...                 ...       ...   \n",
       "54       30        xgboost            5              ma_lag  0.739130   \n",
       "56       30        xgboost            5              ma_rel  0.739130   \n",
       "71       30  random_forest            5  experimental_slope  0.739130   \n",
       "57       30  random_forest            5              ma_rel  0.739130   \n",
       "68       30        xgboost            5            vix_skew  0.739130   \n",
       "\n",
       "     bal_acc     brier   log_loss       mcc  cov_|0.6|  acc_|0.6|  composite  \n",
       "0   0.519932  0.369391   3.588157  0.039969   0.913043   0.519048   0.313733  \n",
       "16  0.516462  0.365913   4.524742  0.034545   0.926087   0.539906   0.326206  \n",
       "9   0.509291  0.265620   0.730046  0.022149   0.647826   0.530201   0.052827  \n",
       "10  0.504781  0.359870   3.663870  0.009630   0.926087   0.530516   0.313953  \n",
       "11  0.502892  0.256772   0.707895  0.006713   0.608696   0.528571   0.007580  \n",
       "..       ...       ...        ...       ...        ...        ...        ...  \n",
       "54  0.470098  0.380109   5.935268 -0.054680   0.947826   0.545872   0.301279  \n",
       "56  0.450000  0.481391  11.468517 -0.087942   0.973913   0.468750   0.288629  \n",
       "71  0.441667  0.241565   0.679825 -0.136521   0.834783   0.619792   0.178269  \n",
       "57  0.408333  0.347467   0.963860 -0.161748   0.817391   0.425532   0.105241  \n",
       "68  0.394608  0.378022   6.063782 -0.216989   0.939130   0.546296   0.214564  \n",
       "\n",
       "[72 rows x 12 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss, log_loss, matthews_corrcoef, balanced_accuracy_score\n",
    "\n",
    "gcols = [\"horizon\", \"model\", \"train_years\", \"feature_set\"]\n",
    "\n",
    "y_col = \"test_pos_n\"   # 0/1 actual\n",
    "p_col = \"pred\"         # P(y=1)\n",
    "\n",
    "def _clip01(p, eps=1e-15):\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return np.clip(p, eps, 1 - eps)\n",
    "\n",
    "def _metrics(g: pd.DataFrame) -> pd.Series:\n",
    "    y = g[y_col].astype(int).to_numpy()\n",
    "    p = _clip01(g[p_col].to_numpy())\n",
    "\n",
    "    # hard preds at 0.5\n",
    "    yhat = (p >= 0.5).astype(int)\n",
    "\n",
    "    # confident subset mask\n",
    "    sel = (p >= 0.6) | (p <= 0.4)\n",
    "\n",
    "    # probability metrics\n",
    "    brier = brier_score_loss(y, p)\n",
    "    ll = log_loss(y, p)\n",
    "\n",
    "    # MCC (needs both classes in y and yhat)\n",
    "    mcc = np.nan\n",
    "    if (np.unique(y).size > 1) and (np.unique(yhat).size > 1):\n",
    "        mcc = matthews_corrcoef(y, yhat)\n",
    "\n",
    "    # Balanced accuracy (needs both classes in y)\n",
    "    bal_acc = np.nan\n",
    "    if np.unique(y).size > 1:\n",
    "        bal_acc = balanced_accuracy_score(y, yhat)\n",
    "\n",
    "    # confident accuracy + coverage\n",
    "    cov = float(sel.mean())\n",
    "    acc_conf = float((yhat[sel] == y[sel]).mean()) if sel.any() else np.nan\n",
    "\n",
    "    return pd.Series({\n",
    "        \"pos_rate\": float(y.mean()),\n",
    "        \"bal_acc\": float(bal_acc) if not np.isnan(bal_acc) else np.nan,\n",
    "        \"brier\": float(brier),\n",
    "        \"log_loss\": float(ll),\n",
    "        \"mcc\": float(mcc) if not np.isnan(mcc) else np.nan,\n",
    "        \"cov_|0.6|\": cov,\n",
    "        \"acc_|0.6|\": acc_conf,\n",
    "    })\n",
    "\n",
    "metrics_df = (\n",
    "    perf_df\n",
    "    .dropna(subset=[y_col, p_col])\n",
    "    .groupby(gcols, sort=False)\n",
    "    .apply(_metrics, include_groups=False)\n",
    "    .reset_index()\n",
    "    .sort_values([\"horizon\", \"mcc\", \"brier\"], ascending=[True, False, True])\n",
    ")\n",
    "\n",
    "metrics_df['composite'] = 0.5*(metrics_df['bal_acc']) + 0.25*(metrics_df['mcc']) + .125*(1-(metrics_df['brier'])) + 0.1*(metrics_df['acc_|0.6|']) - (1-(metrics_df['cov_|0.6|']))\n",
    "# top per horizon (ranked by MCC desc, then Brier asc)\n",
    "top_by_horizon = (\n",
    "    metrics_df\n",
    "    .sort_values([\"horizon\", \"composite\", \"log_loss\"], ascending=[True, False, False])\n",
    "    .groupby(\"horizon\", as_index=False, sort=False)\n",
    "    .head(3)\n",
    ")\n",
    "\n",
    "#top_by_horizon[['horizon', 'feature_set']].to_csv('top_performers.csv', index=False)\n",
    "top_by_horizon.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45298eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p_mean</th>\n",
       "      <th>y_rate</th>\n",
       "      <th>p_min</th>\n",
       "      <th>p_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>228</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>194</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>525</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n  p_mean  y_rate  p_min  p_max\n",
       "0  317    0.09    0.43   0.00   0.20\n",
       "1  334    0.35    0.39   0.25   0.40\n",
       "2  184    0.45    0.46   0.45   0.45\n",
       "3  447    0.52    0.53   0.50   0.55\n",
       "4  235    0.60    0.69   0.60   0.60\n",
       "5  228    0.65    0.66   0.65   0.65\n",
       "6  194    0.70    0.67   0.70   0.70\n",
       "7  272    0.79    0.71   0.75   0.85\n",
       "8  525    0.97    0.71   0.90   1.00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calibration_table(g, n_bins=8):\n",
    "    y = g[y_col].astype(int).to_numpy()\n",
    "    p = np.clip(g[p_col].to_numpy(dtype=float), 1e-15, 1-1e-15)\n",
    "\n",
    "    # quantile bins (stable counts); duplicates=\"drop\" prevents errors if probs repeat\n",
    "    bins = pd.qcut(p, q=n_bins, duplicates=\"drop\")\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame({\"bin\": bins, \"y\": y, \"p\": p})\n",
    "        .groupby(\"bin\", observed=True)\n",
    "        .agg(\n",
    "            n=(\"y\", \"size\"),\n",
    "            p_mean=(\"p\", \"mean\"),   # predicted probability avg\n",
    "            y_rate=(\"y\", \"mean\"),   # observed frequency\n",
    "            p_min=(\"p\", \"min\"),\n",
    "            p_max=(\"p\", \"max\"),\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"p_mean\")\n",
    "    )\n",
    "    return out\n",
    "\n",
    "cols = ['horizon']\n",
    "# example: get calibration table for ONE group\n",
    "key = (2)  # change\n",
    "g = perf_df.set_index(cols).loc[key].reset_index()\n",
    "calib_tbl = calibration_table(g, n_bins=10)\n",
    "round(calib_tbl,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_table(g, n_bins=8):\n",
    "    y = g[y_col].astype(int).to_numpy()\n",
    "    p = np.clip(g[p_col].to_numpy(dtype=float), 1e-15, 1-1e-15)\n",
    "\n",
    "    # quantile bins (stable counts); duplicates=\"drop\" prevents errors if probs repeat\n",
    "    bins = pd.qcut(p, q=n_bins, duplicates=\"drop\")\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame({\"bin\": bins, \"y\": y, \"p\": p})\n",
    "        .groupby(\"bin\", observed=True)\n",
    "        .agg(\n",
    "            n=(\"y\", \"size\"),\n",
    "            p_mean=(\"p\", \"mean\"),   # predicted probability avg\n",
    "            y_rate=(\"y\", \"mean\"),   # observed frequency\n",
    "            p_min=(\"p\", \"min\"),\n",
    "            p_max=(\"p\", \"max\"),\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"p_mean\")\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# example: get calibration table for ONE group\n",
    "#key = (10, \"xgboost\", 6, \"daily\")  # change\n",
    "g = perf_df.set_index(gcols).loc[key].reset_index()\n",
    "calib_tbl = calibration_table(g, n_bins=20)\n",
    "round(calib_tbl,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
