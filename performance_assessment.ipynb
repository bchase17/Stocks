{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5513588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import min_features, daily_return\n",
    "import importlib\n",
    "importlib.reload(min_features)\n",
    "importlib.reload(daily_return)\n",
    "\n",
    "perf_df = pd.read_csv(\"baseline_performance.csv\")\n",
    "perf_df['Date'] = perf_df['test_start']\n",
    "returns = [1, 2, 3, 5, 10, 20, 30]\n",
    "df_daily, feats = daily_return.pull_daily('QQQ', returns) \n",
    "return_cols = df_daily.columns[df_daily.columns.str.contains(\"Return_\")].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4ccd8fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model</th>\n",
       "      <th>train_years</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>n_1_c</th>\n",
       "      <th>acc_1_c</th>\n",
       "      <th>n_-1_c</th>\n",
       "      <th>acc_-1_c</th>\n",
       "      <th>bal_acc_1_o</th>\n",
       "      <th>bal_acc_2_o</th>\n",
       "      <th>bal_acc_3_o</th>\n",
       "      <th>bal_acc_3p_o</th>\n",
       "      <th>wba_open</th>\n",
       "      <th>wba_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>6</td>\n",
       "      <td>initial</td>\n",
       "      <td>35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>35</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>4</td>\n",
       "      <td>initial</td>\n",
       "      <td>35</td>\n",
       "      <td>0.63</td>\n",
       "      <td>35</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>6</td>\n",
       "      <td>initial</td>\n",
       "      <td>19</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>5</td>\n",
       "      <td>initial+sma</td>\n",
       "      <td>19</td>\n",
       "      <td>0.84</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>5</td>\n",
       "      <td>initial+sma</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>5</td>\n",
       "      <td>initial</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>6</td>\n",
       "      <td>initial</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>6</td>\n",
       "      <td>initial+volu</td>\n",
       "      <td>8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>5</td>\n",
       "      <td>initial-rsimacd+volu</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>6</td>\n",
       "      <td>initial</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    horizon      model  train_years           feature_set  n_1_c  acc_1_c  \\\n",
       "4         2  xgboost-6            6               initial     35     0.80   \n",
       "0         2  xgboost-6            4               initial     35     0.63   \n",
       "10        5  xgboost-6            6               initial     19     0.89   \n",
       "8         5  xgboost-6            5           initial+sma     19     0.84   \n",
       "13       10  xgboost-6            5           initial+sma     11     1.00   \n",
       "12       10  xgboost-6            5               initial     11     1.00   \n",
       "18       20  xgboost-6            6               initial      8     1.00   \n",
       "20       20  xgboost-6            6          initial+volu      8     0.88   \n",
       "24       30  xgboost-6            5  initial-rsimacd+volu      6     1.00   \n",
       "25       30  xgboost-6            6               initial      6     1.00   \n",
       "\n",
       "    n_-1_c  acc_-1_c  bal_acc_1_o  bal_acc_2_o  bal_acc_3_o  bal_acc_3p_o  \\\n",
       "4       35      0.54         0.62         0.44         0.41          0.59   \n",
       "0       35      0.69         0.58         0.45         0.51          0.55   \n",
       "10      20      0.35         0.64         0.57         0.58          0.55   \n",
       "8       20      0.40         0.62         0.60         0.58          0.50   \n",
       "13      12      0.17         0.66         0.75         0.64          0.68   \n",
       "12      12      0.25         0.70         0.64         0.88          0.63   \n",
       "18       8      0.12         0.67         0.65         0.57          0.72   \n",
       "20       8      0.25         0.54         0.65         0.67          0.68   \n",
       "24       7      0.43         0.79         0.63         0.67          0.65   \n",
       "25       7      0.14         0.71         0.65         0.54          0.64   \n",
       "\n",
       "    wba_open  wba_close  \n",
       "4       0.52       0.52  \n",
       "0       0.52       0.51  \n",
       "10      0.59       0.60  \n",
       "8       0.59       0.59  \n",
       "13      0.68       0.64  \n",
       "12      0.71       0.63  \n",
       "18      0.65       0.61  \n",
       "20      0.62       0.57  \n",
       "24      0.70       0.69  \n",
       "25      0.65       0.62  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flip_bucket_tables_multi_dual(\n",
    "    df_daily,\n",
    "    perf_df,\n",
    "    returns,\n",
    "    *,\n",
    "    K=3,\n",
    "    date_col=\"Date\",\n",
    "    close_col=\"Close\",\n",
    "    w=None,\n",
    "    perf_filter=None,  # optional callable to filter perf_df per horizon\n",
    "):\n",
    "    \"\"\"\n",
    "    For each horizon r:\n",
    "      - builds streak + streak_lag1 from Return_r\n",
    "      - merges into perf_df rows for (horizon=r) (and any extra filters you provide)\n",
    "      - buckets BOTH streak and streak_lag1 into [-K..K] plus tails as +/- (K+1) labeled \"3+\"\n",
    "      - computes:\n",
    "          - wba_close (from streak) and wba_open (from streak_lag1)\n",
    "          - bal_acc pair scores for +/-1, +/-2, +/-3 for both contexts\n",
    "          - (optional) keeps acc/n wide columns for each context with suffixes _c and _o\n",
    "\n",
    "    Returns:\n",
    "      by_r: dict[r] -> wide table (flat columns)\n",
    "      all_out: concat of all horizons with horizon as index level (flat columns)\n",
    "    \"\"\"\n",
    "    if w is None:\n",
    "        # weights: ±1 -> 2.0, ±2 -> 1.5, ±3 -> 1.25, ±3+ -> 1.0\n",
    "        w = {1: 2.0, 2: 1.5, 3: 1.25, \"3+\": 1.0}\n",
    "\n",
    "    max_score = float(sum(w.values()))\n",
    "    gcols = [\"model\", \"train_years\", \"feature_set\"]\n",
    "\n",
    "    def _add_streak(df_base, ret_col):\n",
    "        d = df_base[[date_col, close_col, ret_col]].sort_values(date_col).copy()\n",
    "        s = d[ret_col].astype(\"int8\")\n",
    "        grp = s.ne(s.shift()).cumsum()\n",
    "        streak_len = s.groupby(grp).cumcount() + 1\n",
    "        d[\"streak\"] = streak_len.where(s.eq(1), -streak_len).astype(\"int32\")\n",
    "        d[\"streak_lag1\"] = d[\"streak\"].shift(1).fillna(0).astype(\"Int64\")\n",
    "        return d\n",
    "\n",
    "    def _bucketize(series: pd.Series) -> pd.Series:\n",
    "        b = series.clip(lower=-K, upper=K).astype(\"int32\")\n",
    "        b = b.copy()\n",
    "        b.loc[series < -K] = -(K + 1)\n",
    "        b.loc[series >  K] =  (K + 1)\n",
    "        return b\n",
    "\n",
    "    def _make_context_table(d: pd.DataFrame, bucket_col: str, suffix: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        suffix: \"_c\" for streak (close), \"_o\" for streak_lag1 (open)\n",
    "        returns a flat-column wide df indexed by gcols, containing:\n",
    "          - acc_{bucket}{suffix}, n_{bucket}{suffix} for buckets {1,-1,2,-2,3,-3,3+,-3+}\n",
    "          - bal_acc_{1/2/3}{suffix}\n",
    "          - wba_{close/open} (handled outside)\n",
    "        \"\"\"\n",
    "        flip_perf = (\n",
    "            d.groupby(gcols + [bucket_col], sort=False)\n",
    "             .agg(n=(\"acc\", \"size\"), acc=(\"acc\", \"mean\"))\n",
    "        )\n",
    "\n",
    "        wide = pd.concat(\n",
    "            {\"acc\": flip_perf[\"acc\"].unstack(bucket_col),\n",
    "             \"n\":   flip_perf[\"n\"].unstack(bucket_col)},\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # enforce order: +1/-1, +2/-2, +3/-3, 3+/-3+\n",
    "        ordered_cols = []\n",
    "        for k in [1, 2, 3, \"3+\"]:\n",
    "            pb = (K + 1) if k == \"3+\" else k\n",
    "            nb = -(K + 1) if k == \"3+\" else -k\n",
    "            ordered_cols += [(\"acc\", pb), (\"acc\", nb), (\"n\", pb), (\"n\", nb)]\n",
    "        wide = wide.reindex(columns=pd.MultiIndex.from_tuples(ordered_cols))\n",
    "\n",
    "        # relabel bucket keys to strings (\"3+\", \"-3+\", etc.)\n",
    "        rename_cols = []\n",
    "        for metric, b in wide.columns:\n",
    "            if b == (K + 1): lab = \"3+\"\n",
    "            elif b == -(K + 1): lab = \"-3+\"\n",
    "            else: lab = str(b)\n",
    "            rename_cols.append((metric, lab))\n",
    "        wide.columns = pd.MultiIndex.from_tuples(rename_cols)\n",
    "\n",
    "        # flatten to single-level names: acc_1_c, n_-2_o, etc.\n",
    "        flat = wide.copy()\n",
    "        flat.columns = [f\"{m}_{b}{suffix}\" for (m, b) in flat.columns]\n",
    "\n",
    "        # pair bal_acc for +/-1,2,3 (no 3+ requested here)\n",
    "        def _pair(acc_pos, acc_neg):\n",
    "            return (acc_pos + acc_neg) / 2\n",
    "\n",
    "        flat[f\"bal_acc_1{suffix}\"] = _pair(flat.get(f\"acc_1{suffix}\"),  flat.get(f\"acc_-1{suffix}\"))\n",
    "        flat[f\"bal_acc_2{suffix}\"] = _pair(flat.get(f\"acc_2{suffix}\"),  flat.get(f\"acc_-2{suffix}\"))\n",
    "        flat[f\"bal_acc_3{suffix}\"] = _pair(flat.get(f\"acc_3{suffix}\"),  flat.get(f\"acc_-3{suffix}\"))\n",
    "        flat[f\"bal_acc_3p{suffix}\"] = _pair(flat.get(f\"acc_3+{suffix}\"), flat.get(f\"acc_-3+{suffix}\"))\n",
    "\n",
    "        return flat\n",
    "\n",
    "    base = df_daily[[date_col, close_col] + [f\"Return_{r}\" for r in returns]].copy()\n",
    "\n",
    "    by_r = {}\n",
    "\n",
    "    for r in returns:\n",
    "        ret_col = f\"Return_{r}\"\n",
    "        df_r = _add_streak(base, ret_col)\n",
    "\n",
    "        # merge with perf\n",
    "        perf_r = perf_df[perf_df[\"horizon\"] == r]\n",
    "        if perf_filter is not None:\n",
    "            perf_r = perf_filter(perf_r)\n",
    "\n",
    "        d = df_r.merge(perf_r, on=date_col, how=\"inner\")\n",
    "\n",
    "        other = perf_r.copy()\n",
    "        # bucket both contexts\n",
    "        d[\"bucket_c\"] = _bucketize(d[\"streak\"])       # close-context\n",
    "        d[\"bucket_o\"] = _bucketize(d[\"streak_lag1\"])  # open-context\n",
    "        \n",
    "        #other = d[['Date', \"bucket_c\"]]\n",
    "\n",
    "        tab_c = _make_context_table(d, \"bucket_c\", \"_c\")\n",
    "        tab_o = _make_context_table(d, \"bucket_o\", \"_o\")\n",
    "\n",
    "        # combine side-by-side\n",
    "        out = tab_c.join(tab_o, how=\"outer\")\n",
    "\n",
    "        # compute wba_close / wba_open from each context’s pair balances\n",
    "        out[\"wba_close\"] = (\n",
    "            w[1]   * out[\"bal_acc_1_c\"] +\n",
    "            w[2]   * out[\"bal_acc_2_c\"] +\n",
    "            w[3]   * out[\"bal_acc_3_c\"] +\n",
    "            w[\"3+\"] * out[\"bal_acc_3p_c\"]\n",
    "        ) / max_score\n",
    "\n",
    "        out[\"wba_open\"] = (\n",
    "            w[1]   * out[\"bal_acc_1_o\"] +\n",
    "            w[2]   * out[\"bal_acc_2_o\"] +\n",
    "            w[3]   * out[\"bal_acc_3_o\"] +\n",
    "            w[\"3+\"] * out[\"bal_acc_3p_o\"]\n",
    "        ) / max_score\n",
    "\n",
    "        out[\"wba_close\"] = out[\"wba_close\"].round(2)\n",
    "        out[\"wba_open\"]  = out[\"wba_open\"].round(2)\n",
    "\n",
    "        # optional: keep horizon as a column too (handy for later concat)\n",
    "        out = out.reset_index()\n",
    "        out.insert(0, \"horizon\", r)\n",
    "\n",
    "        by_r[r] = out\n",
    "\n",
    "    all_out = pd.concat(by_r.values(), ignore_index=True)\n",
    "    return by_r, all_out, other\n",
    "\n",
    "# ---- usage ----\n",
    "returns = [2, 5, 10, 20, 30]\n",
    "by_r, all_out, d = flip_bucket_tables_multi_dual(\n",
    "    df_daily=df_daily,\n",
    "    perf_df=perf_df,\n",
    "    returns=returns,\n",
    "    K=3,\n",
    ")\n",
    "\n",
    "# horizon 10 table\n",
    "by_r[10].sort_values([\"wba_close\", \"wba_open\"], ascending=False).head(25)\n",
    "\n",
    "# all horizons combined\n",
    "perf_columns = ['horizon', 'model', 'train_years', 'feature_set', 'n_1_c', 'acc_1_c', 'n_-1_c', 'acc_-1_c',\n",
    "                 'bal_acc_1_o', 'bal_acc_2_o', 'bal_acc_3_o', 'bal_acc_3p_o', 'wba_open', 'wba_close']\n",
    "\n",
    "# top per horizon (ranked by MCC desc, then Brier asc)\n",
    "top_by_horizon = (\n",
    "    all_out\n",
    "    .sort_values([\"horizon\", 'wba_close', 'wba_open'], ascending=[True, False, False])\n",
    "    .groupby(\"horizon\", as_index=False, sort=False)\n",
    "    .head(2)\n",
    ")\n",
    "\n",
    "# top 2 per horizon + anything containing \"-rsi\" in feature_set\n",
    "top2 = (\n",
    "    all_out\n",
    "    .sort_values([\"horizon\", \"wba_open\", \"wba_close\"], ascending=[True, False, False])\n",
    "    .groupby(\"horizon\", sort=False)\n",
    "    .head(6)\n",
    ")\n",
    "top_by_horizon[perf_columns].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d7125b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model</th>\n",
       "      <th>train_years</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>brier</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>mcc</th>\n",
       "      <th>cov_|0.6|</th>\n",
       "      <th>acc_|0.6|</th>\n",
       "      <th>composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>4</td>\n",
       "      <td>initial</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.37</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>5</td>\n",
       "      <td>initial</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>5</td>\n",
       "      <td>initial+sma</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>6</td>\n",
       "      <td>initial</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>xgboost-6</td>\n",
       "      <td>5</td>\n",
       "      <td>initial-rsimacd+volu</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    horizon      model  train_years           feature_set  pos_rate  bal_acc  \\\n",
       "0         2  xgboost-6            4               initial      0.57     0.54   \n",
       "4         5  xgboost-6            5               initial      0.61     0.54   \n",
       "17       10  xgboost-6            5           initial+sma      0.64     0.65   \n",
       "11       20  xgboost-6            6               initial      0.71     0.68   \n",
       "25       30  xgboost-6            5  initial-rsimacd+volu      0.74     0.64   \n",
       "\n",
       "    brier  log_loss   mcc  cov_|0.6|  acc_|0.6|  composite  \n",
       "0    0.37      6.06  0.09       0.93       0.55       0.36  \n",
       "4    0.35      5.01  0.08       0.96       0.57       0.38  \n",
       "17   0.24      4.84  0.38       0.96       0.73       0.55  \n",
       "11   0.16      2.00  0.45       0.97       0.80       0.60  \n",
       "25   0.20      1.82  0.29       0.97       0.74       0.53  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss, log_loss, matthews_corrcoef, balanced_accuracy_score\n",
    "\n",
    "gcols = [\"horizon\", \"model\", \"train_years\", \"feature_set\"]\n",
    "\n",
    "y_col = \"test_pos_n\"   # 0/1 actual\n",
    "p_col = \"pred\"         # P(y=1)\n",
    "\n",
    "def _clip01(p, eps=1e-15):\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return np.clip(p, eps, 1 - eps)\n",
    "\n",
    "def _metrics(g: pd.DataFrame) -> pd.Series:\n",
    "    y = g[y_col].astype(int).to_numpy()\n",
    "    p = _clip01(g[p_col].to_numpy())\n",
    "\n",
    "    # hard preds at 0.5\n",
    "    yhat = (p >= 0.5).astype(int)\n",
    "\n",
    "    # confident subset mask\n",
    "    sel = (p >= 0.6) | (p <= 0.4)\n",
    "\n",
    "    # probability metrics\n",
    "    brier = brier_score_loss(y, p)\n",
    "    ll = log_loss(y, p)\n",
    "\n",
    "    # MCC (needs both classes in y and yhat)\n",
    "    mcc = np.nan\n",
    "    if (np.unique(y).size > 1) and (np.unique(yhat).size > 1):\n",
    "        mcc = matthews_corrcoef(y, yhat)\n",
    "\n",
    "    # Balanced accuracy (needs both classes in y)\n",
    "    bal_acc = np.nan\n",
    "    if np.unique(y).size > 1:\n",
    "        bal_acc = balanced_accuracy_score(y, yhat)\n",
    "\n",
    "    # confident accuracy + coverage\n",
    "    cov = float(sel.mean())\n",
    "    acc_conf = float((yhat[sel] == y[sel]).mean()) if sel.any() else np.nan\n",
    "\n",
    "    return pd.Series({\n",
    "        \"pos_rate\": float(y.mean()),\n",
    "        \"bal_acc\": float(bal_acc) if not np.isnan(bal_acc) else np.nan,\n",
    "        \"brier\": float(brier),\n",
    "        \"log_loss\": float(ll),\n",
    "        \"mcc\": float(mcc) if not np.isnan(mcc) else np.nan,\n",
    "        \"cov_|0.6|\": cov,\n",
    "        \"acc_|0.6|\": acc_conf,\n",
    "    })\n",
    "\n",
    "metrics_df = (\n",
    "    perf_df\n",
    "    .dropna(subset=[y_col, p_col])\n",
    "    .groupby(gcols, sort=False)\n",
    "    .apply(_metrics, include_groups=False)\n",
    "    .reset_index()\n",
    "    .sort_values([\"horizon\", \"mcc\", \"brier\"], ascending=[True, False, True])\n",
    ")\n",
    "\n",
    "metrics_df['composite'] = 0.5*(metrics_df['bal_acc']) + 0.25*(metrics_df['mcc']) + .125*(1-(metrics_df['brier'])) + 0.1*(metrics_df['acc_|0.6|']) - (1-(metrics_df['cov_|0.6|']))\n",
    "# top per horizon (ranked by MCC desc, then Brier asc)\n",
    "top_by_horizon = (\n",
    "    metrics_df\n",
    "    .sort_values([\"horizon\", \"composite\", \"log_loss\"], ascending=[True, False, False])\n",
    "    .groupby(\"horizon\", as_index=False, sort=False)\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "#top_by_horizon.to_csv('top_performers.csv', index=False)\n",
    "top_by_horizon.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45298eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p_mean</th>\n",
       "      <th>y_rate</th>\n",
       "      <th>p_min</th>\n",
       "      <th>p_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>228</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>194</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>525</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n  p_mean  y_rate  p_min  p_max\n",
       "0  317    0.09    0.43   0.00   0.20\n",
       "1  334    0.35    0.39   0.25   0.40\n",
       "2  184    0.45    0.46   0.45   0.45\n",
       "3  447    0.52    0.53   0.50   0.55\n",
       "4  235    0.60    0.69   0.60   0.60\n",
       "5  228    0.65    0.66   0.65   0.65\n",
       "6  194    0.70    0.67   0.70   0.70\n",
       "7  272    0.79    0.71   0.75   0.85\n",
       "8  525    0.97    0.71   0.90   1.00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calibration_table(g, n_bins=8):\n",
    "    y = g[y_col].astype(int).to_numpy()\n",
    "    p = np.clip(g[p_col].to_numpy(dtype=float), 1e-15, 1-1e-15)\n",
    "\n",
    "    # quantile bins (stable counts); duplicates=\"drop\" prevents errors if probs repeat\n",
    "    bins = pd.qcut(p, q=n_bins, duplicates=\"drop\")\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame({\"bin\": bins, \"y\": y, \"p\": p})\n",
    "        .groupby(\"bin\", observed=True)\n",
    "        .agg(\n",
    "            n=(\"y\", \"size\"),\n",
    "            p_mean=(\"p\", \"mean\"),   # predicted probability avg\n",
    "            y_rate=(\"y\", \"mean\"),   # observed frequency\n",
    "            p_min=(\"p\", \"min\"),\n",
    "            p_max=(\"p\", \"max\"),\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"p_mean\")\n",
    "    )\n",
    "    return out\n",
    "\n",
    "cols = ['horizon']\n",
    "# example: get calibration table for ONE group\n",
    "key = (2)  # change\n",
    "g = perf_df.set_index(cols).loc[key].reset_index()\n",
    "calib_tbl = calibration_table(g, n_bins=10)\n",
    "round(calib_tbl,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_table(g, n_bins=8):\n",
    "    y = g[y_col].astype(int).to_numpy()\n",
    "    p = np.clip(g[p_col].to_numpy(dtype=float), 1e-15, 1-1e-15)\n",
    "\n",
    "    # quantile bins (stable counts); duplicates=\"drop\" prevents errors if probs repeat\n",
    "    bins = pd.qcut(p, q=n_bins, duplicates=\"drop\")\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame({\"bin\": bins, \"y\": y, \"p\": p})\n",
    "        .groupby(\"bin\", observed=True)\n",
    "        .agg(\n",
    "            n=(\"y\", \"size\"),\n",
    "            p_mean=(\"p\", \"mean\"),   # predicted probability avg\n",
    "            y_rate=(\"y\", \"mean\"),   # observed frequency\n",
    "            p_min=(\"p\", \"min\"),\n",
    "            p_max=(\"p\", \"max\"),\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"p_mean\")\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# example: get calibration table for ONE group\n",
    "#key = (10, \"xgboost\", 6, \"daily\")  # change\n",
    "g = perf_df.set_index(gcols).loc[key].reset_index()\n",
    "calib_tbl = calibration_table(g, n_bins=20)\n",
    "round(calib_tbl,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
